<ac:layout>
  <ac:layout-section ac:type="single">
    <ac:layout-cell>
      <p>
        <span style="font-size: 24.0px;letter-spacing: -0.01em;">Overview </span>
      </p>
      <p>The<span> </span> <strong>"Install and Configure Hypervisor"</strong> <span> </span>operation is an integral part of the following Nutanix features and workflows:</p>
      <ul>
        <li>Foundation</li>
        <li>Phoenix</li>
        <li>Cluster Expansion</li>
        <li>Prism: Repair Host Boot Device (Failed)</li>
      </ul>
      <p>During a fresh imaging or reinstallation of the hypervisor on a Nutanix node, it is essential to install the required hardware drivers and apply critical system-level configurations. These steps are necessary to ensure the successful initialization and functionality of the<span> </span>Controller VM (CVM)<span> </span>on the target node.</p>
      <ac:structured-macro ac:macro-id="chapter-overview" ac:name="info" ac:schema-version="1">
        <ac:parameter ac:name="title">What You Will Learn</ac:parameter>
        <ac:rich-text-body>
          <p>By the end of this chapter, you will be able to:</p>
          <ul>
            <li>
              <strong>Understand hypervisor configuration workflows</strong> - Learn how hypervisor configuration integrates with Foundation, Phoenix, and cluster expansion</li>
            <li>
              <strong>Configure hypervisors for Nutanix</strong> - Follow step-by-step procedures for configuring AHV, ESXi, and Hyper-V using Phoenix</li>
            <li>
              <strong>Master first boot processes</strong> - Understand AHV first boot scripts and systemd services for proper initialization</li>
            <li>
              <strong>Configure networking and system settings</strong> - Learn essential network configuration and system-level setup requirements</li>
            <li>
              <strong>Apply best practices</strong> - Follow recommended procedures for successful hypervisor deployment and CVM integration</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
    </ac:layout-cell>
  </ac:layout-section>
  <ac:layout-section ac:type="single">
    <ac:layout-cell>
      <h1>Best Practices</h1>
      <ul>
        <li style="list-style-type: disc;">
          <p>Consult the <strong> <a class="external-link" href="https://portal.nutanix.com/page/documents/list?type=software&amp;filterKey=software&amp;filterVal=Foundation">Field Installation Guide</a> </strong> <span> </span>to ensure that you have taken the proper steps when installing the hypervisor manually</p>
        </li>
        <li style="list-style-type: disc;">
          <p>
            <strong>Default Credentials</strong>: Retain the default hypervisor user password <code>nutanix/4u </code>for<span> </span> <code>root</code> <span> </span>or<span> </span> <code>administrator</code> until the imaging process is complete and the node has successfully joined its designated cluster.</p>
        </li>
        <li style="list-style-type: disc;">
          <p>Do not perform any manual network or system configuration between the completion of hypervisor imaging and the execution of the<span> </span> <strong>"Configure Hypervisor"</strong> <span> </span>step using Phoenix.</p>
        </li>
        <li style="list-style-type: disc;">
          <p>The<span> </span> <strong>"Configure Hypervisor"</strong> <span> </span>action in Phoenix must not be executed multiple times. In the event of a failure, review the<span> </span> <code>first_boot.log</code> <span> </span>file to identify the root cause. Once resolved, re-run the first boot scripts manually. If a complete reconfiguration is required, the hypervisor must be reinstalled prior to reinitiating the<span> </span> <strong>"Configure Installed Hypervisor"</strong> <span> </span>process.</p>
        </li>
      </ul>
      <p style="list-style-type: disc;">
        <br/>
      </p>
      <ac:structured-macro ac:macro-id="e3ac5a2b-f5b3-46b9-bd3b-4906d8521883" ac:name="note" ac:schema-version="1">
        <ac:rich-text-body>
          <p>
            <span style="color: rgb(51,51,51);">In rare cases, after replacing a failed M.2 drive in a G8 node configured with hardware RAID, the system may fail to boot due to RAID-related issues. Knowledge Base article </span> <a href="https://portal.nutanix.com/kb/14874"> KB-14874 </a> <span style="color: rgb(51,51,51);">provides step-by-step guidance on rebuilding the M.2 drive RAID on G8 nodes.</span>
          </p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <p>
        <strong> <ac:inline-comment-marker ac:ref="9d070c7e-09c5-4a1b-b7f5-bea6252b8cb4">Phoenix Installer</ac:inline-comment-marker> </strong>
      </p>
      <p>
        <span style="color: rgb(66,66,66);">When a screen similar to the one shown appears, you have reached the<span> </span> </span> <strong>Nutanix Installer</strong> <span style="color: rgb(66,66,66);"> <span> </span>interface. At this stage, the required action is to select and execute<span> </span> </span> <strong>Install + Configure Hypervisor</strong> <span style="color: rgb(66,66,66);">.</span>
      </p>
      <p>
        <span style="color: rgb(66,66,66);"> <ac:image ac:height="400">
            <ri:attachment ri:filename="Nutanix-Installer1.jpg"/>
          </ac:image> <br/>
        </span>
      </p>
      <p> <span style="color: rgb(66,66,66);">After clicking </span> <strong style="letter-spacing: 0.0px;">Next</strong> <span style="color: rgb(66,66,66);">, you will be prompted to enter the required </span> <strong style="letter-spacing: 0.0px;">networking details</strong> <span style="color: rgb(66,66,66);"> to proceed with the hypervisor installation and configuration process.</span>
      </p>
      <p>
        <span style="color: rgb(66,66,66);"> <ac:image ac:height="400">
            <ri:attachment ri:filename="Nutanix_Installer2.jpg"/>
          </ac:image> <br/>
        </span>
      </p>
      <p>
        <strong>Note</strong>:<span> </span> <span style="color: rgb(66,66,66);">If the IP address fields are left blank, the system will automatically attempt to obtain network configuration via<span> </span> </span> <strong>DHCP</strong>
      </p>
      <p>The<span> </span> <strong>AHV installation or re-imaging process</strong> <span> </span>begins after this step.</p>
      <p>
        <ac:image ac:height="400">
          <ri:attachment ri:filename="Nutanix-Installer3.jpg"/>
        </ac:image>
      </p>
      <h2>AHV </h2>
      <p>
        <span> <span style="color: rgb(66,66,66);">The </span> </span> <span> <strong>first boot</strong> <span style="color: rgb(66,66,66);"> script runs during the initial boot of a </span> <strong>KVM hypervisor</strong> <span style="color: rgb(66,66,66);"> in Nutanix environments. It configures the hypervisor, sets up networking, deploys the </span> <strong>CVM</strong> <span style="color: rgb(66,66,66);">, and can optionally initialize a one-node cluster. Phoenix typically triggers </span>it</span> <span> <span style="color: rgb(66,66,66);"> during imaging.</span> </span>
      </p>
      <h3>
        <strong>AHV 9.0 and later releases</strong>
      </h3>The firstboot script is now part of<span> </span> <code>nutanix-ahv as shown below whereas the script was at /root/firstboot/kvm_first_boot.py prior to AHV 9.0.</code>
      <ac:structured-macro ac:macro-id="f863e731-9027-4559-9ddd-ad2bb3f4a624" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:plain-text-body><![CDATA[[root@NTNX-24SG6Q020010-B /]# ls -la ./usr/share/nutanix-ahv/firstboot/
total 20
drwxr-xr-x. 3 root root 4096 Jul  7 08:33 .
drwxr-xr-x. 5 root root 4096 Jul  7 08:22 ..
-rw-r--r--. 1 root root 3589 May  8  2024 firstboot_utils.py
-rwxr-xr-x. 1 root root 3524 May  8  2024 kvm_first_boot.py
drwxr-xr-x. 2 root root 4096 Jul  7 08:33 __pycache__]]></ac:plain-text-body>
      </ac:structured-macro>
      <p>
        <span style="color: rgb(36,41,47);"> <span style="color: rgb(66,66,66);">The<span> </span> </span> <strong>firstboot/hostsetup</strong> <span style="color: rgb(66,66,66);"> <span> </span>process manages a series of services, each executed in a defined order based on inter-service dependencies. For example, the<span> </span> </span> <code>ahv-setup-network</code> <span style="color: rgb(66,66,66);"> <span> </span>service will only run after the successful completion of<span> </span> </span> <code>ahv-configuration-generator</code> <span style="color: rgb(66,66,66);">. Below is the list of services.</span> </span>
      </p>
      <ac:structured-macro ac:macro-id="462dbea2-28d7-4215-bc5d-41e9658dda94" ac:name="info" ac:schema-version="1">
        <ac:rich-text-body>
          <ul>
            <li>
              <p>
                <code>ahv-generate-cvm-config: (Previously named ahv-configuration-generator )</code>: Generates the configuration for CVM and <span>stores it in /etc/nutanix/config/cvm_config.json on the AHV host.</span>
              </p>
            </li>
            <li>
              <p>
                <code>ahv-setup-network</code>: Setup AHV networking i.e physical nics, br0 OVS bridge, clusters OVS bridge chain and DNS configuration.</p>
            </li>
            <li>
              <p>
                <code>ahv-setup-ssh</code>: Inject SSH keys for linux users(root, nutanix, admin) as created by AHV installation.</p>
            </li>
            <li>
              <p>
                <code>ahv-setup-hostname</code>: Update/configure hostname on AHV.</p>
            </li>
            <li>
              <p>
                <code>ahv-install-cvm</code>: Install CVM if AOS installer info is populated in CVM configuration. Currently, supported only for Cluster on AWS &amp; Azure.</p>
            </li>
            <li>
              <p>
                <code>ahv-configure-cvm</code>: Inject hardware-config, factory-config, ssh-keys (for passwordless access of AHV-&gt;CVM &amp; CVM-&gt;AHV), setup network configuration.</p>
            </li>
            <li>
              <p>
                <code>ahv-define-cvm</code>: Generate CVM XML domain using CVM configuration, which would have list of pass-through devices and start CVM.</p>
            </li>
            <li>
              <p>
                <code>ahv-status-cvm</code>: Checks CVM firstboot installation status by checking for marker file "/tmp/svm_boot_succeeded", created by CVM firstboot script on success.</p>
            </li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
      <p class="auto-cursor-target">In AHV, the firstboot scripts are wrapped in a systemd service:</p>
      <ac:structured-macro ac:macro-id="e855313f-16b8-4dca-9bab-7c4fa80c2331" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">systemctl status ahv_first_boot</ac:parameter>
        <ac:plain-text-body><![CDATA[[root@NTNX-24SG6Q020010-B phases]# systemctl status ahv_first_boot
● ahv_first_boot.service - AHV firstboot script
   Loaded: loaded (/usr/lib/systemd/system/ahv_first_boot.service; enabled; vendor preset: enabled)
   Active: active (exited) since Tue 2025-07-08 23:23:31 UTC; 2min 23s ago
  Process: 14326 ExecStart=/usr/share/nutanix-ahv/firstboot/kvm_first_boot.py (code=exited, status=0/SUCCESS)
 Main PID: 14326 (code=exited, status=0/SUCCESS)
    Tasks: 0 (limit: 2464604)
   Memory: 0B
   CGroup: /system.slice/ahv_first_boot.service
 
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "svmboot.iso": "aos/svmboot.iso",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "svmboot_kexec.iso": "aos/svmboot_kexec.iso",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "hardware_config_path": "config/hardware_config.json",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "nutanix_private_key_path": "config/nutanix"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]: }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]: [2025-07-08 23:23:31,921 foundation_logger.py:282] [INFO] Running cmd ['uname -m']
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]: [2025-07-08 23:23:31,923 foundation_logger.py:282] [INFO] Running cmd ['touch /root/.firstboot_success']
Jul 08 23:23:31 NTNX-24SG6Q020010-B systemd[1]: Started AHV firstboot script.]]></ac:plain-text-body>
      </ac:structured-macro>
      <p>
        <span style="color: rgb(66,66,66);">The<span> </span> </span> <strong>firstboot</strong> <span style="color: rgb(66,66,66);"> <span> </span>functionality has been migrated from the<span> </span> </span> <code>ahv_first_boot</code> <span style="color: rgb(66,66,66);"> <span> </span>service to the<span> </span> </span> <code>hostconfig</code> <span style="color: rgb(66,66,66);"> <span> </span>service. Logs for<span> </span> </span> <code>hostconfig</code> <span style="color: rgb(66,66,66);"> <span> </span>are now managed by<span> </span> </span> <strong>journald</strong> <span style="color: rgb(66,66,66);"> <span> </span>and can be accessed using the<span> </span> </span> <code>journalctl</code> <span style="color: rgb(66,66,66);"> <span> </span>command.</span>
      </p>
      <p>Test Environment Details</p>
      <ul>
        <li>
          <p>
            <strong>AOS Version</strong>: 7.0.0.5</p>
        </li>
        <li>
          <p>
            <strong>Foundation Version</strong>: 5.7</p>
        </li>
        <li>
          <p>
            <strong>Hypervisor Version</strong>: AHV 10.0.0.1</p>
        </li>
        <li>
          <p>
            <strong>Hardware Model</strong>: <ac:inline-comment-marker ac:ref="6c724fa4-9792-4180-af2e-96d564cdea27">NX-1065-G9</ac:inline-comment-marker>
          </p>
        </li>
      </ul>
      <p>
        <span style="color: rgb(23,43,77);"> <strong>Example 1</strong>: To fetch the logs of the networking setup, you may use the following journalctl command:<br/>
        </span>
      </p>
      <ac:structured-macro ac:macro-id="3830681c-3f20-41a3-90f9-47974089b2b6" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">journalctl -u ahv-setup-network</ac:parameter>
        <ac:parameter ac:name="collapse">true</ac:parameter>
        <ac:plain-text-body><![CDATA[[root@NTNX-24SG6Q020010-B ~]# journalctl -u ahv-setup-network
-- Logs begin at Tue 2025-07-08 23:22:01 UTC, end at Tue 2025-07-08 23:27:31 UTC. --
Jul 08 23:22:17 localhost.localdomain systemd[1]: Starting Nutanix ahv network setup utility...
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,639 base_logger.py:32] [INFO] setup ahv network started
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,640 base_logger.py:38] [WARNING] No CVM XML file found...
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,641 base_logger.py:38] [WARNING] No CVM XML file found...
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,647 base_logger.py:32] [INFO] Network device ahv0 doesn't have interface name matching ethX scheme
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,647 base_logger.py:32] [INFO] setting nic ahv0 as eth0
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,705 base_logger.py:32] [INFO] Network device ahv1 doesn't have interface name matching ethX scheme
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,705 base_logger.py:32] [INFO] setting nic ahv1 as eth1
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,765 base_logger.py:32] [INFO] Network device ahv2 doesn't have interface name matching ethX scheme
Jul 08 23:22:17 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:17,765 base_logger.py:32] [INFO] setting nic ahv2 as eth2
Jul 08 23:22:18 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:18,133 base_logger.py:32] [INFO] Network device ahv3 doesn't have interface name matching ethX scheme
Jul 08 23:22:18 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:18,133 base_logger.py:32] [INFO] setting nic ahv3 as eth3
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,221 base_logger.py:32] [INFO] DNS entries not populated in the config
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,233 base_logger.py:32] [INFO] Monitoring url not provided, Configuring OVS withall NICs
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,233 base_logger.py:32] [INFO] Deleting bridge, port, interface connection for br0. A remote connection to this AHV might temporarily get disconnected
Jul 08 23:22:21 localhost.localdomain ovs-vsctl[8631]: ovs|00001|vsctl|INFO|Called as ovs-vsctl --if-exists del-br br0
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,569 base_logger.py:32] [INFO] Deleting bridge, port, interface connection for br1. A remote connection to this AHV might temporarily get disconnected
Jul 08 23:22:21 localhost.localdomain ovs-vsctl[8888]: ovs|00001|vsctl|INFO|Called as ovs-vsctl --if-exists del-br br1
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,905 base_logger.py:32] [INFO] nic eth3 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth2 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth1 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth0 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth3 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth2 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth1 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth0 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth3 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth2 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth1 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth0 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth3 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth2 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth1 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth0 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth3 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth2 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth1 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth0 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] uplink speed not provided in vswitch br0adding nic eth3 to vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] uplink speed not provided in vswitch br0adding nic eth2 to vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth1 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth0 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth1 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] nic eth0 does not match with uplink  in vswitch br0. Dropping from this vswitch. Might retry with other vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] uplink speed not provided in vswitch br0adding nic eth1 to vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 base_logger.py:32] [INFO] uplink speed not provided in vswitch br0adding nic eth0 to vswitch
Jul 08 23:22:21 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:21,906 foundation_logger.py:282] [INFO] Uplink detected for br0: eth3
Jul 08 23:22:22 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:22,014 foundation_logger.py:282] [INFO] Adding ['eth3', 'eth2', 'eth1', 'eth0'] to the list of uplinks for vswitch br0
Jul 08 23:22:25 localhost.localdomain ovs-vsctl[10736]: ovs|00001|vsctl|INFO|Called as ovs-vsctl -- --may-exist add-bond br0 br0-up eth3 eth2 eth1 eth0 -- set port br0-up bond_mode=active-backup
Jul 08 23:22:25 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:25,761 foundation_logger.py:282] [INFO] Configuring BMC interface
Jul 08 23:22:25 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:25,885 base_logger.py:32] [INFO] Bringing up OVS interface br0
Jul 08 23:22:26 localhost.localdomain ahv-setup-network[6950]: [2025-07-08 23:22:26,166 foundation_logger.py:282] [INFO] setup ahv network finished
Jul 08 23:22:26 localhost.localdomain systemd[1]: Started Nutanix ahv network setup utility.]]></ac:plain-text-body>
      </ac:structured-macro>
      <p>
        <span style="color: rgb(23,43,77);"> <strong>Example 2</strong> To fetch the logs of the firstboot script, use the following command. The following example shows a successful firstboot script in AHV 9.0 and later releases.</span>
      </p>
      <ac:structured-macro ac:macro-id="1160daea-76d9-453d-929e-5bb9112ce881" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">journalctl -u ahv_first_boot</ac:parameter>
        <ac:parameter ac:name="collapse">true</ac:parameter>
        <ac:plain-text-body><![CDATA[root@NTNX-24SG6Q020010-B ~]# journalctl -u ahv_first_boot
-- Logs begin at Tue 2025-07-08 23:22:01 UTC, end at Tue 2025-07-08 23:32:51 UTC. --
Jul 08 23:23:31 NTNX-24SG6Q020010-B systemd[1]: Starting AHV firstboot script...
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]: [2025-07-08 23:23:31,921 foundation_logger.py:282] [INFO] installer_json = {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "install_device": "sda",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "lcm_family": "smc_gen_13",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "monitoring_url_root": null,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "installing_callback_url": "None&step=Installing%20AHV",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "rebooting_callback_url": "None&step=Rebooting%20AHV",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "phoenix_version": "phoenix-5.7_f86e8a13",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "foundation_version": "unknown",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "smbios": "smbios.bin",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "pci": "lspci.txt",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "use_dhcp": true,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "platform_may_need_power_cycle_quirk": false,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "version": "1.0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "cvm_config": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "memory_mib": 20480,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "cpu": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       "topology": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "sockets": 12,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "dies": 1,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "threads": 1,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "cores": 1
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       "vcpus": [
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "id": "default",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "cpuset": "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       ]
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "numa": {},
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "network_interfaces": [
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "name": "eth0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "type": "bridge",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "source_name": "br0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "vlan": 0
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "name": "eth1",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "type": "network",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "source_name": "NTNX-Local-Network"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "name": "eth2",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "type": "bridge",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "source_name": "br0"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     ]
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "cvm_devices": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "pci": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       "disks": [
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "type": "pci",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "sbdf_address": "0000:17:00.0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "vendor_id": "00001000",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "device_id": "000000E6",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "subsystem_vendor_id": "000015D9",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "subsystem_device_id": "00001B64",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "base_class": "01",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "sub_class": "07",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:           "interface": "00"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       ],
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       "nics": []
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "scsi": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       "disks": []
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "node_type": "hci",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "hostname": "NTNX-24SG6Q020010-B",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "foundation": {},
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "network_config": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "passthru_nics": [],
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "host_interfaces": [
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "name": "br0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "ip": "10.24.137.227",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "netmask": "255.255.252.0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "gateway": "10.24.136.1",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "vswitch": "br0"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     ],
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "vswitches": [
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "name": "br0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "bond-mode": "active-backup"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     ],
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "enable_ipv6": false,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "use_all_nics": false,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "setup_bmc_interface": true
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "config_drivers": true,
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "boot_device_meta": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "type": "pci",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "sbdf_address": "0000:3d:00.0",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "vendor_id": "00001B4B",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "device_id": "00002241",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "subsystem_vendor_id": "000015D9",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "subsystem_device_id": "00001C94",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "base_class": "01",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "sub_class": "08",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "interface": "02"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "edition": "enterprise",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "users": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     "infra": {
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       "public_ssh_keys": [
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:         "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC2ApoY9bimnhAvp+dMhE9XNFxjLVSc05a+e5wpXYwspeBrJwcVkEW2TKA/lcIhTSAn3ssrA1Zm5Dh3KXLomXfpHw7yAMTgtJvWPCVf/LBa1AmPUCbaKapahn9pF/R1x>
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:       ]
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:     }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   },
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "svmboot.iso": "aos/svmboot.iso",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "svmboot_kexec.iso": "aos/svmboot_kexec.iso",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "hardware_config_path": "config/hardware_config.json",
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]:   "nutanix_private_key_path": "config/nutanix"
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]: }
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]: [2025-07-08 23:23:31,921 foundation_logger.py:282] [INFO] Running cmd ['uname -m']
Jul 08 23:23:31 NTNX-24SG6Q020010-B kvm_first_boot.py[14326]: [2025-07-08 23:23:31,923 foundation_logger.py:282] [INFO] Running cmd ['touch /root/.firstboot_success']
Jul 08 23:23:31 NTNX-24SG6Q020010-B systemd[1]: Started AHV firstboot script.]]></ac:plain-text-body>
      </ac:structured-macro>
      <p>The status of the<span> </span> <strong>firstboot</strong> <span> </span>script can be determined by checking for the presence of marker files:</p>
      <ul>
        <li>
          <p>
            <code>.firstboot_success</code> <span> </span>— Indicates the script completed successfully</p>
        </li>
        <li>
          <p>
            <code>.firstboot_fail</code> <span> </span>— Indicates the script encountered an error</p>
        </li>
      </ul>
      <p>In the example below, the presence of the<span> </span> <code>.firstboot_success</code> <span> </span>file confirms a successful execution of the firstboot script on the node.</p>
      <ac:structured-macro ac:macro-id="401cdf4a-0629-47b1-8a76-171d7197f82e" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:plain-text-body><![CDATA[root@NTNX-24SG6Q020010-B ~]# ls -al
total 152
dr-xr-x---.  6 root root  4096 Jul  8 23:52 .
dr-xr-xr-x. 18 root root  4096 Jul  8 16:11 ..
drwxr-xr-x.  3 root root  4096 Jul  8 23:25 acropolis_modules
-rw-------.  1 root root 47275 Jul  8 16:12 anaconda-ks.cfg
drwxr-x---.  2 root root  4096 Jul  8 23:24 .augeas
-rw-------.  1 root root   872 Jul  8 23:52 .bash_history
-rw-r-----.  1 root root    18 Mar 14  2021 .bash_logout
-rw-r-----.  1 root root   176 Mar 14  2021 .bash_profile
-rw-r-----.  1 root root   176 Mar 14  2021 .bashrc
-rw-r-----.  1 root root   100 Mar 14  2021 .cshrc
drwxr-x---.  3 root root  4096 Jul  8 23:22 firstboot
-rw-r--r--.  1 root root     0 Jul  8 23:23 .firstboot_success   <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
lrwxrwxrwx.  1 root root    33 Jul  8 16:13 hardware_config.json -> /etc/nutanix/hardware_config.json
-rw-------.  1 root root 48262 Jul  8 16:16 original-ks.cfg
drwx------.  2 root root  4096 Jul  8 23:24 .ssh
-rw-r-----.  1 root root   129 Mar 14  2021 .tcshrc
-rwx------.  1 root root  7571 Mar  7  2024 upgrade_config.sh]]></ac:plain-text-body>
      </ac:structured-macro>
      <h4>
        <strong>To re-run the AHV First Boot Script:</strong>
      </h4>
      <p>
        <span>If the script fails, check </span> <code class="language-PlainText">
          <span>/var/log/firstboot.log</span>
        </code> <span> for detailed logs and fix the issue.</span>
      </p>
      <ol>
        <li>
          <p>Remove the firstboot_fail marker file.</p>
          <pre>[root@NTNX-24SG6Q020010-B /] rm /root/.firstboot*<br/>
            <br/>
          </pre>
        </li>
        <li>
          <p class="auto-cursor-target">You may need to add the /root/.firstboot marker before the first boot scripts run again. Use the following command for that:</p>
          <pre>[root@NTNX-24SG6Q020010-B /] touch /root/.firstboot<br/>
            <br/>
          </pre>
        </li>
        <li>
          <p>Execute the First Boot Script from '/'</p>
          <pre>[root@NTNX-24SG6Q020010-B /] ./usr/share/nutanix-ahv/firstboot/kvm_first_boot.py</pre>
        </li>
      </ol>
      <h3>
        <strong>Prior to the AHV 9.0 release</strong>
      </h3>
      <p class="auto-cursor-target">As part of the first host boot, the script /root/firstboot/kvm_first_boot.py is called. This file was previously copied from the Foundation repository: <code>phoenix/bootloader/initrd/phoenix/firstboot/kvm/kvm_first_boot.py</code> <span> </span>
      </p>
      <p>
        <span style="color: rgb(0,0,0);"> <strong>First Boot Phases</strong> </span>
      </p>
      <pre>[root@AHV-1 ~]# cd /root/firstboot/phases
</pre>
      <ac:structured-macro ac:macro-id="ae475a8c-5108-4b8f-8e8e-0c00bcb0ddc0" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:plain-text-body><![CDATA[[root@AHV-1 phases]# ls -ltr
total 0
-rw-r-----. 1 root root 0 May 17  2022 configure_network
-rw-r-----. 1 root root 0 May 17  2022 create_cvm
-rw-r-----. 1 root root 0 May 17  2022 create_libvirt_networks
-rw-r-----. 1 root root 0 May 17  2022 cvm_firstboot
-rw-r-----. 1 root root 0 May 17  2022 expand_boot_partition]]></ac:plain-text-body>
      </ac:structured-macro>
      <pre>Example of firstboot.out with success</pre>
      <ac:structured-macro ac:macro-id="9f33fa6e-e2eb-40f4-bf3d-3597e4130867" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">firstboot.out</ac:parameter>
        <ac:parameter ac:name="collapse">true</ac:parameter>
        <ac:plain-text-body><![CDATA[INFO Running cmd ['uname -m']
INFO Running cmd ['service ntpd stop']
INFO first_boot_config = {
...
}
INFO Running cmd ['uname -r']
INFO Running cmd ['uname -m']
INFO Running cmd ['/sbin/restorecon -R /root/.ssh']
INFO Running cmd ["\n# Set OS Host buffers to 4096: ENG-89456\nfor nic in $(netstat -i |egrep -o 'eth[0-9]+'); do\n  /sbin/ethtool -G $nic rx 4096;\ndone\n"]
INFO Running cmd ['/sbin/restorecon -R /etc/sysconfig/network-scripts']
INFO Running cmd ['ethtool eth1']
INFO Running cmd ['ethtool eth0']
INFO Running cmd ['ethtool eth3']
INFO Running cmd ['ethtool eth2']
INFO Adding ['eth1', 'eth0', 'eth3', 'eth2'] to the list of uplinks for vswitch br0
INFO Running cmd ['/sbin/ifdown eth1']
INFO Running cmd ['/sbin/ifup eth1']
INFO Running cmd ['/sbin/ifdown eth0']
INFO Running cmd ['/sbin/ifup eth0']
INFO Running cmd ['/sbin/ifdown eth3']
INFO Running cmd ['/sbin/ifup eth3']
INFO Running cmd ['/sbin/ifdown eth2']
INFO Running cmd ['/sbin/ifup eth2']
INFO Running cmd ['uname -r']
INFO Running cmd [u'ovs-vsctl add-br br0 -- add-bond br0 br0-up eth1 eth0 eth3 eth2']
INFO Running cmd [u'/sbin/ifdown br0']
INFO Running cmd [u'/sbin/ifup br0']
INFO Running cmd ['service network restart']
INFO Running cmd [u'arping -A -I br0 10.1.105.32 -c 1']
INFO Running cmd ['sleep 2']
INFO Running cmd [u'arping -U -I br0 10.1.105.32 -c 1']
INFO Running cmd ['ipcalc -b 10.1.105.32 255.255.252.0']
INFO Running cmd [u'ping -c 1 10.1.107.255 -W 1']
ERROR Execution of command [u'ping -c 1 10.1.107.255 -W 1'] failed, exit code: 2, stdout: , stderr: Do you want to ping broadcast? Then -b. If not, check your local firewall rules.
INFO Running cmd ['touch /root/firstboot/phases/configure_network']
INFO Running cmd ['ovs-appctl bond/list']
INFO Running cmd [u'ovs-appctl bond/set-active-slave br0-up eth2']
INFO Running cmd [u'ping -c 1 10.1.104.5']
INFO Using eth2 as the active slave in bond br0-up
INFO Expanding boot partition. This may take some time.
INFO Running cmd ['/usr/bin/nohup /sbin/resize2fs /dev/sda1 &>/dev/null &']
INFO Running cmd ['touch /root/firstboot/phases/expand_boot_partition']
INFO Running cmd ['virsh net-list --all']
INFO Running cmd ['virsh net-list --all']
INFO Running cmd ['virsh net-define /root/net-VM-Network.xml']
INFO Running cmd ['virsh net-start VM-Network']
INFO Running cmd ['virsh net-autostart VM-Network']
INFO Running cmd ['virsh net-list --all']
INFO Running cmd ['virsh net-define /root/net-NTNX-Local-Network.xml']
INFO Running cmd ['virsh net-start NTNX-Local-Network']
INFO Running cmd ['virsh net-autostart NTNX-Local-Network']
INFO Running cmd ['touch /root/firstboot/phases/create_libvirt_networks']
INFO Running cmd ['echo "$(hostname)-CVM"']
INFO Running cmd [u'sed -i "s/<name>NTNX-CVM/<name>NTNX-BattleKid-2-CVM/" /root/NTNX-CVM.xml']
INFO Running cmd ['sed -i "/<uuid>/d" /root/NTNX-CVM.xml']
INFO Running cmd ['chmod 644 /var/lib/libvirt/NTNX-CVM/svmboot.iso']
INFO Running cmd ['chown qemu:qemu /var/lib/libvirt/NTNX-CVM/svmboot.iso']
INFO Running cmd ['virsh define /root/NTNX-CVM.xml']
INFO Running cmd ['service libvirtd restart']
INFO Running cmd [u'virsh start "NTNX-BattleKid-2-CVM"']
INFO Running cmd [u'virsh autostart "NTNX-BattleKid-2-CVM"']
ERROR Execution of command ['/usr/bin/ssh -i /root/firstboot/ssh_keys/nutanix -o StrictHostKeyChecking=no -o NumberOfPasswordPrompts=0 -o UserKnownHostsFile=/dev/null nutanix@192.168.5.2 "ls /tmp/svm_boot_succeeded"'] failed, exit code: 255, stdout: , stderr: FIPS mode initialized
ssh: connect to host 192.168.5.2 port 22: No route to host
ERROR Execution of command ['/usr/bin/ssh -i /root/firstboot/ssh_keys/nutanix -o StrictHostKeyChecking=no -o NumberOfPasswordPrompts=0 -o UserKnownHostsFile=/dev/null nutanix@192.168.5.2 "ls /tmp/svm_boot_succeeded"'] failed, exit code: 255, stdout: , stderr: 
...
FIPS mode initialized
Warning: Permanently added '192.168.5.2' (RSA) to the list of known hosts.
Nutanix Controller VM
ls: cannot access /tmp/svm_boot_succeeded: No such file or directory
INFO [14/160] Waiting for CVM to finish first boot
ERROR Execution of command ['/usr/bin/ssh -i /root/firstboot/ssh_keys/nutanix -o StrictHostKeyChecking=no -o NumberOfPasswordPrompts=0 -o UserKnownHostsFile=/dev/null nutanix@192.168.5.2 "ls /tmp/svm_boot_succeeded"'] failed, exit code: 255, stdout: , stderr: FIPS mode initialized
ssh: connect to host 192.168.5.2 port 22: Connection refused
INFO Running cmd ['touch /root/.firstboot_success']
INFO Running cmd ['service ntpd start']
INFO Running cmd ['/sbin/chkconfig ntpd on']]]></ac:plain-text-body>
      </ac:structured-macro>
      <h4>
        <strong> <span>Log Location</span> </strong>
      </h4>
      <pre>/var/log/firstboot.log<br/>OR<br/>/root/firstboot/firstboot.out</pre>
      <h4>
        <strong>To re-run First Boot Script:</strong>
      </h4>
      <ol>
        <li>
          <p>Review firstboot.out log and fix issue which caused script to fail.</p>
        </li>
        <li>
          <p>Remove firstboot_fail marker file.</p>
          <pre>[root@AHV-4 NTNX]# rm /root/.firstboot_fail</pre>
        </li>
        <li>
          <p class="auto-cursor-target">You may need to add the /root/.firstboot marker before the first boot scripts run again. Use the following command for that:</p>
          <pre>[root@AHV-4 NTNX]# touch /root/.firstboot</pre>
        </li>
        <li>
          <p>Execute the First Boot Script.</p>
          <pre>[root@AHV-4 NTNX]# /root/firstboot/kvm_first_boot.py</pre>
        </li>
      </ol>
      <h2>ESXi</h2>
      <p> <span style="letter-spacing: 0.0px;">The</span> <span style="letter-spacing: 0.0px;"> </span> <code style="letter-spacing: 0.0px;">esx_first_boot.py</code> <span style="letter-spacing: 0.0px;"> </span> <span style="letter-spacing: 0.0px;">script automates the initial configuration of an ESXi hypervisor during its first boot following imaging by the Nutanix installer. This script is responsible for:</span>
      </p>
      <ul>
        <li>
          <p>Configuring the hypervisor environment</p>
        </li>
        <li>
          <p>
            <ac:inline-comment-marker ac:ref="912f651c-f973-4e0b-b124-0df94e9cffce"> <span style="color: rgb(23,43,77);">Creating a VM object to make the existing CVM manageable from ESXi</span> </ac:inline-comment-marker>
          </p>
        </li>
        <li>
          <p>Preparing the system for integration into a Nutanix cluster</p>
        </li>
      </ul>
      <p>
        <ac:inline-comment-marker ac:ref="c10c88c0-cb2d-4dc5-99c3-8e5bfc50a676">The script executes a series of predefined phases located in the following directory called First Boot Phases. </ac:inline-comment-marker> <span style="letter-spacing: 0.0px;"> </span> <span style="letter-spacing: 0.0px;">As each phase of the first boot scripts completes, a marker file named for this phase is added into the directory below. In the event that the first boot script has to be run a second time, the marker file tells the script which phases have already succeeded so that it doesn't try to perform these again.</span>
      </p>
      <pre>[root@Mother-2:~]cd /bootbank/Nutanix/firstboot/phases</pre>
      <p> Example directory listing:</p>
      <ac:structured-macro ac:macro-id="8a2c8199-178a-42c2-b5e3-1110febc92fd" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:plain-text-body><![CDATA[[root@Mother-2:~]cd /bootbank/Nutanix/firstboot/phases
[root@Mother-2:~]/vmfs/volumes/900d4956-8b4e3ad0-5cba-2a1c336ac949/Nutanix/firstboot/phases] ls -al
total 512
drwxr-xr-x 1 root root 8 Jul 15 02:29 .
drwxr-xr-x 1 root root 8 Jul 15 02:30 ..
-rwx------ 1 root root 0 Jul 15 02:27 apply_licenses
-rwx------ 1 root root 0 Jul 15 02:27 conserve_bootbank_space
-rwx------ 1 root root 0 Jul 15 02:27 disable_network
-rwx------ 1 root root 0 Jul 15 02:24 disable_vmd_vibs
-rwx------ 1 root root 0 Jul 15 02:29 driver_BCM_bootbank_bnxtnet_226.0.121.0-1OEM.800.1.0.20613240.vib
-rwx------ 1 root root 0 Jul 15 02:28 driver_NTX_bootbank_ntx-esxi-01-smartctlcmd_1.0-01.vib
-rwx------ 1 root root 0 Jul 15 02:28 driver_NTX_bootbank_ntx-esxi-1-ipmitool_1.0-01.vib
-rwx------ 1 root root 0 Jul 15 02:29 driver_SMC_bootbank_smc-esxi-01-ipmicfg_1.0-01.vib
-rwx------ 1 root root 0 Jul 15 02:24 driver_i40en_2.7.2.0-1OEM.800.1.0.20613240.vib
-rwx------ 1 root root 0 Jul 15 02:24 driver_icen_1.13.2.0-1OEM.800.1.0.20613240.vib
-rwx------ 1 root root 0 Jul 15 02:28 driver_ixgben_1.18.2.0-1OEM.800.1.0.20613240.vib
-rwx------ 1 root root 0 Jul 15 02:28 driver_nfs-vaai-plugin-3.0-44d2a400.vib
-rwx------ 1 root root 0 Jul 15 02:27 dump_first_boot_config
-rwx------ 1 root root 0 Jul 15 02:27 esx_firstboot
-rwx------ 1 root root 0 Jul 15 02:27 firstboot_scripts_started
-rwx------ 1 root root 0 Jul 15 02:24 install_nic_drivers_with_reboot
-rwx------ 1 root root 0 Jul 15 02:29 install_vibs
-rwx------ 1 root root 0 Jul 15 02:23 nmlx5_rdma_disabled
-rwx------ 1 root root 0 Jul 15 02:24 passthru_map
-rwx------ 1 root root 0 Jul 15 02:27 scratch_created
-rwx------ 1 root root 0 Jul 15 02:27 uninstall_vibs
]]></ac:plain-text-body>
      </ac:structured-macro>
      <p>
        <span style="color: rgb(51,51,51);">During the ESXi first boot process, the presence of a marker file named </span>.firstboot_fail indicates that the esx_first_boot.py script encountered an error and did not complete successfully.</p>
      <p>
        <span style="letter-spacing: 0.0px;">Test Environment Details</span>
      </p>
      <p>
        <span> <strong>AOS Version:</strong> 7.0.1.5<br/>
          <strong>Foundation Version</strong>: foundation-5.7.1-b100e38c<br/>
          <strong>Hypervisor Version</strong>: 8.0.3-24022510<br/>
          <strong>HW Model:</strong> NX-1065-G8</span>
      </p>
      <p>
        <strong> <span style="color: rgb(51,51,51);"> <span style="font-size: 16.0px;letter-spacing: -0.006em;">Example: First Boot Script Failure Log</span> </span> </strong>
      </p>
      <p>In the example below, the<span> </span> <code>.firstboot_fail</code> <span> </span>file is present in the first boot directory, confirming a failure during execution:</p>
      <ac:structured-macro ac:macro-id="4254e9b3-7fbc-46b5-9dc8-354ca0f19d64" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:plain-text-body><![CDATA[[root@Failed-Install~]cd /bootbank/Nutanix/firstboot/
[root@Failed-Install:~] ls -al
total 62127
drwxr-xr-x    1 root     root             8 Jul 15 02:30 .
drwxr-xr-x    1 root     root             8 Jul 15 02:23 ..
-rwx------    1 root     root             0 Jul 15 02:30 .firstboot_fail  <<<<<<<<<<<<<
-rwx------    1 root     root             0 Jul 15 01:07 __init__.py
drwxr-xr-x    1 root     root             8 Jul 15 02:23 __pycache__
-rwx------    1 root     root          4028 Jul 15 01:07 auto_start.snip
-rwx------    1 root     root          4612 Jul 15 01:07 configure_network.py
-rwx------    1 root     root          1714 Jul 15 01:07 configure_nfs.sh
-rwx------    1 root     root          4743 Jul 15 01:07 consts.py
-rwx------    1 root     root          1001 Jul 15 01:07 create_scratch_part.sh
-rwx------    1 root     root          1243 Jul 15 01:07 create_vmfs_part.sh
-rwx------    1 root     root         11492 Jul 15 01:07 customize_svm_tar.py
-rwx------    1 root     root        114309 Jul 15 01:07 esx_first_boot.py
-rwx------    1 root     root         18863 Jul 15 02:30 esx_first_boot_launcher.log
-rwx------    1 root     root         38838 Jul 15 01:07 esx_util.py
-rwx------    1 root     root           232 Jul 15 02:19 factory_config.json
-rwx------    1 root     root          8284 Jul 15 02:18 fc_progress.py
-rwx------    1 root     root         40034 Jul 15 02:30 first_boot.log
-rwx------    1 root     root         15903 Jul 15 02:19 first_boot_config.json
-rwx------    1 root     root         11432 Jul 15 02:18 firstboot_utils.py
-rwx------    1 root     root             7 Jul 15 02:19 foundation_version
-rwx------    1 root     root          7446 Jul 15 02:19 hardware_config.json
-rwx------    1 root     root          5705 Jul 15 01:07 hba_quirks.py
-rwx------    1 root     root          8494 Jul 15 02:18 log.py
-rwx------    1 root     root          1217 Jul 15 02:18 passthru.map.snip
drwxr-xr-x    1 root     root             8 Jul 15 02:29 phases
-rwx------    1 root     root            22 Jul 15 02:19 phoenix_version
-rwx------    1 root     root          4164 Jul 15 02:18 ssh.tgz
drwxr-xr-x    1 root     root             8 Jul 15 02:23 ssh_keys
-rwx------    1 root     root      61995155 Jul 15 02:19 svm_template.tar.gz
-rwx------    1 root     root           342 Jul 15 01:07 welcome_message]]></ac:plain-text-body>
      </ac:structured-macro>
      <p>To investigate the cause of the failure, review the log files generated during the first boot process. These logs provide detailed output from each phase of the script execution:</p>
      <p>These logs are essential for troubleshooting and identifying the specific phase or operation that failed.</p>
      <h3>
        <strong>Log Location </strong>
      </h3>
      <p>/bootbank/first_boot.log<br/>OR<br/>/bootbank/Nutanix/firstboot/first_boot.log</p>
      <p>
        <br/>When the <code style="color: rgb(51,51,51);letter-spacing: 0.0px;">esx_first_boot.py</code> <span style="color: rgb(51,51,51);letter-spacing: 0.0px;"> script encounters a fatal error during execution, the failure is logged in </span> <code style="color: rgb(51,51,51);letter-spacing: 0.0px;">first_boot.log</code> <span style="color: rgb(51,51,51);letter-spacing: 0.0px;">. Below is a sample snippet from a failed installation:</span>
      </p>
      <ac:structured-macro ac:macro-id="13bd8215-fca2-464d-a31e-cb1b86d408ed" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">/bootbank/Nutanix/firstboot/first_boot.log</ac:parameter>
        <ac:plain-text-body><![CDATA[[root@Failed-Install~]cat /bootbank/Nutanix/firstboot/first_boot.log

2025-07-15 02:30:12,587 INFO  esx_util.py:929 Creating vmk nic and attaching to portgroup 'ntnx-internal-vmk'
2025-07-15 02:30:15,610 FATAL  esx_first_boot.py:3100 Fatal exception encountered:
Traceback (most recent call last):
  File "/bootbank/Nutanix/firstboot/esx_first_boot.py", line 3093, in <module>
    main()
  File "/bootbank/Nutanix/firstboot/esx_first_boot.py", line 2851, in main
    configure_host_common()
  File "/bootbank/Nutanix/firstboot/esx_first_boot.py", line 848, in configure_host_common
    configure_vswitches(passthru_nics=P_LIST.passthru_nics)
  File "/bootbank/Nutanix/firstboot/esx_first_boot.py", line 579, in configure_vswitches
    api.create_vmkernel_nic(pg["name"], vmk["ip"], vmk["netmask"])
  File "/vmfs/volumes/900d4956-8b4e3ad0-5cba-2a1c336ac949/Nutanix/firstboot/esx_util.py", line 938, in create_vmkernel_nic
    AddVirtualNic(portgroup=pg_name, nic=vmk)
  File "/lib64/python3.11/site-packages/pyVmomi/VmomiSupport.py", line 618, in <lambda>
  File "/lib64/python3.11/site-packages/pyVmomi/VmomiSupport.py", line 391, in _InvokeMethod
  File "/lib64/python3.11/site-packages/pyVmomi/SoapAdapter.py", line 1607, in InvokeMethod
pyVmomi.VmomiSupport.vmodl.fault.InvalidArgument: (vmodl.fault.InvalidArgument) {
   dynamicType = <unset>,
   dynamicProperty = (vmodl.DynamicProperty) [],
   msg = 'A specified parameter was not correct: Vim.Host.VirtualNic.Specification.Ip',
   faultCause = <unset>,
   faultMessage = (vmodl.LocalizableMessage) [],
   invalidProperty = 'Vim.Host.VirtualNic.Specification.Ip'
}

2025-07-15 02:30:15,611 INFO  firstboot_utils.py:88 Running cmd ['touch /bootbank/Nutanix/firstboot/.firstboot_fail']
2025-07-15 02:30:15,630 INFO  esx_first_boot.py:1689 Changing ESX hostname to 'Failed-Install'
2025-07-15 02:30:15,631 INFO  firstboot_utils.py:88 Running cmd ['esxcli system hostname set --fqdn Failed-Install']
2025-07-15 02:30:16,039 INFO  firstboot_utils.py:88 Running cmd ["kill $(ps | grep dcui | awk '{print $1}')"]
2025-07-15 02:30:16,099 INFO  firstboot_utils.py:88 Running cmd ['esxcli network ip interface ipv4 set -i vmk0 -I 10.24.137.32 -N 255.255.252.0 -t static']
2025-07-15 02:30:16,588 INFO  firstboot_utils.py:88 Running cmd ["esxcfg-vswitch -p 'Management Network' -v 0 vSwitch0"]
2025-07-15 02:30:16,639 INFO  firstboot_utils.py:88 Running cmd ['esxcfg-route 10.24.136.1']]]></ac:plain-text-body>
      </ac:structured-macro>
      <h3>
        <strong style="color: rgb(94,108,132);letter-spacing: 0.0px;">To re-run the ESXi First Boot Script:</strong>
      </h3>
      <p>If the <code>esx_first_boot.py</code> script fails during initial execution, you can manually re-run it after resolving the underlying issue. Follow the steps below:</p>
      <ol>
        <li>
          <p>Review first_boot.log and fix the issue that caused the script to fail.</p>
        </li>
      </ol>
      <pre>[root@Failed-Install:~] cat /bootbank/Nutanix/firstboot/first_boot.log</pre>
      <p>       2. Delete the<span> </span> <code>.firstboot_fail</code> <span> </span>marker file to allow the script to be re-executed:</p>
      <pre>[root@Failed-Install:~]rm /bootbank/Nutanix/firstboot/.firstboot_fail</pre>
      <p>       3. Navigate to the first boot directory and execute the script manually.</p>
      <pre>[root@Failed-Install:~] cd /bootbank/Nutanix/firstboot<br/>[root@Failed-Install:/vmfs/volumes/556a8545-a34f7553-4981-62599792afc6/Nutanix/firstboot]./esx_first_boot.py<br/>
        <br/>
      </pre>
      <strong> <span style="letter-spacing: 0.0px;color: rgb(51,51,51);">Example: Successful First Boot Script Log</span> </strong>
      <p>
        <span style="color: rgb(23,43,77);"> <span> <span style="color: rgb(66,66,66);">When the </span> <code>esx_first_boot.py</code> <span style="color: rgb(66,66,66);"> script completes successfully, the </span> <code>first_boot.log</code> <span style="color: rgb(66,66,66);"> file will contain a series of informational messages as shown below</span> <br/>
          </span> </span>
      </p>
      <ac:structured-macro ac:macro-id="ff7a7007-1614-4bc9-8f46-805f8aafa277" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">first_boot.log</ac:parameter>
        <ac:parameter ac:name="collapse">true</ac:parameter>
        <ac:plain-text-body><![CDATA[2025-07-15 07:00:01,599 INFO  esx_first_boot.py:1689 Changing ESX hostname to 'NTNX-21SM6N510296-B'
2025-07-15 07:00:01,601 INFO  firstboot_utils.py:88 Running cmd ['esxcli system hostname set --fqdn NTNX-21SM6N510296-B']
2025-07-15 07:00:02,026 INFO  firstboot_utils.py:88 Running cmd ['cp /bootbank/Nutanix/firstboot/welcome_message /etc/vmware/welcome']
2025-07-15 07:00:02,039 INFO  firstboot_utils.py:88 Running cmd ["kill $(ps | grep dcui | awk '{print $1}')"]
2025-07-15 07:00:02,091 INFO  firstboot_utils.py:88 Running cmd ['esxcfg-module -d nmlx5_rdma']
2025-07-15 07:00:03,313 INFO  esx_first_boot.py:94 Completed phase 'nmlx5_rdma_disabled'
2025-07-15 07:00:03,313 INFO  esx_first_boot.py:2528 Waiting for esxcli
2025-07-15 07:00:03,314 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib list']
2025-07-15 07:00:05,773 INFO  esx_first_boot.py:2538 Installing nic drivers which might require a reboot
2025-07-15 07:00:05,776 INFO  esx_first_boot.py:1703 Enumerating all PCI devices
2025-07-15 07:00:05,776 INFO  firstboot_utils.py:88 Running cmd ['lspci -n']
2025-07-15 07:00:05,827 INFO  esx_first_boot.py:2171 Installing Intel Ethernet i40en driver
2025-07-15 07:00:05,828 INFO  esx_first_boot.py:2114 Installing driver [/bootbank/Nutanix/firstboot/vibs/i40en_2.7.2.0-1OEM.800.1.0.20613240.vib]
2025-07-15 07:00:05,828 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /bootbank/Nutanix/firstboot/vibs/i40en_2.7.2.0-1OEM.800.1.0.20613240.vib']
2025-07-15 07:00:16,705 INFO  esx_first_boot.py:94 Completed phase 'driver_i40en_2.7.2.0-1OEM.800.1.0.20613240.vib'
2025-07-15 07:00:16,707 INFO  esx_first_boot.py:2171 Installing Intel E810 NIC controller driver
2025-07-15 07:00:16,707 INFO  esx_first_boot.py:2114 Installing driver [/bootbank/Nutanix/firstboot/vibs/icen_1.13.2.0-1OEM.800.1.0.20613240.vib]
2025-07-15 07:00:16,708 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /bootbank/Nutanix/firstboot/vibs/icen_1.13.2.0-1OEM.800.1.0.20613240.vib']
2025-07-15 07:00:29,488 INFO  esx_first_boot.py:94 Completed phase 'driver_icen_1.13.2.0-1OEM.800.1.0.20613240.vib'
2025-07-15 07:00:29,857 INFO  esx_first_boot.py:94 Completed phase 'install_nic_drivers_with_reboot'
2025-07-15 07:00:29,858 INFO  hba_quirks.py:71 HBA Device type is 1000:00e6
2025-07-15 07:00:29,858 INFO  hba_quirks.py:71 HBA Device type is 8086:28c0
2025-07-15 07:00:29,859 DEBUG  hba_quirks.py:74 Create new instance of HBA Quirk.
2025-07-15 07:00:29,859 INFO  hba_quirks.py:156 For Icelake and VMD Passthrough, adding in passthru.map and requesting reboot.
2025-07-15 07:00:29,859 DEBUG  esx_first_boot.py:2577 Found quirk for 8086:28c0 HBA
2025-07-15 07:00:29,859 DEBUG  esx_first_boot.py:2584 Found current HBAs: {'1000:00e6', '8086:28c0'}.
2025-07-15 07:00:29,859 DEBUG  esx_first_boot.py:2586 Reboot may be required due to HBAs: {'8086:28c0'}.
2025-07-15 07:00:29,859 DEBUG  esx_first_boot.py:2587 These HBAs don't need reset due to current ESXi improvements: set().
2025-07-15 07:00:29,860 INFO  esx_first_boot.py:2592 Reboot is required to make {'8086:28c0'} available for passthrough.
2025-07-15 07:00:31,136 INFO  esx_first_boot.py:94 Completed phase 'passthru_map'
2025-07-15 07:00:31,514 INFO  esx_first_boot.py:94 Completed phase 'disable_vmd_vibs'
2025-07-15 07:03:42,073 INFO  esx_first_boot.py:1689 Changing ESX hostname to 'NTNX-21SM6N510296-B'
2025-07-15 07:03:42,074 INFO  firstboot_utils.py:88 Running cmd ['esxcli system hostname set --fqdn NTNX-21SM6N510296-B']
2025-07-15 07:03:42,431 INFO  firstboot_utils.py:88 Running cmd ['cp /bootbank/Nutanix/firstboot/welcome_message /etc/vmware/welcome']
2025-07-15 07:03:42,449 INFO  firstboot_utils.py:88 Running cmd ["kill $(ps | grep dcui | awk '{print $1}')"]
2025-07-15 07:03:42,502 INFO  firstboot_utils.py:88 Running cmd ['/bin/sh /esx_host_cfg.sh']
2025-07-15 07:03:48,094 INFO  esx_first_boot.py:94 Completed phase 'esx_firstboot'
2025-07-15 07:03:48,094 INFO  firstboot_utils.py:88 Running cmd ['/etc/init.d/ntpd stop >/dev/null 2>&1']
2025-07-15 07:03:51,127 INFO  esx_util.py:442 Denying service 'ntpClient' in host firewall
2025-07-15 07:03:51,575 INFO  esx_first_boot.py:94 Completed phase 'firstboot_scripts_started'
2025-07-15 07:03:51,937 INFO  esx_first_boot.py:94 Completed phase 'apply_licenses'
2025-07-15 07:03:51,939 INFO  esx_first_boot.py:2724 first_boot_config.json =
{
  "hyp_type": "esx",
  "hyp_version": "8.0.3",
  "hyp_distro": null,
  "hypervisor_iso_url": null,
  "hypervisor_iso_path": "/mnt/local/images/hypervisor/esx/VMware-VMvisor-Installer-8.0U3-24022510.x86_64.iso",
  "iso_whitelist_path": null,
  "svmboot_iso_path": "/mnt/svm_installer/install/images/svmboot.iso",
  "model": "USE_LAYOUT",
  "model_string": "NX-1065-G8",
  "node_position": "B",
  "node_name": "21SM6N510296-B",
  "svm_version": "7.0.1.5",
  "nos_version": "7.0.1.5",
  "block_id": "21SM6N510296",
  "cluster_name": "NTNX",
  "node_serial": "HM219S013990",
  "node_uuid": "c97c1ce5-4f32-4317-a721-1d3cc663d53c",
  "cluster_id": 2157854159792320458,
  "hyp_install_type": "clean",
"svm_install_type": null,
  "delete_fb_on_success": true,
  "monitoring_url_root": null,
  "monitoring_url_retry_count": null,
  "monitoring_url_timeout_secs": null,
  "fc_imaged_node_uuid": null,
  "fc_deployment_uuid": null,
  "fc_phx_wf": false,
  "fc_settings": null,
  "vswitches": [],
  "host_interfaces": [],
  "cvm_interfaces": [],
  "host_ip": "10.24.137.32",
  "host_subnet_mask": "255.255.252.0",
  "svm_ip": "10.24.138.32",
  "svm_subnet_mask": "255.255.252.0",
  "svm_default_gw": "10.24.136.1",
  "svm_gb_ram": 20,
  "user_passed_svm_gb_ram": false,
  "svm_numa_nodes": [
    0
  ],
  "svm_num_vcpus": 12,
  "is_svm_vcpus_static_placement": true,
  "default_gw": "10.24.136.1",
  "dns_ip": "",
  "crypt_password": null,
  "boot_disk": "nvme0n1",
  "boot_disk_sz_sectors": 1000083456,
  "boot_disk_sz_GB": 512.042729472,
  "exclude_nvmes_from_passthru": [],
  "volume_boot_drives": [],
  "volume_sz_GB": null,
  "volume_disks_sn": {},
  "volume_name": null,
  "ptable_end_sector": 1000083456,
  "partition_table_type": "gpt",
  "storage_passthru": true,
  "use_vmfs_datastore": true,
  "use_vmdk_svm_disk": false,
  "use_ten_gig_only": false,
  "network_devices": {
    "eth4": {
  "vendor_id": "8086",
      "device_id": "104e",
      "vendor_string": "Intel",
      "mac_addr": "3c:ec:ef:62:9b:a0"
    },
    "eth2": {
      "vendor_id": "8086",
      "device_id": "15ff",
      "vendor_string": "Intel",
      "mac_addr": "3c:ec:ef:62:9b:9e"
    },
    "eth0": {
      "vendor_id": "8086",
      "device_id": "158b",
      "vendor_string": "Intel",
      "mac_addr": "40:a6:b7:77:02:94"
    },
    "eth5": {
      "vendor_id": "8086",
      "device_id": "104e",
      "vendor_string": "Intel",
      "mac_addr": "3c:ec:ef:62:9b:a1"
    },
    "eth3": {
      "vendor_id": "8086",
      "device_id": "15ff",
      "vendor_string": "Intel",
      "mac_addr": "3c:ec:ef:62:9b:9f"
    },
    "eth1": {
      "vendor_id": "8086",
      "device_id": "158b",
      "vendor_string": "Intel",
      "mac_addr": "40:a6:b7:77:02:95"
    }
  },
  "fio_detected": false,
  "installer_path": "/mnt/nos_from_svm/7.0.1.5/nutanix_installer_package.tar",
  "factory_iso_path": null,
  "factory_iso_size": null,
  "factory_iso_offset": null,
  "hyp_image_path": null,
  "bootbank": 5,
  "vibs": [],
  "hyperv_binaries": null,
  "rpms": [],
  "driver_package": "/tmp/drivers/driver_package.tar.gz",
  "driver_config": {
    "hyp_versions": [
      "8.0.0",
      "8.0.1",
      "8.0.2",
      "8.0.3"
    ],
    "vendor_name": "smc",
    "drivers": [
      {
        "file_name": "nfs-vaai-plugin-3.0-44d2a400.vib",
        "md5sum": "042b679e03e4d853a1dd898c6578e86d"
},
      {
        "file_name": "ixgben_1.18.2.0-1OEM.800.1.0.20613240.vib",
        "md5sum": "c57142129b874fea11a4787402f5e25f"
      },
      {
        "file_name": "NTX_bootbank_ntx-esxi-1-ipmitool_1.0-01.vib",
        "md5sum": "8d8796cfbe6acc2f8a00ebfa1d06a29b",
        "install_path": "/opt/nutanix/bin/ipmitool",
        "symlink_name": "/ipmitool"
      },
      {
        "file_name": "NTX_bootbank_ntx-esxi-01-smartctlcmd_1.0-01.vib",
        "md5sum": "453d18d82065d3239fd3d21cf917e384",
        "install_path": "/opt/nutanix/bin/smartctlcmd",
        "symlink_name": "/smartctl_cmd"
      },
      {
        "file_name": "SMC_bootbank_smc-esxi-01-ipmicfg_1.0-01.vib",
        "md5sum": "bef91ddc821a02a4f6acfc9a66744a3c",
        "install_path": "/opt/supermicro/ipmicfg/ipmicfg",
        "symlink_name": "/ipmicfg"
      },
      {
        "file_name": "i40en_2.7.2.0-1OEM.800.1.0.20613240.vib",
        "platform_requirements": {
          "reboot_only_for_pci_ids": [
            "8086:158b"
          ]
        },
        "md5sum": "51cfdfb381b07d5499788ae839605ea3",
        "friendly_name": "Intel Ethernet i40en",
        "tags": [
          "nic_driver_with_reboot"
        ]
      },
      {
        "file_name": "BCM_bootbank_lsi-mr3_7.717.04.00-1OEM.700.1.0.15843807.vib",
        "md5sum": "f7d185678ba6efffeb395e1b534288e0",
        "friendly_name": "Broadcom SAS-RAID driver",
        "tags": [
  "nested_cluster_only"
        ]
      },
      {
        "file_name": "BCM_bootbank_bnxtnet_226.0.121.0-1OEM.800.1.0.20613240.vib",
        "md5sum": "738dc77b01c8b7af068f757b9466deb6"
      },
      {
        "file_name": "icen_1.13.2.0-1OEM.800.1.0.20613240.vib",
        "platform_requirements": {
          "reboot_only_for_pci_ids": [
            "8086:1590",
            "8086:1591",
            "8086:1592",
            "8086:1593",
            "8086:1599",
            "8086:159a",
            "8086:159b"
          ]
        },
        "md5sum": "b9e98167c88c04254428ad064d39439a",
        "friendly_name": "Intel E810 NIC controller",
        "tags": [
          "nic_driver_with_reboot"
        ]
      }
    ]
  },
  "phoenix_version": "phoenix-5.7.1_b100e38c",
  "foundation_version": "unknown",
  "foundation_ip": null,
  "hypervisor_hostname": null,
  "skip_hypervisor": false,
  "cvm_vlan_id": "0",
  "factory_megaraid_adapter": null,
  "factory_hyp_lun_label": null,
  "factory_hyp_lun_index": null,
  "factory_lun_label": null,
  "factory_lun_index": null,
  "factory_phoenix_lun_label": null,
  "factory_phoenix_lun_index": null,
  "factory_error_flag_file": null,
  "factory_success_flag_file": null,
  "factory_logfile_info": null,
  "factory_logfile_error": null,
  "factory_hyp_image": null,
  "factory_run_level": 0,
  "factory_folder": null,
  "megaraid_boot_device": true,
"factory_partition_label": null,
  "factory_hypervisors_location": [],
  "factory_drivers_location": [],
  "ce_hyp_boot_disk": null,
  "ce_cvm_boot_disks": [],
  "ce_cvm_data_disks": [],
  "ce_eula_accepted": false,
  "ce_eula_viewed": false,
  "create_1node_cluster": false,
  "ce_disks": [],
  "esx_path": "",
  "ce_serials": [],
  "ce_wwns": [],
  "passthru_devs": [
    "32:00.0",
    "c9:00.5",
    "e2:00.5"
  ],
  "per_node_ntp_servers": "0.north-america.pool.ntp.org,1.north-america.pool.ntp.org,2.north-america.pool.ntp.org,3.north-america.pool.ntp.org",
  "vpd_method": null,
  "use_hugetlbfs": false,
  "foundation_payload": null,
  "host_backplane_ip": null,
  "passthru_nvme_devices": [],
  "exclude_boot_serial": null,
  "eos_metadata": null,
  "compute_only": false,
  "passthru_nics": [],
  "rdma_passthrough": false,
  "rdma_mac_addr": null,
  "rdma_port_passthrough": false,
  "hyperv_external_vswitch": null,
  "hyperv_external_vswitch_alias": null,
  "hyperv_sku": null,
  "hook_scripts": {},
  "custom_ahv_kernel": null,
  "custom_linux_kernel": null,
  "custom_cvm_kernel": null,
  "http_proxy": [],
  "is_secureboot": false,
  "is_factory": false,
  "hyp_installed_in_vm": false,
  "svm_rescue_args": [],
  "pmem": {},
  "hyperv_driver_spec_enabled": false,
  "hypervisor_licenses": [],
  "ucs_fabric_interconnect_enabled": false,
  "cvm_config": {},
  "cvm_devices": {},
  "enable_ipv6": false,
  "foundation_ipv6_address": null,
  "root_crypt_password": null,
  "enable_luks": false,
  "nutant_user_data": {},
  "boot_disk_info": null,
  "boot_disk_model": "Marvell_NVMe_Controller",
  "scratch_present": false,
  "vmfs_present": false,
  "altbootbank": 6
2025-07-15 07:03:52,314 INFO  esx_first_boot.py:94 Completed phase 'dump_first_boot_config'
2025-07-15 07:03:52,314 INFO  firstboot_utils.py:88 Running cmd ['/sbin/vsish -e set /net/tcpip/instances/defaultTcpipStack/sysctl/_net_inet_tcp_delayed_ack 0']
2025-07-15 07:03:52,335 INFO  esx_first_boot.py:2750 Setting maxIntrCookies to 4096
2025-07-15 07:03:52,336 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings kernel set -s maxIntrCookies -v 4096']
2025-07-15 07:03:52,781 INFO  esx_first_boot.py:2753 Disabling vmk0 network during installation process
2025-07-15 07:03:52,783 INFO  firstboot_utils.py:88 Running cmd ['esxcli network ip interface ipv4 set -i vmk0 -I 10.24.137.32 -N 255.255.252.0 -t static']
2025-07-15 07:03:55,341 INFO  firstboot_utils.py:88 Running cmd ["esxcfg-vswitch -p 'Management Network' -v 0 vSwitch0"]
2025-07-15 07:03:55,391 INFO  firstboot_utils.py:88 Running cmd ['esxcfg-route 10.24.136.1']
2025-07-15 07:03:56,575 INFO  esx_first_boot.py:94 Completed phase 'disable_network'
2025-07-15 07:03:56,575 INFO  firstboot_utils.py:88 Running cmd ['localcli system uuid get']
2025-07-15 07:03:56,821 INFO  esx_first_boot.py:2762 Obtained 6875f6ff-9931-0842-f1b3-3cecef629ba0 as uuid of the system
2025-07-15 07:03:57,915 INFO  esx_first_boot.py:94 Completed phase 'scratch_created'
2025-07-15 07:03:57,915 INFO  firstboot_utils.py:88 Running cmd ['mkdir -p /scratch/Nutanix']
2025-07-15 07:03:57,942 INFO  esx_first_boot.py:1836 Conserving space in bootbank. Moving vibs to /scratch/Nutanix/vibs
2025-07-15 07:03:57,944 INFO  firstboot_utils.py:88 Running cmd ['mv /bootbank/Nutanix/firstboot/vibs /scratch/Nutanix/vibs']
2025-07-15 07:03:58,369 INFO  esx_first_boot.py:94 Completed phase 'conserve_bootbank_space'
2025-07-15 07:03:58,371 INFO  esx_first_boot.py:2809 Removing vibs: ['lsi-msgpt2', 'scsi-mptsas', 'lsi-mr3'] as they are not required
2025-07-15 07:03:58,371 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib remove -n lsi-msgpt2']
2025-07-15 07:04:09,712 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib remove -n scsi-mptsas']
2025-07-15 07:04:13,022 INFO  firstboot_utils.py:128 Execution of command ['esxcli software vib remove -n scsi-mptsas'] failed, exit code: 1, stdout:  [NoMatchError]
 No VIB matching VIB search specification 'scsi-mptsas'.
 Please refer to the log file for more details.
, stderr:
2025-07-15 07:04:18,026 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib remove -n lsi-mr3']
2025-07-15 07:04:30,585 INFO  esx_first_boot.py:94 Completed phase 'uninstall_vibs'
2025-07-15 07:04:30,587 INFO  esx_first_boot.py:2822 Installing important drivers
2025-07-15 07:04:30,588 INFO  esx_first_boot.py:2171 Installing nfs-vaai-plugin-3.0-44d2a400.vib driver
2025-07-15 07:04:30,588 INFO  esx_first_boot.py:2114 Installing driver [/scratch/Nutanix/vibs/nfs-vaai-plugin-3.0-44d2a400.vib]
2025-07-15 07:04:30,588 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /scratch/Nutanix/vibs/nfs-vaai-plugin-3.0-44d2a400.vib']
2025-07-15 07:04:43,483 INFO  esx_first_boot.py:94 Completed phase 'driver_nfs-vaai-plugin-3.0-44d2a400.vib'
2025-07-15 07:04:43,485 INFO  esx_first_boot.py:2171 Installing ixgben_1.18.2.0-1OEM.800.1.0.20613240.vib driver
2025-07-15 07:04:43,486 INFO  esx_first_boot.py:2114 Installing driver [/scratch/Nutanix/vibs/ixgben_1.18.2.0-1OEM.800.1.0.20613240.vib]
2025-07-15 07:04:43,486 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /scratch/Nutanix/vibs/ixgben_1.18.2.0-1OEM.800.1.0.20613240.vib']
2025-07-15 07:04:56,371 INFO  esx_first_boot.py:94 Completed phase 'driver_ixgben_1.18.2.0-1OEM.800.1.0.20613240.vib'
2025-07-15 07:04:56,373 INFO  esx_first_boot.py:2171 Installing NTX_bootbank_ntx-esxi-1-ipmitool_1.0-01.vib driver
2025-07-15 07:04:56,373 INFO  esx_first_boot.py:2114 Installing driver [/scratch/Nutanix/vibs/NTX_bootbank_ntx-esxi-1-ipmitool_1.0-01.vib]
2025-07-15 07:04:56,373 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /scratch/Nutanix/vibs/NTX_bootbank_ntx-esxi-1-ipmitool_1.0-01.vib']
2025-07-15 07:05:09,338 INFO  esx_first_boot.py:94 Completed phase 'driver_NTX_bootbank_ntx-esxi-1-ipmitool_1.0-01.vib'
2025-07-15 07:05:09,341 INFO  esx_first_boot.py:2171 Installing NTX_bootbank_ntx-esxi-01-smartctlcmd_1.0-01.vib driver
2025-07-15 07:05:09,341 INFO  esx_first_boot.py:2114 Installing driver [/scratch/Nutanix/vibs/NTX_bootbank_ntx-esxi-01-smartctlcmd_1.0-01.vib]
2025-07-15 07:05:09,342 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /scratch/Nutanix/vibs/NTX_bootbank_ntx-esxi-01-smartctlcmd_1.0-01.vib']
2025-07-15 07:05:22,326 INFO  esx_first_boot.py:94 Completed phase 'driver_NTX_bootbank_ntx-esxi-01-smartctlcmd_1.0-01.vib'
2025-07-15 07:05:22,328 INFO  esx_first_boot.py:2171 Installing SMC_bootbank_smc-esxi-01-ipmicfg_1.0-01.vib driver
2025-07-15 07:05:22,328 INFO  esx_first_boot.py:2114 Installing driver [/scratch/Nutanix/vibs/SMC_bootbank_smc-esxi-01-ipmicfg_1.0-01.vib]
2025-07-15 07:05:22,328 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /scratch/Nutanix/vibs/SMC_bootbank_smc-esxi-01-ipmicfg_1.0-01.vib']
2025-07-15 07:05:35,736 INFO  esx_first_boot.py:94 Completed phase 'driver_SMC_bootbank_smc-esxi-01-ipmicfg_1.0-01.vib'
2025-07-15 07:05:35,738 INFO  esx_first_boot.py:2171 Installing BCM_bootbank_bnxtnet_226.0.121.0-1OEM.800.1.0.20613240.vib driver
2025-07-15 07:05:35,738 INFO  esx_first_boot.py:2114 Installing driver [/scratch/Nutanix/vibs/BCM_bootbank_bnxtnet_226.0.121.0-1OEM.800.1.0.20613240.vib]
2025-07-15 07:05:35,738 INFO  firstboot_utils.py:88 Running cmd ['esxcli software vib install --maintenance-mode -v /scratch/Nutanix/vibs/BCM_bootbank_bnxtnet_226.0.121.0-1OEM.800.1.0.20613240.vib']
2025-07-15 07:05:48,809 INFO  esx_first_boot.py:94 Completed phase 'driver_BCM_bootbank_bnxtnet_226.0.121.0-1OEM.800.1.0.20613240.vib'
2025-07-15 07:05:49,159 INFO  esx_first_boot.py:94 Completed phase 'install_vibs'
2025-07-15 07:05:49,159 INFO  esx_first_boot.py:2850 Configuring ESX host
2025-07-15 07:05:49,160 INFO  esx_util.py:986 Collecting information for all attached physical NICs.
2025-07-15 07:05:49,161 INFO  esx_util.py:90 Connecting to host 'localhost' with user 'root'
2025-07-15 07:05:52,253 INFO  esx_first_boot.py:436 Checking for passthrough nics
2025-07-15 07:05:52,253 INFO  esx_first_boot.py:453 Checking for USB Ethernet devices.
:2025-07-15 07:05:55,255 INFO  esx_util.py:525 Gathering vswitch objects
2025-07-15 07:05:58,276 INFO  esx_util.py:844 Gathering portgroup objects
2025-07-15 07:05:58,291 INFO  esx_first_boot.py:544 Configuring vswitch vSwitch0
2025-07-15 07:06:10,353 INFO  esx_util.py:654 Physical NIC 'vmnic0' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:10,363 INFO  esx_util.py:654 Physical NIC 'vmnic1' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:10,374 INFO  esx_util.py:654 Physical NIC 'vmnic2' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:10,383 INFO  esx_util.py:654 Physical NIC 'vmnic3' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:10,394 INFO  esx_util.py:654 Physical NIC 'vmnic4' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:10,404 INFO  esx_util.py:654 Physical NIC 'vmnic5' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:19,478 INFO  esx_util.py:855 Creating portgroup 'Backplane Network' and attaching to vswitch 'vSwitch0'
2025-07-15 07:06:22,515 INFO  esx_first_boot.py:592 Will choose among dict_keys(['vmnic0', 'vmnic1', 'vmnic2', 'vmnic3', 'vmnic4', 'vmnic5']) for active NIC for switch vSwitch0
2025-07-15 07:06:28,556 INFO  esx_util.py:654 Physical NIC 'vmnic0' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:28,567 INFO  esx_util.py:654 Physical NIC 'vmnic1' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:28,576 INFO  esx_util.py:654 Physical NIC 'vmnic2' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:28,586 INFO  esx_util.py:654 Physical NIC 'vmnic3' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:28,595 INFO  esx_util.py:654 Physical NIC 'vmnic4' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:28,604 INFO  esx_util.py:654 Physical NIC 'vmnic5' is already attached to vSwitch 'vSwitch0'.
2025-07-15 07:06:37,744 INFO  esx_util.py:759 Setting vSwitch NIC failover policy for vswitch 'vSwitch0' to: active_nics=['vmnic0'], standby_nics=['vmnic1', 'vmnic2', 'vmnic3', 'vmnic4', 'vmnic5']
2025-07-15 07:06:43,766 INFO  esx_util.py:778 Adding NIC vmnic0 to activeNic policy
2025-07-15 07:06:43,767 INFO  esx_util.py:778 Adding NIC vmnic1 to standbyNic policy
2025-07-15 07:06:43,767 INFO  esx_util.py:778 Adding NIC vmnic2 to standbyNic policy
2025-07-15 07:06:43,767 INFO  esx_util.py:778 Adding NIC vmnic3 to standbyNic policy
2025-07-15 07:06:43,767 INFO  esx_util.py:778 Adding NIC vmnic4 to standbyNic policy
2025-07-15 07:06:43,767 INFO  esx_util.py:778 Adding NIC vmnic5 to standbyNic policy
2025-07-15 07:06:46,825 INFO  esx_first_boot.py:544 Configuring vswitch vSwitchNutanix
2025-07-15 07:06:50,068 INFO  esx_util.py:855 Creating portgroup 'ntnx-internal-vmk' and attaching to vswitch 'vSwitchNutanix'
2025-07-15 07:06:53,095 INFO  esx_util.py:929 Creating vmk nic and attaching to portgroup 'ntnx-internal-vmk'
2025-07-15 07:06:56,226 INFO  esx_util.py:913 Disabling vmkernel interface feature 'vmotion' for 'vmk1'
2025-07-15 07:06:56,250 INFO  esx_util.py:913 Disabling vmkernel interface feature 'management' for 'vmk1'
2025-07-15 07:06:56,258 INFO  esx_util.py:913 Disabling vmkernel interface feature 'faultToleranceLogging' for 'vmk1'
2025-07-15 07:06:56,272 INFO  esx_util.py:855 Creating portgroup 'ntnx-internal-pg' and attaching to vswitch 'vSwitchNutanix'
2025-07-15 07:06:59,299 INFO  esx_util.py:902 Enabling vmkernel interface feature 'vmotion' for 'vmk0'
2025-07-15 07:06:59,336 INFO  esx_util.py:902 Enabling vmkernel interface feature 'management' for 'vmk0'
2025-07-15 07:07:00,455 INFO  esx_first_boot.py:94 Completed phase 'configure_vswitches'
2025-07-15 07:07:03,459 INFO  esx_util.py:427 Allowing service 'sshClient' in host firewall
2025-07-15 07:07:04,998 INFO  esx_first_boot.py:94 Completed phase 'tsm_ssh'
2025-07-15 07:07:05,755 INFO  esx_first_boot.py:94 Completed phase 'esxi_shell'
2025-07-15 07:07:08,758 INFO  esx_util.py:442 Denying service 'vprobeServer' in host firewall
2025-07-15 07:07:08,773 ERROR  esx_util.py:446 Service 'vprobeServer' was not found
2025-07-15 07:07:08,773 INFO  firstboot_utils.py:88 Running cmd ['/etc/init.d/storageRM stop']
2025-07-15 07:07:08,814 INFO  firstboot_utils.py:88 Running cmd ['chkconfig storageRM off']
2025-07-15 07:07:08,837 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /Misc/APDHandlingEnable -i 1']
2025-07-15 07:07:09,245 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /NFS/HeartbeatTimeout -i 30']
2025-07-15 07:07:09,640 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /NFS/MaxVolumes -i 64']
2025-07-15 07:07:10,038 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /Net/TcpipHeapSize -i 32']
2025-07-15 07:07:10,375 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /Power/UseCStates -i 0']
2025-07-15 07:07:10,766 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /Net/TcpipHeapMax -i 512']
2025-07-15 07:07:11,160 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /UserVars/SuppressShellWarning -i 1']
2025-07-15 07:07:11,561 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings advanced set -o /SunRPC/MaxConnPerIP -i 64']
2025-07-15 07:07:13,116 INFO  esx_first_boot.py:94 Completed phase 'adv_params'
2025-07-15 07:07:16,120 INFO  esx_util.py:392 Applying passthru for devices ['0000:32:00.0', '0000:c9:00.5', '0000:e2:00.5']
:2025-07-15 07:07:17,436 INFO  esx_first_boot.py:94 Completed phase 'passthru_devs'
2025-07-15 07:07:17,438 INFO  esx_first_boot.py:2874 Disabling driver rste
2025-07-15 07:07:17,438 INFO  firstboot_utils.py:88 Running cmd ['/sbin/esxcfg-module -d rste']
2025-07-15 07:07:17,496 INFO  esx_first_boot.py:2874 Disabling driver mpt2sas
2025-07-15 07:07:17,497 INFO  firstboot_utils.py:88 Running cmd ['/sbin/esxcfg-module -d mpt2sas']
2025-07-15 07:07:17,544 INFO  firstboot_utils.py:128 Execution of command ['/sbin/esxcfg-module -d mpt2sas'] failed, exit code: 1, stdout: , stderr: Unknown module name mpt2sas
2025-07-15 07:07:22,547 INFO  esx_first_boot.py:2874 Disabling driver lsi_msgpt3
2025-07-15 07:07:22,548 INFO  firstboot_utils.py:88 Running cmd ['/sbin/esxcfg-module -d lsi_msgpt3']
2025-07-15 07:07:23,764 INFO  esx_first_boot.py:94 Completed phase 'disable_drivers'
2025-07-15 07:07:23,765 INFO  esx_first_boot.py:2881 Enabling wbem, this will start sfcbd-watchdog
2025-07-15 07:07:23,765 INFO  firstboot_utils.py:88 Running cmd ['esxcli system wbem set --enable true']
2025-07-15 07:07:26,336 INFO  esx_first_boot.py:94 Completed phase 'sfcbd_watchdog'
2025-07-15 07:07:26,338 INFO  esx_first_boot.py:937 Creating VMFS partition and mounting it on datastore NTNX-local-ds-21SM6N510296-B
2025-07-15 07:07:26,339 INFO  firstboot_utils.py:88 Running cmd ['vmkfstools -P /vmfs/volumes/0a0e8175-3647a2c1-52ba-55dca3d9ffdd']
2025-07-15 07:07:26,385 INFO  firstboot_utils.py:88 Running cmd ['partedUtil getptbl /dev/disks/t10.NVMe____Marvell_NVMe_Controller_________________01000002C9435000']
2025-07-15 07:07:26,417 INFO  esx_first_boot.py:771 Partition size not specified.  Defaulting to use remaining space on disk: 731645985 sectors
2025-07-15 07:07:26,418 INFO  esx_first_boot.py:779 Not enough space on disk for a partition of 731645985 sectors but strict flag was not specified so defaulting to using remaining space of 731645985 sectors.
2025-07-15 07:07:26,418 INFO  firstboot_utils.py:88 Running cmd ['partedUtil setptbl "/dev/disks/t10.NVMe____Marvell_NVMe_Controller_________________01000002C9435000" gpt "1 64 204863 C12A7328F81F11D2BA4B00A0C93EC93B 128" "5 208896 8595455 EBD0A0A2B9E5443387C068B6B72699C7 0" "6 8597504 16984063 EBD0A0A2B9E5443387C068B6B72699C7 0" "7 16986112 268435422 4EB2EA3978554790A79EFAE495E21F8D 0" "8 268435423 1000081408 AA31E02A400F11DB9590000C2911D1B8 0"']
2025-07-15 07:07:26,441 INFO  firstboot_utils.py:88 Running cmd ['vmkfstools -C vmfs5 -b 1m -S NTNX-local-ds-21SM6N510296-B "/dev/disks/t10.NVMe____Marvell_NVMe_Controller_________________01000002C9435000:8"']
2025-07-15 07:07:26,683 INFO  esx_first_boot.py:794 Created new partition with UUID: 6875fe2e-d31e3839-e75e-40a6b7770294
2025-07-15 07:07:27,824 INFO  esx_first_boot.py:94 Completed phase 'create_vmfs_datastore'
2025-07-15 07:07:27,834 INFO  firstboot_utils.py:88 Running cmd ['tar xvzf /bootbank/Nutanix/firstboot/ssh.tgz -C /']
2025-07-15 07:07:28,967 INFO  esx_first_boot.py:94 Completed phase 'deploy_ssh_keys'
2025-07-15 07:07:30,094 INFO  esx_first_boot.py:94 Completed phase 'modify_sshd_config'
2025-07-15 07:07:31,203 INFO  esx_first_boot.py:94 Completed phase 'update_altbootbank'
2025-07-15 07:07:31,204 INFO  esx_first_boot.py:2967 Rebooting system. This may take several minutes
2025-07-15 07:07:32,325 INFO  esx_first_boot.py:94 Completed phase 'first_boot'
2025-07-15 07:10:44,424 INFO  esx_first_boot.py:1689 Changing ESX hostname to 'NTNX-21SM6N510296-B'
2025-07-15 07:10:44,425 INFO  firstboot_utils.py:88 Running cmd ['esxcli system hostname set --fqdn NTNX-21SM6N510296-B']
2025-07-15 07:10:44,837 INFO  firstboot_utils.py:88 Running cmd ['cp /bootbank/Nutanix/firstboot/welcome_message /etc/vmware/welcome']
2025-07-15 07:10:44,861 INFO  firstboot_utils.py:88 Running cmd ["kill $(ps | grep dcui | awk '{print $1}')"]
2025-07-15 07:10:44,920 INFO  firstboot_utils.py:88 Running cmd ['/etc/init.d/ntpd stop >/dev/null 2>&1']
2025-07-15 07:10:47,960 INFO  esx_util.py:442 Denying service 'ntpClient' in host firewall
2025-07-15 07:10:48,088 DEBUG  esx_first_boot.py:2727 first_boot_config.json was dumped, skipping
2025-07-15 07:10:48,088 INFO  firstboot_utils.py:88 Running cmd ['/sbin/vsish -e set /net/tcpip/instances/defaultTcpipStack/sysctl/_net_inet_tcp_delayed_ack 0']
2025-07-15 07:10:48,111 INFO  esx_first_boot.py:2750 Setting maxIntrCookies to 4096
2025-07-15 07:10:48,112 INFO  firstboot_utils.py:88 Running cmd ['esxcli system settings kernel set -s maxIntrCookies -v 4096']
2025-07-15 07:10:48,462 INFO  esx_first_boot.py:2753 Disabling vmk0 network during installation process
2025-07-15 07:10:48,463 INFO  firstboot_utils.py:88 Running cmd ['localcli system uuid get']
2025-07-15 07:10:48,714 INFO  esx_first_boot.py:2762 Obtained 6875f6ff-9931-0842-f1b3-3cecef629ba0 as uuid of the system
2025-07-15 07:10:48,716 INFO  firstboot_utils.py:88 Running cmd ['mkdir -p /scratch/Nutanix']
2025-07-15 07:10:48,732 INFO  esx_first_boot.py:2850 Configuring ESX host
2025-07-15 07:10:51,736 INFO  esx_util.py:442 Denying service 'vprobeServer' in host firewall
2025-07-15 07:10:51,747 ERROR  esx_util.py:446 Service 'vprobeServer' was not found
2025-07-15 07:10:51,747 INFO  firstboot_utils.py:88 Running cmd ['/etc/init.d/storageRM stop']
2025-07-15 07:10:51,768 INFO  firstboot_utils.py:88 Running cmd ['chkconfig storageRM off']
2025-07-15 07:10:51,794 INFO  esx_first_boot.py:948 Customizing SVM vmx from template
2025-07-15 07:10:51,795 INFO  esx_first_boot.py:2028 This node uses VMD in CVM.
2025-07-15 07:10:51,795 INFO  firstboot_utils.py:88 Running cmd ['python /bootbank/Nutanix/firstboot/customize_svm_tar.py -i /bootbank/Nutanix/firstboot/svm_template.tar.gz -u 6875f6ff-9931-0842-f1b3-3cecef629ba0 -o /tmp/svmboot.tar.gz -d INSTALLING -n ServiceVM_Centos --hardware-version 20 --pci-hole-range 2048']
2025-07-15 07:10:56,926 INFO  esx_first_boot.py:990 Deleting /bootbank/Nutanix/firstboot/svm_template.tar.gz
2025-07-15 07:10:56,928 INFO  esx_first_boot.py:996 Untarring the svmboot.tar.gz that was created earlier
2025-07-15 07:10:56,928 INFO  firstboot_utils.py:88 Running cmd ['tar -C /vmfs/volumes/NTNX-local-ds-21SM6N510296-B -xvzf /tmp/svmboot.tar.gz']
2025-07-15 07:10:59,023 INFO  esx_first_boot.py:94 Completed phase 'customize_svm_template'
2025-07-15 07:10:59,024 INFO  esx_first_boot.py:2314 Configuring pynfs datastore
2025-07-15 07:10:59,024 INFO  firstboot_utils.py:88 Running cmd ['/bin/sh /bootbank/Nutanix/firstboot/configure_nfs.sh 6875f6ff-9931-0842-f1b3-3cecef629ba0 NTNX-local-ds-21SM6N510296-B']
2025-07-15 07:11:00,160 INFO  esx_first_boot.py:94 Completed phase 'pynfs_datastore'
2025-07-15 07:11:00,160 INFO  esx_first_boot.py:2299 Registering the SVM
2025-07-15 07:11:03,163 INFO  esx_util.py:171 Registering VM - [NTNX-local-ds-21SM6N510296-B] ServiceVM_Centos/ServiceVM_Centos.vmx
2025-07-15 07:11:07,209 INFO  firstboot_utils.py:88 Running cmd ['esxcli --formatter csv hardware cpu list']
2025-07-15 07:11:07,639 INFO  firstboot_utils.py:88 Running cmd ['esxcli hardware cpu list']
2025-07-15 07:11:08,068 INFO  firstboot_utils.py:88 Running cmd ['esxcli hardware cpu global get']
2025-07-15 07:11:11,494 INFO  esx_util.py:233 Setting memory for VM 'INSTALLING' to 20GB
2025-07-15 07:11:15,535 INFO  esx_util.py:1038 Setting numa node affinity for VM 'INSTALLING' to 0
2025-07-15 07:11:19,559 INFO  esx_util.py:272 Setting cpu allocation for VM 'INSTALLING': num_sockets: 1, num_vcpus: 12, share_level: high, reservation: None MHz, cpu affinity: None
2025-07-15 07:11:21,680 INFO  esx_first_boot.py:94 Completed phase 'configure_svm_resources'
2025-07-15 07:11:21,683 INFO  esx_util.py:986 Collecting information for all attached physical NICs.
2025-07-15 07:11:25,879 INFO  esx_first_boot.py:94 Completed phase 'rc_local_update'
2025-07-15 07:11:28,925 INFO  esx_first_boot.py:2202 PMEM datastore not found
2025-07-15 07:11:31,932 INFO  esx_first_boot.py:226 Waiting for power state of SVM to change to poweredOn (attempt 0)
2025-07-15 07:11:39,959 INFO  esx_first_boot.py:224 Svm power state is now poweredOn
2025-07-15 07:12:43,301 INFO  esx_util.py:90 Connecting to host 'localhost' with user 'root'
2025-07-15 07:12:46,350 INFO  esx_util.py:201 Changing the display name of the VM from 'INSTALLING' to 'NTNX-21SM6N510296-B-CVM'
2025-07-15 07:12:53,426 INFO  esx_util.py:310 Updating AutoStart policy for VM 'NTNX-21SM6N510296-B-CVM'
2025-07-15 07:12:54,741 INFO  esx_first_boot.py:94 Completed phase 'final_svm_conf'
2025-07-15 07:12:57,744 INFO  esx_util.py:885 Assingning VLAN ID '0' to portgroup 'Management Network'
2025-07-15 07:13:00,746 INFO  esx_util.py:844 Gathering portgroup objects
2025-07-15 07:13:06,802 INFO  esx_util.py:885 Assingning VLAN ID '0' to portgroup 'VM Network'
2025-07-15 07:13:09,805 INFO  esx_util.py:844 Gathering portgroup objects
2025-07-15 07:13:12,864 INFO  esx_first_boot.py:3047 Configuring vmk0 interface
2025-07-15 07:13:12,864 INFO  firstboot_utils.py:88 Running cmd ['esxcli network ip interface ipv4 set -i vmk0 -I 10.24.137.32 -N 255.255.252.0 -t static']
2025-07-15 07:13:13,271 INFO  firstboot_utils.py:88 Running cmd ["esxcfg-vswitch -p 'Management Network' -v 0 vSwitch0"]
2025-07-15 07:13:13,339 INFO  firstboot_utils.py:88 Running cmd ['esxcfg-route 10.24.136.1']
2025-07-15 07:13:13,412 INFO  firstboot_utils.py:88 Running cmd ["kill $(ps | grep dcui | awk '{print $1}')"]
2025-07-15 07:13:13,464 INFO  firstboot_utils.py:88 Running cmd ['touch /bootbank/Nutanix/firstboot/.firstboot_success']
2025-07-15 07:13:13,488 INFO  esx_first_boot.py:3060 Running auto-backup.sh
2025-07-15 07:13:13,488 INFO  firstboot_utils.py:88 Running cmd ['sh /sbin/auto-backup.sh']
2025-07-15 07:13:14,625 INFO  firstboot_utils.py:88 Running cmd ['rm -rf /scratch/Nutanix']]]></ac:plain-text-body>
      </ac:structured-macro>
      <h2>
        <span style="font-size: 16.0px;font-weight: bold;letter-spacing: -0.006em;">Hyper-V</span>
      </h2>
      <p>
        <span style="letter-spacing: 0.0px;">The </span> <span style="letter-spacing: 0.0px;">hyperv_first_boot PowerShell script is used during the </span> <span style="letter-spacing: 0.0px;">initial boot of a Nutanix node running Microsoft Hyper-V</span> <span style="letter-spacing: 0.0px;">. It configures the Windows environment, installs necessary drivers and features, sets up the Nutanix Controller VM (CVM), and ensures the system is ready for production use.</span> <span style="letter-spacing: 0.0px;"> </span>
      </p>
      <p>
        <span style="letter-spacing: 0.0px;">The status of the</span> <span style="letter-spacing: 0.0px;"> </span> <code style="letter-spacing: 0.0px;">hyperv_first_boot</code> <span style="letter-spacing: 0.0px;"> </span> <span style="letter-spacing: 0.0px;">script is determined by the presence of marker files located in</span> <span style="letter-spacing: 0.0px;"> </span> <code style="letter-spacing: 0.0px;">D:\markers</code> <span style="letter-spacing: 0.0px;">:</span>
      </p>
      <ul>
        <li>
          <strong> <code>firstboot_success</code> </strong> <span> </span>— Indicates the script completed successfully.</li>
        <li>
          <strong> <code>firstboot_fail</code> </strong> <span> </span>— Indicates the script encountered an error.</li>
      </ul>
      <p>
        <span style="letter-spacing: 0.0px;">Test Environment Details</span>
      </p>
      <p>
        <strong>AOS Version: </strong>7.0.1.5<br/>
        <strong>Foundation Version</strong>: 5.7.1<br/>
        <strong>Hypervisor Version:</strong> Microsoft Windows Server 2022 Datacenter<br/>
        <strong>HW Model: </strong>NX-8155-G8</p>
      <p>Among the listed files, the presence of<span> </span> <code>firstboot_success</code> <span> </span>confirms that the script executed successfully. </p>
      <ac:structured-macro ac:macro-id="596311ba-b6d4-42d3-9206-f21b80773889" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">C:\Users\Administrator&gt;dir D:\markers</ac:parameter>
        <ac:plain-text-body><![CDATA[C:\Users\Administrator>dir D:\markers
 Volume in drive D is STAGING
 Volume Serial Number is E6B9-4F2C

 Directory of D:\markers

07/15/2025  01:26 PM    <DIR>          .
07/15/2025  01:26 PM    <DIR>          ..
07/15/2025  01:26 PM                 0 wer_dumps_enabled
07/15/2025  01:26 PM                 0 nutanix_utils_setup
07/15/2025  01:26 PM                 0 nutanix_utils_installed
07/15/2025  01:26 PM                 0 phase1_drivers_installed
07/15/2025  01:26 PM                 0 hyperv_roles_installed
07/15/2025  01:30 PM                 0 hyperv_failover_roles_installed
07/15/2025  01:31 PM                 0 cygwin_3_0_0_installed
07/15/2025  01:32 PM                 0 intelchipsetdriver_10_1_18807_8279_installed
07/15/2025  01:33 PM                 0 intelproset_29_0_installed
07/15/2025  01:33 PM                 0 python_2_7_15_installed
07/15/2025  01:33 PM                 0 ipmiutil_3_1_7_installed
07/15/2025  01:33 PM                 0 phase2_drivers_installed
07/15/2025  06:36 AM                 0 vswitch_setup
07/15/2025  06:36 AM                 0 nic_team_setup
07/15/2025  06:36 AM                 0 vmq_setup
07/15/2025  06:36 AM                 0 nutanix_utils_loaded
07/15/2025  06:36 AM                 0 jumbo_frames_enabled
07/15/2025  06:36 AM                 0 host_configured
07/15/2025  06:37 AM                 0 register_cvm_with_vmms_scheduled
07/15/2025  06:37 AM                 0 svm_setup
07/15/2025  06:37 AM                 0 phase3_drivers_installed
07/15/2025  06:48 AM                 0 firstboot_success
              22 File(s)              0 bytes
               2 Dir(s)     751,935,488 bytes free]]></ac:plain-text-body>
      </ac:structured-macro>
      <p>To monitor the script's progress in real-time, use the following PowerShell command:</p>
      <ac:structured-macro ac:macro-id="2c97df46-cc5a-4b86-ac13-331152092c4a" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:parameter ac:name="title">Get-Content "C:\Program Files\Nutanix\Logs\first_boot.log" -Tail 5 -wait</ac:parameter>
        <ac:plain-text-body><![CDATA[S C:\Users\Administrator> Get-Content "C:\Program Files\Nutanix\Logs\first_boot.log" -Tail 5 -wait
7/15/2025 6:48 AM Info Enabling page file for crash dumps
7/15/2025 6:48 AM Info Successfully enabled page file for crash dumps at C:\DedicatedDumpFile.sys
7/15/2025 6:48 AM Info Unset AutoLogon
7/15/2025 6:48 AM Info Unset on-logon script
7/15/2025 6:48 AM Info Marking first boot script run as success]]></ac:plain-text-body>
      </ac:structured-macro>
      <h3>Log Location</h3>
      <pre>C:\Program Files\Nutanix\Logs\first_boot.log</pre>
      <p>Below is an excerpt from a successful run of the<span> </span> <code>hyperv_first_boot</code> <span> </span>script:</p>
      <ac:structured-macro ac:macro-id="be8a0a26-c044-44df-a617-0f4dd1c0a169" ac:name="code" ac:schema-version="1">
        <ac:parameter ac:name="theme">RDark</ac:parameter>
        <ac:plain-text-body><![CDATA[7/15/2025 6:35 AM Info First boot script started
7/15/2025 6:35 AM Info WER dumps already enabled
7/15/2025 6:35 AM Info Enabling Event Channels
7/15/2025 6:36 AM Info Pagefile not found
7/15/2025 6:36 AM Info PCI Device of VendorID: 8086, DeviceID: 15FF is detected
7/15/2025 6:36 AM Info PCI Device of VendorID: 8086, DeviceID: 15FF is detected
7/15/2025 6:36 AM Info PCI Device of VendorID: 8086, DeviceID: 104E is detected
7/15/2025 6:36 AM Info PCI Device of VendorID: 8086, DeviceID: 104E is detected
7/15/2025 6:36 AM Info Creating VMSwitch
7/15/2025 6:36 AM Info Setting up Switch Embedded Teaming with adapters: Ethernet,Ethernet 2
7/15/2025 6:36 AM Info Setting the interface metric and disabling the automatic metric calculation on the external virtual switch
7/15/2025 6:36 AM Info Removing internal virtual switch InternalSwitch if it exists
7/15/2025 6:36 AM Info [1/10] Attempting to create a new internal virtual switch InternalSwitch
7/15/2025 6:36 AM Info [1/60] Checking if vEthernet (InternalSwitch) is Up
7/15/2025 6:36 AM Info vEthernet (InternalSwitch) is Up
7/15/2025 6:36 AM Info [1/10] Setting up internal vswitch IP address
7/15/2025 6:36 AM Info Setting the interface metric and disabling the automatic metric calculation on the internal virtual switch
7/15/2025 6:36 AM Info Setting up frame size for internal vswitch
7/15/2025 6:36 AM Info Enabling RDP
7/15/2025 6:36 AM Info VSwitch is already setup
7/15/2025 6:36 AM Info Setting the start virtual MAC address range to 0 21 93 170 104 0 and stop to 0 21 93 170 107 255
7/15/2025 6:36 AM Info Setting the power scheme to SCHEME_MIN.
7/15/2025 6:36 AM Info Tweak registry value of the internal interface to set it tx/rx Jumbo packets
7/15/2025 6:36 AM Info Opening up firewall for file and print services.
7/15/2025 6:36 AM Info Opening up firewall for WMI
7/15/2025 6:36 AM Info Generated svm name NTNX-21SG5H470006-A-CVM
7/15/2025 6:36 AM Info Creating CVM with name NTNX-21SG5H470006-A-CVM, memory 51539607552
7/15/2025 6:36 AM Info Setting CVM auto-start Start auto-stop ShutDown
7/15/2025 6:36 AM Info Pass thru disks to CVM
7/15/2025 6:37 AM Info Enabling serial port re-direction
7/15/2025 6:37 AM Info Disabling VM time synchronization
7/15/2025 6:37 AM Info Configuring processor count and weight
7/15/2025 6:37 AM Info Setting static memory to 51539607552 bytes
7/15/2025 6:37 AM Info Setting RAM priority to 100
7/15/2025 6:37 AM Info Adding external adapter on System.Collections.Hashtable['external_vswitch_name']
7/15/2025 6:37 AM Info Configuring External VLAN
7/15/2025 6:37 AM Info Adding internal adapter on System.Collections.Hashtable['internal_vswitch_name']
7/15/2025 6:37 AM Info Adding backplane adapter on System.Collections.Hashtable['external_vswitch_name']
7/15/2025 6:37 AM Info Configuring Backplane VLAN
7/15/2025 6:37 AM Info Removing default network adapter
7/15/2025 6:37 AM Info Attaching svmboot.iso
7/15/2025 6:37 AM Info CVM configuration complete
7/15/2025 6:37 AM Info Scheduling register CVM with VMMS
7/15/2025 6:37 AM Info Setting NTNX-21SG5H470006-A-CVM to auto-start and disabling auto-stop
7/15/2025 6:37 AM Info Starting svm NTNX-21SG5H470006-A-CVM
7/15/2025 6:37 AM Info Running cmd ls /tmp/svm_boot_succeeded on svm
7/15/2025 6:48 AM Info Running ssh command with nutanix@192.168.5.254 -o StrictHostKeyChecking=no -o NumberOfPasswordPrompts=0 -o UserKnownHostsFile=NUL -i /cygdrive/C/staging/ssh_keys/nutanix ls /tmp/svm_boot_succeeded
7/15/2025 6:48 AM Info Success running ls /tmp/svm_boot_succeeded
7/15/2025 6:48 AM Info Setting storage new disk policy
7/15/2025 6:48 AM Info Calling LastReboot without reboot..
7/15/2025 6:48 AM Info Beginning last reboot
7/15/2025 6:48 AM Info Waiting for CVM to boot up.
7/15/2025 6:48 AM Info Running cmd ls /tmp/svm_boot_succeeded on svm
7/15/2025 6:48 AM Info Running ssh command with nutanix@192.168.5.254 -o StrictHostKeyChecking=no -o NumberOfPasswordPrompts=0 -o UserKnownHostsFile=NUL -i /cygdrive/C/staging/ssh_keys/nutanix ls /tmp/svm_boot_succeeded
7/15/2025 6:48 AM Info Success running ls /tmp/svm_boot_succeeded
7/15/2025 6:48 AM Info Enabling page file for crash dumps
7/15/2025 6:48 AM Info Successfully enabled page file for crash dumps at C:\DedicatedDumpFile.sys
7/15/2025 6:48 AM Info Unset AutoLogon
7/15/2025 6:48 AM Info Unset on-logon script
7/15/2025 6:48 AM Info Marking first boot script run as success]]></ac:plain-text-body>
      </ac:structured-macro>
      <h3>
        <strong>To re-run the First Boot Script:</strong>
      </h3>
      <p>If the script fails, follow these steps to re-run it:</p>
      <ol>
        <li>Examine the first_boot.log <span style="color: rgb(66,66,66);">to identify and resolve the root cause of the failure.</span>
        </li>
        <li>
          <p>Remove the firstboot_fail marker file.</p>
          <pre>PS C:\Users\Administrator&gt; Remove-Item -path D:\markers\firstboot_fail<br/>
            <br/>
          </pre>
        </li>
        <li>
          <p>Execute the First Boot Script.</p>
          <pre>PS C:\Users\Administrator&gt; cd D:\
PS D:\&gt; .\FirstBoot.BAT</pre>
        </li>
      </ol>
    </ac:layout-cell>
  </ac:layout-section>
  <ac:layout-section ac:type="single">
    <ac:layout-cell>
      <p>
        <br/>
      </p>
    </ac:layout-cell>
  </ac:layout-section>
  <ac:layout-section ac:type="single">
    <ac:layout-cell>
      <p>
        <br/>
      </p>
      <p>
        <ac:structured-macro ac:macro-id="5aa3a59c-9bed-4ea0-a0aa-965de43b4153" ac:name="macrosuite-button" ac:schema-version="1">
          <ac:parameter ac:name="macroId">rC5a5Lc8KpDDv5TXp4bt-</ac:parameter>
          <ac:parameter ac:name="data">JTdCJTIyYnV0dG9uVHlwZSUyMiUzQSUyMmljb25fcmlnaHQlMjIlMkMlMjJidXR0b25TaXplJTIyJTNBJTIybGFyZ2UlMjIlMkMlMjJidXR0b25UZXh0JTIyJTNBJTIyUHJvY2VlZCUyMHRvJTIwQ2hhcHRlciUyMDclM0ElMjBEZWJ1Z2dpbmclMjBpbiUyMFBob2VuaXglMjBvciUyMFJlc2N1ZSUyMFNoZWxsJTIwJTIyJTJDJTIyYnV0dG9uUmFkaXVzJTIyJTNBMSUyQyUyMmJ1dHRvbldpZHRoJTIyJTNBMjAlMkMlMjJidXR0b25Db2xvciUyMiUzQSUyMiUyMzAwMDAwMDAwJTIyJTJDJTIyYnV0dG9uRm9udENvbG9yJTIyJTNBJTIyJTIzMDA2NWZmZmYlMjIlMkMlMjJidXR0b25Cb3JkZXJDb2xvciUyMiUzQSUyMiUyMzAwMDAwMDAwJTIyJTJDJTIyYnV0dG9uTGluayUyMiUzQSUyMiU3QiU1QyUyMmlkJTVDJTIyJTNBJTVDJTIyNDMxMzI4MzAzJTVDJTIyJTJDJTVDJTIybGluayU1QyUyMiUzQSU1QyUyMiUyRnglMkZMNHkxR1ElNUMlMjIlMkMlNUMlMjJ0aXRsZSU1QyUyMiUzQSU1QyUyMkRSQUZUJTIwLSUyMERlYnVnZ2luZyUyMGluJTIwUGhvZW5peCUyMG9yJTIwUmVzY3VlJTIwU2hlbGwlNUMlMjIlMkMlNUMlMjJ0eXBlJTVDJTIyJTNBJTVDJTIycGFnZSU1QyUyMiUyQyU1QyUyMnNvdXJjZSU1QyUyMiUzQSU1QyUyMnBhZ2UlNUMlMjIlN0QlMjIlMkMlMjJidXR0b25OZXdUYWIlMjIlM0ElMjJ0cnVlJTIyJTJDJTIyYnV0dG9uTmV3TGluayUyMiUzQSUyMiUyMiUyQyUyMmJ1dHRvbkljb24lMjIlM0ElMjJib290c3RyYXAlMkZBcnJvd1JpZ2h0Q2lyY2xlJTIyJTJDJTIyYnV0dG9uSG92ZXJDb2xvciUyMiUzQSUyMnRyYW5zcGFyZW50JTIyJTJDJTIyYnV0dG9uQm9yZGVySG92ZXJDb2xvciUyMiUzQSUyMiUyMzAwMDAwMDAwJTIyJTJDJTIyYnV0dG9uRm9udEhvdmVyQ29sb3IlMjIlM0ElMjIlMjMwMDAwMDAwMCUyMiUyQyUyMmJ1dHRvbkljb25Ib3ZlckNvbG9yJTIyJTNBJTIyJTIzMDAwMDAwMDAlMjIlMkMlMjJpc0J1dHRvblNoYWRvd09uJTIyJTNBdHJ1ZSUyQyUyMmJ1dHRvbkljb25Db2xvciUyMiUzQSUyMiUyMzAwNjVmZmZmJTIyJTJDJTIyYnV0dG9uV2lkdGhEZXRlY3Rpb24lMjIlM0E2MCUyQyUyMmVtb2ppRW5hYmxlZCUyMiUzQWZhbHNlJTJDJTIyZW1vamklMjIlM0ElMjIlN0IlN0QlMjIlN0Q=</ac:parameter>
        </ac:structured-macro>
      </p>
    </ac:layout-cell>
  </ac:layout-section>
</ac:layout>

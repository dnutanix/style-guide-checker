<ac:layout>
  <ac:layout-section ac:type="single">
    <ac:layout-cell>
      <p>
        <span style="letter-spacing: -0.01em;font-size: 24.0px;">Overview</span>
      </p>
      <p>This chapter provides detailed guidance on installing and repairing Controller Virtual Machines (CVMs) using Phoenix. You'll learn the critical differences between these two operations, when to use each approach, and the step-by-step procedures for both processes. This chapter also covers alternative repair methods and post-repair configuration requirements.</p>
      <ac:structured-macro ac:macro-id="chapter-overview" ac:name="info" ac:schema-version="1">
        <ac:parameter ac:name="title">What You Will Learn</ac:parameter>
        <ac:rich-text-body>
          <p>By the end of this chapter, you will be able to:</p>
          <ul>
            <li>
              <strong>Understand CVM operations</strong> - Learn the differences between CVM installation and repair processes</li>
            <li>
              <strong>Install CVMs safely</strong> - Follow step-by-step procedures for installing new CVMs using Phoenix</li>
            <li>
              <strong>Repair CVMs effectively</strong> - Understand when and how to repair existing CVMs while preserving data</li>
            <li>
              <strong>Use alternative repair methods</strong> - Learn about the single_ssd_repair script and when to use it</li>
            <li>
              <strong>Complete post-repair configuration</strong> - Understand the boot_disk_replace script and cluster reintegration</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
      <h2>Install vs. Repair</h2>
      <h3>Understanding the Two Approaches</h3>
      <p>Phoenix provides two distinct processes for working with Nutanix CVMs on hypervisors. Understanding the differences is crucial for selecting the appropriate approach for your specific scenario.</p>
      <p>
        <strong>Choose INSTALL when:</strong>
      </p>
      <ul>
        <li>Working with a completely new node</li>
        <li>Node has been logically removed from its original cluster</li>
        <li>Complete system re-imaging is required</li>
        <li>Data loss is acceptable or expected</li>
      </ul>
      <p>
        <strong>Choose REPAIR when:</strong>
      </p>
      <ul>
        <li>Fixing software issues on an existing CVM</li>
        <li>Preserving customer data is critical</li>
        <li>Node is part of an active cluster</li>
        <li>Only CVM infrastructure needs restoration</li>
      </ul>
      <p>
        <strong>Always consider:</strong>
      </p>
      <ul>
        <li>Data preservation requirements</li>
        <li>Cluster impact and availability</li>
        <li>Time required for the operation</li>
        <li>Post-operation configuration needs</li>
      </ul>
      <ac:structured-macro ac:macro-id="support-supervision" ac:name="warning" ac:schema-version="1">
        <ac:parameter ac:name="title">Support Supervision Required</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>NEVER</strong> permit a customer or resident/SE to use these utilities without direct assistance from Nutanix Support.</p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="single-node-cluster" ac:name="warning" ac:schema-version="1">
        <ac:parameter ac:name="title">Single-Node Cluster Prohibition</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>NEVER</strong> utilize these utilities on a <strong>single-node cluster</strong> -- doing so will result in <strong>COMPLETE DATA LOSS</strong>.</p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="aos-upgrade-restrictions" ac:name="warning" ac:schema-version="1">
        <ac:parameter ac:name="title">AOS Upgrade Restrictions</ac:parameter>
        <ac:rich-text-body>
          <p>These utilities are not recommended for clusters undergoing an AOS upgrade.</p>
          <p>If it is determined that a CVM may need to be repaired during an ongoing AOS upgrade, involve DevEx via filing an ONCALL ticket in Jira under the '<strong>Infrastructure</strong>' component.</p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="hardware-fault-considerations" ac:name="warning" ac:schema-version="1">
        <ac:parameter ac:name="title">Hardware Fault Considerations</ac:parameter>
        <ac:rich-text-body>
          <p>These utilities should not be utilized on a CVM if there are signs of any hardware faults on the node.</p>
          <p>If the CVM is unable to boot normally, start by checking the alerts history of the cluster to see if there are any hardware-failure related alerts.</p>
          <p>Utilize <strong>
              <a href="https://portal.nutanix.com/kb/1113">KB-1113</a>
            </strong> for troubleshooting and consult the <strong>
              <a href="https://portal.nutanix.com/#/page/docs/list?type=hardware">Hardware Replacement Documentation</a>
            </strong> for the appropriate platform and boot drive configuration (single-SSD vs. multi-NVMe/SSD platform).</p>
          <p>The <strong>
              <a href="https://confluence.eng.nutanix.com:8443/pages/viewpage.action?pageId=18613438#Low-LevelSoftwareTroubleshooting&amp;HardwareFaultIsolation-PaniconBoot">CVM Console Logs</a>
            </strong> on the hypervisor may also contain <strong>
              <a href="https://confluence.eng.nutanix.com:8443/display/STK/WF%3A+Disk+Debugging">signatures of disk-related errors</a>
            </strong>.</p>
          <p>The <strong>
              <a href="https://confluence.eng.nutanix.com:8443/display/STK/Using+the+cvm_diagnose+Script">cvm_diagnose script</a>
            </strong> may also be utilized in order to provision a debug shell to verify the health of the node's disks, HBA, and mount the CVM's /home partition to analyze kernel logs.</p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="repair-approach" ac:name="warning" ac:schema-version="1">
        <ac:parameter ac:name="title">Repair Approach and Important Notes</ac:parameter>
        <ac:rich-text-body>
          <p>The <code>single_ssd_repair</code> script should be the <strong>FIRST approach</strong> in attempting to repair an affected CVM experiencing filesystem corruption or a single-SSD system undergoing a boot drive replacement, prior to resorting to a manual svmrescue or Phoenix Repair CVM action.</p>
          <p>
            <strong>-----</strong>
          </p>
          <p>Rescuing a CVM is destructive to the CVM's cluster configuration data and should ONLY be executed if the rest of the nodes in the cluster are fully operational.</p>
          <p>
            <strong>-----</strong>
          </p>
          <p>Rescuing a CVM is not intended as an approach for recovery from errors in AOS caused by hardware faults. Any faulty hardware must be replaced before you try to recreate the CVM.</p>
          <p>For proper troubleshooting and recovery from these failures, utilize <a href="https://portal.nutanix.com/kb/1113">KB-1113</a> for troubleshooting and consult the <a href="https://portal.nutanix.com/#/page/docs/list?type=hardware">Hardware Replacement Documentation</a> for the appropriate platform and boot drive configuration (single-SSD vs. multi-NVMe/SSD platform).</p>
          <p>
            <strong>-----</strong>
          </p>
          <p>These utilities are not to be utilized on multi-NVMe/SSD platforms when one of the CVM's boot drives is not physically inserted.</p>
          <p>Doing so will result in the CVM's software RAID array not getting configured properly and will require a full Phoenix re-imaging of the node in order to remediate.</p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="when-in-doubt" ac:name="warning" ac:schema-version="1">
        <ac:parameter ac:name="title">When in Doubt, Ask for Help</ac:parameter>
        <ac:rich-text-body>
          <p>If you have ANY doubts and are not 100% confident in the appropriate action plan in utilizing these utilities, <strong>ALWAYS</strong> reach out to an STL or member of DevEx for guidance.</p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="additional-resources" ac:name="info" ac:schema-version="1">
        <ac:parameter ac:name="title">Additional Resources</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>For hardware troubleshooting:</strong>
          </p>
          <ul>
            <li>
              <a href="https://confluence.eng.nutanix.com:8443/pages/viewpage.action?pageId=18613438#Low-LevelSoftwareTroubleshooting&amp;HardwareFaultIsolation-PaniconBoot">CVM Console Logs</a> - Check for hardware-related errors</li>
            <li>
              <a href="https://confluence.eng.nutanix.com:8443/display/STK/WF%3A+Disk+Debugging">Disk Debugging Guide</a> - Identify disk-related issues</li>
            <li>
              <a href="https://confluence.eng.nutanix.com:8443/display/STK/Using+the+cvm_diagnose+Script">cvm_diagnose Script</a> - Verify node health and analyze logs</li>
          </ul>
          <p>
            <strong>For boot drive failures:</strong>
          </p>
          <ul>
            <li>
              <a href="https://portal.nutanix.com/kb/1113">KB-1113</a> - Troubleshooting guide for boot drive issues</li>
            <li>
              <a href="https://portal.nutanix.com/#/page/docs/list?type=hardware">Hardware Replacement Documentation</a> - Platform-specific guidance</li>
          </ul>
          <p>
            <strong>Important Notes:</strong>
          </p>
          <ul>
            <li>Manual rescue is destructive to cluster configuration data</li>
            <li>These utilities are not suitable for multi-NVMe/SSD platforms with missing boot drives</li>
            <li>Always ensure proper authorization before proceeding</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
    </ac:layout-cell>
  </ac:layout-section>
  <ac:layout-section ac:type="single">
    <ac:layout-cell>
      <p>
        <span style="letter-spacing: -0.006em;font-size: 16.0px;font-weight: bold;">Phoenix Installer: Install CVM - Complete fresh installation process (wipes existing data)</span>
      </p>
      <p>This section covers the complete installation process for a new CVM using Phoenix. This process will completely erase all data on the node, so it's only suitable for new nodes or nodes that have been removed from their original cluster.</p>
      <ac:structured-macro ac:macro-id="install-tips" ac:name="info" ac:schema-version="1">
        <ac:parameter ac:name="title">Tips and Gotchas</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>When to use Install:</strong>
          </p>
          <ul>
            <li>New nodes being added to a cluster</li>
            <li>Nodes that have been logically removed from their original cluster</li>
            <li>Complete system re-imaging scenarios</li>
          </ul>
          <p>
            <strong>Important considerations:</strong>
          </p>
          <ul>
            <li>Ensure you have proper authorization for this operation</li>
            <li>Verify the node is not part of an active cluster</li>
            <li>Have the correct AOS version ready for installation</li>
            <li>Plan for the time required for complete installation</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="expand-install-cvm" ac:name="expand" ac:schema-version="1">
        <ac:parameter ac:name="title">Click to view step-by-step instructions</ac:parameter>
        <ac:rich-text-body>
          <ac:structured-macro ac:macro-id="install-warning" ac:name="warning" ac:schema-version="1">
            <ac:parameter ac:name="title">⚠️ Data Loss Warning</ac:parameter>
            <ac:rich-text-body>
              <p>
                <strong>This process will completely erase all data on the node.</strong> Ensure you have:</p>
              <ul>
                <li>Backed up any critical data</li>
                <li>Confirmed this is a new node or one removed from its original cluster</li>
                <li>Obtained proper authorization for this operation</li>
              </ul>
            </ac:rich-text-body>
          </ac:structured-macro>
          <h3>Step-by-Step Installation Process</h3>
          <ul style="list-style-type: square;">
            <li>At Phoenix's main '<strong>Nutanix Installer</strong>' menu, select the "<strong>Install CVM (Wipes existing data!)</strong>" option as below.<br/>The <strong>UP</strong> / <strong>DOWN</strong> arrow keys will switch between the highlighted/selected fields, and the <strong>LEFT</strong> / <strong>RIGHT</strong> arrow keys will toggle between each selected field's values.<br/>
              <strong>*Note</strong>: For single block/node platforms, select "<strong>A</strong>" for the '<strong>Node Position</strong>' and for multi-node block platforms, select the appropriate node slot (<strong>A</strong>, <strong>B</strong>, <strong>C</strong>, or <strong>D</strong>) in which the node being worked on corresponds to.<br/>Once all fields are validated, highlight '<strong style="letter-spacing: 0.0px;">Next</strong> <span style="letter-spacing: 0.0px;">' at the bottom of the menu and press </span> <strong style="letter-spacing: 0.0px;">Enter</strong> <span style="letter-spacing: 0.0px;">to proceed.</span>
            </li>
          </ul>
          <br/>
          <pre>     <ac:image ac:height="400">
              <ri:attachment ri:filename="1.png"/>
            </ac:image>
          </pre>
          <ul style="list-style-type: square;">
            <li>At the next configuration menu, enter the network information of the node.<br/>
              <strong>*Note</strong>: If no VLAN ID is being used, leave the '<strong>CVM Vlan ID</strong>' field blank.<br/>Once all fields are validated, highlight '<strong style="letter-spacing: 0.0px;">Next</strong> <span style="letter-spacing: 0.0px;">' at the bottom of the menu and press </span> <strong style="letter-spacing: 0.0px;">Enter</strong> <span style="letter-spacing: 0.0px;"> to proceed.</span>
            </li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="2.png"/>
            </ac:image>
          </p>
          <p>
            <br/>
          </p>
          <ul style="list-style-type: square;">
            <li>The next menu will reiterate the actions of the "<strong style="letter-spacing: 0.0px;">Install CVM (Wipes existing data!)</strong> <span style="letter-spacing: 0.0px;">" option <span>that was specified at the initial menu</span>.<br/>Once all statements are acknowledged, highlight '<strong style="letter-spacing: 0.0px;">Yes</strong> <span style="letter-spacing: 0.0px;">' at the bottom of the menu and press </span> <strong style="letter-spacing: 0.0px;">Enter</strong> <span style="letter-spacing: 0.0px;"> to initiate the installation process.</span> </span>
            </li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="3.png"/>
            </ac:image>
          </p>
          <p>
            <br/>
          </p>
          <ul style="list-style-type: square;">
            <li>During the installation process, all AOS packages which are being installed will be displayed.<br/>Although at times it may seem that the installation is stuck, the included AOS packages vary in size and directory depth, and some will take quite a while to install – so long as the underscore cursor in the bottom left corner is flashing/blinking, that will indicate that the installation is still in progress.</li>
          </ul>
          <p>           <ac:image ac:height="400">
              <ri:attachment ri:filename="4.png"/>
            </ac:image>
          </p>
          <p>
            <br/>
          </p>
          <ul style="list-style-type: square;">
            <li>At completion of the installation process, the Phoenix script will prompt for user input.<br/>Type '<strong>Y</strong>' and press the <strong>Enter</strong> key to initiate a reboot of the node.<br/>Unplug/unmount the Phoenix .iso that is attached to the node either via virtual or physical media.</li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="5.png"/>
            </ac:image>
          </p>
          <ac:structured-macro ac:macro-id="install-completion" ac:name="info" ac:schema-version="1">
            <ac:parameter ac:name="title">Installation Complete</ac:parameter>
            <ac:rich-text-body>
              <p>At this stage, the CVM will be in a fresh, un-configured, and discoverable state where it can then be added to a new or existing cluster.</p>
            </ac:rich-text-body>
          </ac:structured-macro>
        </ac:rich-text-body>
      </ac:structured-macro>
      <h3>Phoenix Installer: Repair CVM - Restore CVM while preserving existing data</h3>
      <p>This section covers the repair process for an existing CVM using Phoenix. This process preserves your data while restoring CVM infrastructure. It's the safer option when you need to fix CVM issues without losing customer data.</p>
      <ac:structured-macro ac:macro-id="repair-tips" ac:name="info" ac:schema-version="1">
        <ac:parameter ac:name="title">Tips and Gotchas</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>When to use Repair:</strong>
          </p>
          <ul>
            <li>CVM boot issues or corrupted files</li>
            <li>Software-related problems that don't affect data</li>
            <li>When you need to preserve customer data</li>
            <li>After attempting single_ssd_repair script first</li>
          </ul>
          <p>
            <strong>Important considerations:</strong>
          </p>
          <ul>
            <li>Always try single_ssd_repair script before manual repair</li>
            <li>Ensure the cluster has enough healthy nodes to continue operating</li>
            <li>Plan for post-repair configuration with boot_disk_replace</li>
            <li>Monitor cluster health during the repair process</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="expand-repair-cvm" ac:name="expand" ac:schema-version="1">
        <ac:parameter ac:name="title">Click to view step-by-step instructions</ac:parameter>
        <ac:rich-text-body>
          <ac:structured-macro ac:macro-id="repair-info" ac:name="info" ac:schema-version="1">
            <ac:parameter ac:name="title">ℹ️ Data Preservation</ac:parameter>
            <ac:rich-text-body>
              <p>
                <strong>This process preserves your data while restoring CVM infrastructure.</strong>
              </p>
              <ul>
                <li>Customer data partitions remain intact</li>
                <li>Only CVM infrastructure partitions are reformatted</li>
                <li>Post-repair configuration will be required</li>
              </ul>
            </ac:rich-text-body>
          </ac:structured-macro>
          <h3>Step-by-Step Repair Process</h3>
          <ul>
            <li>At Phoenix's main '<strong>Nutanix Installer</strong>' menu, select the "<strong>Repair CVM (Preserves data!)</strong>" option as below.<br/>The <strong>UP</strong> / <strong>DOWN</strong> arrow keys will switch between the highlighted/selected fields, and the <strong>LEFT</strong> / <strong>RIGHT</strong> arrow keys will toggle between each selected field's values.<br/>
              <strong>*Note</strong>: For single block/node platforms, select "<strong>A</strong>" for the '<strong>Node Position</strong>' and for multi-node block platforms, select the appropriate node slot (<strong>A</strong>, <strong>B</strong>, <strong>C</strong>, or <strong>D</strong>) in which the node being worked on corresponds to.<br/>Once all fields are validated, highlight '<strong>Next</strong> <span>' at the bottom of the menu and press </span> <strong>Enter</strong> <span> to proceed.</span>
            </li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="6.png"/>
            </ac:image>
          </p>
          <ul>
            <li>At the next configuration menu, enter the network information of the node.<br/>
              <strong>*Note</strong>: If no VLAN ID is being used, leave the '<strong>CVM Vlan ID</strong>' field blank.<br/>Once all fields are validated, highlight '<strong>Next</strong> <span>' at the bottom of the menu and press </span> <strong>Enter</strong> <span> to proceed.</span>
            </li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="7.png"/>
            </ac:image>
          </p>
          <ul>
            <li>The next menu will reiterate the actions of the "<strong>Repair CVM (Preserves data!)</strong> <span>" option that was specified at the initial menu.<br/>Once all statements are acknowledged, highlight '<strong>Yes</strong>' at the bottom of the menu and press <strong>Enter</strong> to initiate the installation process.</span>
            </li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="8.png"/>
            </ac:image>
          </p>
          <ul>
            <li>During the installation process, all AOS packages which are being installed will be displayed.<br/>Although at times it may seem that the installation is stuck, the included AOS packages vary in size and directory depth, and some will take quite a while to install – so long as the underscore cursor in the bottom left corner is flashing/blinking, that will indicate that the installation is still in progress.</li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="9.png"/>
            </ac:image>
          </p>
          <ul>
            <li>At completion of the installation process, the Phoenix script will prompt for user input.<br/>Type '<strong>Y</strong>' and press the <strong>Enter</strong> key to initiate a reboot of the node.<br/>Unplug/unmount the Phoenix .iso that is attached to the node either via virtual or physical media.</li>
          </ul>
          <p>          <ac:image ac:height="400">
              <ri:attachment ri:filename="10.png"/>
            </ac:image>
          </p>
          <ac:structured-macro ac:macro-id="repair-completion" ac:name="warning" ac:schema-version="1">
            <ac:parameter ac:name="title">Post-Repair Configuration Required</ac:parameter>
            <ac:rich-text-body>
              <p>At this stage, the <code>boot_disk_replace</code> script within a working CVM from the existing cluster must be executed in order to re-apply the repaired CVM's original configuration information for it to be recognizable and usable by the existing cluster again.</p>
              <p>Proceed to the section below titled "Using the boot_disk_replace Script" for detailed instructions.</p>
            </ac:rich-text-body>
          </ac:structured-macro>
        </ac:rich-text-body>
      </ac:structured-macro>
      <h3>Using the single_ssd_repair Script - Automated CVM repair workflow (recommended first approach)</h3>
      <p>This section covers the automated repair process using the single_ssd_repair script. This is the recommended first approach for repairing CVMs as it's automated, safer, and preserves data. Use this before attempting manual rescue procedures.</p>
      <ac:structured-macro ac:macro-id="single-ssd-tips" ac:name="info" ac:schema-version="1">
        <ac:parameter ac:name="title">Tips and Gotchas</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>When to use single_ssd_repair:</strong>
          </p>
          <ul>
            <li>First approach for any CVM repair scenario</li>
            <li>Filesystem corruption issues</li>
            <li>Single-SSD boot drive replacement</li>
            <li>When automated repair is preferred over manual</li>
          </ul>
          <p>
            <strong>Important considerations:</strong>
          </p>
          <ul>
            <li>
              <span style="letter-spacing: 0.0px;">Affected CVM must be powered OFF</span>
            </li>
            <li>Hypervisor must be functional and operational</li>
            <li>Monitor progress using ssd_repair_status command</li>
            <li>Check Genesis logs for detailed progress information</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="expand-single-ssd-repair" ac:name="expand" ac:schema-version="1">
        <ac:parameter ac:name="title">Click to view automated repair instructions</ac:parameter>
        <ac:rich-text-body>
          <h3>Overview</h3>
          <p>The `<strong>single_ssd_repair</strong>` script (<a href="https://portal.nutanix.com/kb/4637">KB-4637</a>) can be invoked from a working CVM within the same cluster to automate recovery from<span> missing or corrupted OS files/software that prevents the CVM from being able to boot or bring the Genesis service online.</span>
          </p>
          <ac:structured-macro ac:macro-id="1c256b55-0c51-40eb-99c7-811d9ccaf440" ac:name="info" ac:schema-version="1">
            <ac:rich-text-body>
              <p>
                <span style="color: rgb(23,43,77);">While typically a CVM that is a proper candidate for recreation would be unbootable, <a href="http://portal.nutanix.com/kb/13931">KB-13931</a> Action Plans 5 and 6 are examples where the CVM is otherwise running but EXT4 corruption is found on some of its infrastructure/boot files. For these, use of the single_ssd_repair script is recommended (however this is only for AOS version 6.0.1.6 and earlier).</span>
              </p>
            </ac:rich-text-body>
          </ac:structured-macro>
          <ac:structured-macro ac:macro-id="38327675-2f76-4e5f-970a-94c4c140807a" ac:name="note" ac:schema-version="1">
            <ac:parameter ac:name="title">Note</ac:parameter>
            <ac:rich-text-body>
              <p>
                <span>This method should be the </span>
                <strong>
                  <u>FIRST approach</u> </strong>
                <span> </span>
                <span> in attempting to repair an affected CVM experiencing filesystem corruption or a single-SSD system undergoing a boot drive replacement.</span>
              </p>
            </ac:rich-text-body>
          </ac:structured-macro>
          <p>
            <span style="letter-spacing: 0.0px;">The </span>
            <code style="letter-spacing: 0.0px;">single_ssd_repair</code>
            <span style="letter-spacing: 0.0px;"> script aims to be a 1-click repair workflow that automates the restoration of a CVM. There are 7 successive phases of the script, and the actions performed during each phase are detailed below:</span>
          </p>
          <table class="wrapped">
            <colgroup> <col/> <col/> <col/> </colgroup>
            <tbody>
              <tr>
                <th scope="col">
                  <br/>
                </th>
                <th scope="col">Phase</th>
                <th scope="col">Actions Performed</th>
              </tr>
              <tr>
                <td>1.</td>
                <td>
                  <pre>sm_single_ssd_repair_init</pre>
                </td>
                <td>Initializes the repair operation, updates Zookeeper, and sets up task tracking</td>
              </tr>
              <tr>
                <td>2.</td>
                <td>
                  <pre>sm_single_ssd_repair_prechecks</pre>
                </td>
                <td>Validates connectivity and environment pre-requisites</td>
              </tr>
              <tr>
                <td>3.</td>
                <td>
                  <pre>sm_create_transfer_svmrescue_image</pre>
                </td>
                <td>Creates and transfers the svmrescue.iso image to the host, and mounts it as the CVM's boot image</td>
              </tr>
              <tr>
                <td>4.</td>
                <td>
                  <pre>sm_bring_up_rescue_cvm</pre>
                </td>
                <td>Boots the CVM into the svmrescue.iso image</td>
              </tr>
              <tr>
                <td>5.</td>
                <td>
                  <pre>sm_transfer_nos_bundle_and_rescue</pre>
                </td>
                <td>Transfers the AOS .tar.gz bundle to the CVM and initiates rescue scripts</td>
              </tr>
              <tr>
                <td>6.</td>
                <td>
                  <pre>sm_bring_up_cvm</pre>
                </td>
                <td>Boots the CVM normally to the AOS kernel</td>
              </tr>
              <tr>
                <td>7.</td>
                <td>
                  <pre>sm_post_rescue_steps</pre>
                </td>
                <td>Finalizes the CVM's cluster and networking configuration, and performs cleanup steps</td>
              </tr>
            </tbody>
          </table>
          <h2>Prerequisites</h2>
          <ul>
            <li>The hypervisor of the affected CVM must be <strong>functional/operational</strong>
            </li>
            <li>The affected CVM must be powered OFF</li>
          </ul>
          <p style="margin-left: 40.0px;">Shut down the <strong>affected CVM</strong>:</p>
          <ac:structured-macro ac:macro-id="bab029f4-e66e-472a-b543-ad9dfa7b7e58" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Shutdown the affected CVM</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ cvm_shutdown -P now]]></ac:plain-text-body>
          </ac:structured-macro>
          <p style="margin-left: 40.0px;">If services are down or crashing on the affected CVM, the <span style="color: rgb(23,43,77);">"cvm_shutdown" script will not be able to pass its prechecks as the cluster is considered to be in a degraded state</span>. In order to work around this, you may put the unhealthy CVM into CVM Maintenance Mode from another <strong>working CVM</strong>. This will ensure that any services that remain active are gracefully stopped. Then, you can get the CVM to power off using basic Linux commands.</p>
          <ac:structured-macro ac:macro-id="0a37eee0-3db3-4ed7-895c-725210066a09" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Enable maintenance mode (if needed)</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ ncli host edit enable-maintenance-mode=true id={CVM_ID}]]></ac:plain-text-body>
          </ac:structured-macro>
          <p style="margin-left: 40.0px;">
            <span style="letter-spacing: 0.0px;">The <strong>affected CVM</strong> will then need to be shut down in the regular Linux way:</span>
          </p>
          <ac:structured-macro ac:macro-id="004e2e3a-1b4f-4018-9acd-b54a61279d12" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Force shutdown (if maintenance mode was used)</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ sudo shutdown -h now]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <br/>
          </p>
          <p>
            <span style="letter-spacing: -0.008em;font-size: 20.0px;">Script Usage</span>
          </p>
          <p>
            <strong>1.</strong> From a <strong>healthy CVM</strong> in the same cluster, run the `<strong>single_ssd_repair</strong>` script with the following syntax corresponding to the platform's CVM boot drive configuration:</p>
          <p>
            <br/>
          </p>
          <ac:structured-macro ac:macro-id="44f3b668-5074-4286-8a46-cefcc6ace261" ac:name="note" ac:schema-version="1">
            <ac:parameter ac:name="title">Note</ac:parameter>
            <ac:rich-text-body>
              <p>
                <span style="color: rgb(23,43,77);">Only include the '<strong>--ignore_disk_removal</strong>' flag if the original CVM boot drive(s) have not been logically removed from the cluster and are still physically inserted/present in the node.</span>
              </p>
              <p>
                <span style="color: rgb(23,43,77);">When run alone, without the --ignore_disk_removal flag, the single_ssd_repair script wants to make sure that the CVM boot drive(s) on the node were logically removed. This is done because, if the original metadata drives are still in the zeus configuration and the CVM boots up with a fresh drive (new serial number), Cassandra will go into a crash loop because it isn't finding the serial number of the metadata drive that Zookeeper says it should be using. This is covered in <a href="http://portal.nutanix.com/kb/12368">KB-12368</a>.</span>
              </p>
            </ac:rich-text-body>
          </ac:structured-macro>
          <p>
            <br/>
          </p>
          <p>
            <strong> <span style="letter-spacing: 0.0px;">- For single-SSD platforms</span> </strong> <span style="letter-spacing: 0.0px;">:</span>
          </p>
          <ac:structured-macro ac:macro-id="5175ecd8-1059-4f96-b9a4-fa8ba3ce7bab" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Single-SSD Platform Command</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ single_ssd_repair -s {CVM_IP} --ignore_disk_removal]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>Example expected output:<br/>
              <ac:structured-macro ac:macro-id="73993bd4-b40f-4875-a5bb-f70793df6fad" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[Repairing node with IP: {CVM_IP}
Single SSD repair successfully initiated]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <strong> <span style="letter-spacing: 0.0px;">- For multi-NVMe/SSD platforms</span> </strong> <span style="letter-spacing: 0.0px;">:</span>
          </p>
          <ac:structured-macro ac:macro-id="81b9351e-e72f-45b3-8041-34d5286adc12" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Multi-NVMe/SSD Platform Command</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ single_ssd_repair -s {CVM_IP} --ignore_disk_removal --allow_dual_ssd]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>Example expected output:<br/>
              <ac:structured-macro ac:macro-id="b12cf56e-c5aa-4585-b909-29976a6eeb79" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[WARNING: This may perform the single ssd breakfix procedure on a node with dual SSDs. Do you really want to proceed?: [Yes/No] Yes

Repairing node with IP: {CVM_IP}
Single SSD repair successfully initiated]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <h4>Step 2: Monitor Progress</h4>
          <p>Once the script has been executed, the progress of the repair process may be monitored via the <code>ssd_repair_status</code> command:</p>
          <ac:structured-macro ac:macro-id="8952e511-4687-42bf-afed-7b8a6184495c" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Monitor Repair Progress</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ watch -d 'ssd_repair_status']]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>Example expected output:<br/>
              <ac:structured-macro ac:macro-id="f66afeb2-5998-4f36-a78f-59a25ab3f167" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[SSD repair operation ongoing
Current leader is {Genesis Leader IP}
=== Single SSD Repair Info ===
{
  "bp_enabled": false,
  "curr_state": "sm_bring_up_rescue_cvm",
  "host_ip": "{HOST_IP}",
  "host_type": 3,
  "is_sed": false,
  "message": null,
  "prev_state": "sm_create_transfer_svmrescue_image",
  "start_timestamp": "Sat, 12 Jul 2025 15:11:48",
  "svm_id": 6,
  "svm_ip": "{CVM_IP}",
  "task": "1cc1eec3-2720-4046-6644-fcdd8830353f"
}]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <br/>
          </p>
          <p>
            <strong>3.</strong> Further details on the progress of the repair process can be analyzed in the <em> <strong>/home/nutanix/data/logs/genesis.out</strong> </em> log on the CVM which is the current <strong>Genesis leader</strong>.  <span>Execute either of the following commands to identify the current <strong>Genesis leader</strong> to ssh into:</span>
          </p>
          <ac:structured-macro ac:macro-id="ed0c5eee-0727-4e7c-8a83-899f2fc6e536" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Method 1: Find Genesis leader using panacea_cli</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ panacea_cli show_leaders | grep -i genesis]]></ac:plain-text-body>
          </ac:structured-macro>
          <ac:structured-macro ac:macro-id="3d1c5bd9-42b3-4922-9ef3-20d8139a415f" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Method 2: Find Genesis leader using zookeeper</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ service=/appliance/logical/pyleaders/genesis_cluster_manager; echo "Genesis leader is" $(zkcat $service/`zkls $service| head -1`) ; echo]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>- Tail the <em> <strong>/home/nutanix/data/logs/genesis.out</strong> </em> log for entries containing operations done by the `<strong>ssd_breakfix.py</strong>` Python script which carries out the repair process:</p>
          <ac:structured-macro ac:macro-id="0f7b4bbd-7c2b-4f66-bf3a-182da22b58ff" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Monitor ssd_breakfix.py operations</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ tail -F /home/nutanix/data/logs/genesis.out | grep ssd_breakfix.py]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>- If you encounter an task hanging or failing at sm_post_rescue_steps, refer to the <strong>boot_disk_replace.log</strong> on a working CVM to see whether a problem was found while restoring the configuration files to the recreated CVM.</p>
          <ac:structured-macro ac:macro-id="6678ef02-673a-4e06-b556-a973ab682239" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Refer to boot_disk_replace.log for failures in sm_post_rescue_steps phase</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ allssh "tail -n50 /home/nutanix/data/logs/boot_disk_replace.log"]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <br/>
          </p>
          <h4>Step 4: Verify Completion</h4>
          <p>Once the repair process is complete, ensure all cluster services start again on the repaired CVM and that the cluster is returning to a normal operating state with all CVMs participating in the cluster again. <strong>Running NCC is highly encouraged.</strong>
          </p>
          <ac:structured-macro ac:macro-id="af1d6fd4-b71b-4820-a0e6-0b65e7333a4c" ac:name="info" ac:schema-version="1">
            <ac:rich-text-body>
              <p>For clusters larger than 3 nodes, it will take 30 minutes before the recreated CVM will be added back to the Metadata Ring. You can speed this up by navigating to the Hardware Overview page in Prism Element, clicking on this node, and then selecting "<a href="https://portal.nutanix.com/page/documents/details?targetId=Web-Console-Guide-Prism-v7_3:wc-cluster-modify-adding-node-wc-t.html">Enable Metadata Store</a>". <a href="https://nutanix.lightning.force.com/lightning/r/Knowledge_Base__kav/ka0VO0000001zXhYAI/view">KB-8879</a> explains how to monitor the metadata rebalancing operation using the logs.</p>
            </ac:rich-text-body>
          </ac:structured-macro>
        </ac:rich-text-body>
      </ac:structured-macro>
      <h3>Manual SVM Rescue - Advanced manual repair process for complex scenarios</h3>
      <p>This section covers the advanced manual rescue process for complex scenarios where automated methods have failed. This is a last-resort option that requires extensive experience and should only be used when other methods have been exhausted.</p>
      <ac:structured-macro ac:macro-id="manual-rescue-tips" ac:name="warning" ac:schema-version="1">
        <ac:parameter ac:name="title">⚠️ Advanced Process - Use with Caution</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>When to use Manual SVM Rescue:</strong>
          </p>
          <ul>
            <li>Only after single_ssd_repair script has failed</li>
            <li>Complex scenarios requiring manual intervention</li>
            <li>When automated methods are not available</li>
            <li>As a last resort option</li>
          </ul>
          <p>
            <strong>Critical requirements:</strong>
          </p>
          <ul>
            <li>Extensive experience with Nutanix CVM operations</li>
            <li>Proper authorization and support guidance</li>
            <li>Working CVM to create svmrescue.iso</li>
            <li>Access to hypervisor of affected CVM</li>
            <li>Understanding of network configuration</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="expand-manual-svm-rescue" ac:name="expand" ac:schema-version="1">
        <ac:parameter ac:name="title">Click to view advanced manual procedures</ac:parameter>
        <ac:rich-text-body>
          <ac:structured-macro ac:macro-id="manual-rescue-overview" ac:name="warning" ac:schema-version="1">
            <ac:parameter ac:name="title">⚠️ Advanced Manual Process</ac:parameter>
            <ac:rich-text-body>
              <p>
                <strong>This is an advanced manual process for complex scenarios.</strong> Only proceed if:</p>
              <ul>
                <li>The automated <code>single_ssd_repair</code> script has been attempted and failed</li>
                <li>You have extensive experience with Nutanix CVM operations</li>
                <li>You have proper authorization and support guidance</li>
              </ul>
            </ac:rich-text-body>
          </ac:structured-macro>
          <h3>Overview</h3>
          <p>In specific cases, a manual rescue of a CVM may be needed by creating an <strong>svmrescue.iso</strong> image using the <code>make_iso.sh</code> script on a working CVM and mounting/booting the affected CVM into the rescue shell of the <strong>svmrescue.iso</strong> image.</p>
          <p>The `<strong>do_svmrescue.sh`</strong> script within the rescue shell <span> <span style="color: rgb(23,43,77);">will only format the CVM infrastructure partitions (<em> <strong>/home</strong> </em>, <em> <strong>boot</strong> </em>, <em> <strong>altboot</strong> </em> partitions) on the node's associated CVM boot drive(s) and will leave all customer data partitions on the CVM boot drive(s) and associated data drives intact.<br/>
              </span> </span>
          </p>
          <p>
            <span> <span style="color: rgb(23,43,77);">For single-SSD platforms, this will be the <em> <strong>/dev/sda1</strong> </em>, <em> <strong>/dev/sda2</strong> </em>, and <em> <strong>/dev/sda3</strong> </em> partitions.<br/>On multi-NVMe/SSD platforms, this will be the <em> <strong>/dev/md0</strong> </em>, <em> <strong>/dev/md1</strong> </em>, and <em> <strong>/dev/md2</strong> </em> software raid partitions.</span> </span>
          </p>
          <p>
            <ac:image ac:height="400">
              <ri:attachment ri:filename="11.png"/>
            </ac:image>
          </p>
          <h4>Manual SVM Rescue Overview</h4>
          <p>The steps performed during a manual SVM rescue are as follows:</p>
          <table class="wrapped">
            <colgroup> <col/> </colgroup>
            <tbody>
              <tr>
                <td>Create svmrescue.iso on working CVM</td>
              </tr>
              <tr>
                <td>Transfer svmrescue.iso to hypervisor of affected CVM</td>
              </tr>
              <tr>
                <td>Mount svmrescue.iso as affected CVM's boot image file</td>
              </tr>
              <tr>
                <td>Boot affected CVM into svmrescue.iso image</td>
              </tr>
              <tr>
                <td>Run `do_svmrescue.sh` bash script within rescue shell</td>
              </tr>
              <tr>
                <td>Unmount svmrescue.iso and re-mount CVM's original svmboot.iso boot image file</td>
              </tr>
              <tr>
                <td>
                  <p>Boot repaired CVM normally into AOS kernel</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>Configure networking on repaired CVM</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>Run `boot_disk_replace` script from working CVM to restore original cluster configuration information to repaired CVM</p>
                </td>
              </tr>
            </tbody>
          </table>
          <h2>Manual SVM Rescue Procedure</h2>
          <h4>Step 1: Navigate to AOS Installer Directory</h4>
          <p>From a working CVM in the cluster that is running the AOS version which is to be installed on the affected CVM, navigate to the AOS installer directory:</p>
          <ac:structured-macro ac:macro-id="1d69fb92-309d-4e0d-9e3a-6c166129f3a1" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Navigate to AOS installer directory</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ cd /home/nutanix/date/installer/el{X}-release-{AOS version}]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>Example AOS installer directory path:<br/>
              <ac:structured-macro ac:macro-id="24a94a24-9c0c-4d41-a37f-aa12e1ff9344" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[/home/nutanix/date/installer/el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0$]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <br/>
          </p>
          <p>
            <strong>2.</strong> Create a file using a text editor such as <strong>vi</strong>, named <em> <strong>ipconfig.sh</strong> </em> with the following lines:</p>
          <ac:structured-macro ac:macro-id="d27fda6a-bacc-4ec9-bf08-a9e07b49650f" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Create ipconfig.sh file using vi editor</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~/data/installer/el{X}-release-{AOS version}$ vi ipconfig.sh]]></ac:plain-text-body>
          </ac:structured-macro>
          <ac:structured-macro ac:macro-id="d844d45c-fc3e-457c-b179-4a6f8a95f3d8" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">ipconfig.sh content</ac:parameter>
            <ac:plain-text-body><![CDATA[export SVM_INTERFACE=eth1
export SVM_IPADDR=192.168.5.254
export SVM_NETMASK=255.255.255.0]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>Alternatively, the following commands may be run to do so directly from the command line:</p>
          <ac:structured-macro ac:macro-id="a5e34b93-cff7-430f-948b-01004d79668d" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Alternative: Create ipconfig.sh using command line</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~/data/installer/el{X}-release-{AOS version}$ echo 'export SVM_INTERFACE=eth1' > ipconfig.sh
nutanix@cvm:~/data/installer/el{X}-release-{AOS version}$ echo 'export SVM_IPADDR=192.168.5.254' >> ipconfig.sh
nutanix@cvm:~/data/installer/el{X}-release-{AOS version}$ echo 'export SVM_NETMASK=255.255.255.0' >> ipconfig.sh]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <br/>
          </p>
          <p>
            <strong>3.</strong> Create the <strong>svmrescue.iso</strong> image with a GRUB menu timeout value of 120 seconds:</p>
          <ac:structured-macro ac:macro-id="3a8dc1e4-15d0-4f31-b543-247c75506e84" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">Create svmrescue.iso with 120-second timeout</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~/data/installer/el{X}-release-{AOS version}$ ./make_iso.sh svmrescue RescueShell 120]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>Example expected script output during the .iso creation:<br/>
              <ac:structured-macro ac:macro-id="f53a8cb4-c006-4644-b288-613953ed31f5" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[++ dirname ./make_iso.sh
+ dir=.
+ isoname=svmrescue
+ default=RescueShell
+ timeout=120
++ arch
+ arch=x86_64
+ MKISOFS='mkisofs -q -R -uid 0 -gid 0'
+ trap cleanup SIGINT SIGTERM EXIT
+ '[' '!' -z '' ']'
+ '[' RescueShell == Rescue ']'
+ '[' RescueShell == RescueShell ']'
+ default_num=1
+ '[' -f ./boot/grub.cfg ']'
+ rm -rf ./boot/grub/grub.cfg
+ cp ./boot/grub.cfg ./boot/grub/grub.cfg
+ sed -i 's/default=.*/default=1/g' ./boot/grub/grub.cfg
+ sed -i 's/timeout=.*/timeout=120/g' ./boot/grub/grub.cfg
+ echo 'Building svmrescue.iso for x86_64'
Building svmrescue.iso for x86_64
+ '[' x86_64 == x86_64 ']'
+ '[' '!' -f ./boot/grub/i386-pc/eltorito.img ']'
+ MKISOFS_OPTS='-b boot/grub/i386-pc/eltorito.img -no-emul-boot                 -boot-load-size 4 -boot-info-table'
+ get_latest_hcl
+ set +x
Copying hcl.json from /etc/nutanix/hcl.json
+ '[' '!' -z '' ']'
+ mkisofs -q -R -uid 0 -gid 0 -b boot/grub/i386-pc/eltorito.img -no-emul-boot -boot-load-size 4 -boot-info-table -o ./../svmrescue.iso .
+ ret=0
+ exit 0
+ cleanup
+ revert_hcl
++ dirname ./make_iso.sh
+ dir=.
+ aos_bundled_hcl=/home/nutanix/tmp/hcl.json.bundled
+ aos_hcl=./config/hcl.json
+ '[' -f /home/nutanix/tmp/hcl.json.bundled ']'
+ echo 'Moving back /home/nutanix/tmp/hcl.json.bundled to ./config/hcl.json'
Moving back /home/nutanix/tmp/hcl.json.bundled to ./config/hcl.json
+ mv /home/nutanix/tmp/hcl.json.bundled ./config/hcl.json
+ revert_ipconfig
+ '[' -f ./ipconfig.sh ']'
+ cmd='mv -f ./ipconfig.sh ./ipconfig.sh.prev'
+ mv -f ./ipconfig.sh ./ipconfig.sh.prev
+ '[' 0 -ne 0 ']']]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <span style="letter-spacing: 0.0px;">The svmrescue.iso file will be created one directory back in </span> <em style="letter-spacing: 0.0px;"> <strong>/home/nutanix/data/installer</strong> </em> <span style="letter-spacing: 0.0px;">:</span>
          </p>
          <ac:structured-macro ac:macro-id="d98f3597-0f5f-4209-ae16-20e238af9da4" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~/data/installer/el{X}-release-{AOS version}$  cd ../

nutanix@cvm:~/data/installer$  ls -lh svmrescue.iso 
-rw-------. 1 nutanix nutanix 5.4G Jul 12 21:59 svmrescue.iso]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">4. </strong> <span style="letter-spacing: 0.0px;">Transfer the svmrescue.iso file onto the hypervisor of the affected CVM into the hypervisor.</span>
          </p>
          <p>
            <strong>- For AHV:</strong>
          </p>
          <ac:structured-macro ac:macro-id="b22ed6c3-0816-4cf4-8478-a687be49efdc" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~/data/installer$  scp svmrescue.iso root@{HOST_IP}:/var/log/]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <span style="letter-spacing: 0.0px;">Traditionally, the svmrescue.iso file would be transferred onto the AHV host into the </span> <em style="letter-spacing: 0.0px;"> <strong>/var/lib/libvirt/NTNX-CVM</strong> </em> <span style="letter-spacing: 0.0px;"> directory used for the CVM's boot files; however in newer versions of AHV, the </span> <em style="letter-spacing: 0.0px;"> <strong>/var</strong> </em> <span style="letter-spacing: 0.0px;"> mountpoint is only 2.9 GB in size and is insufficient as the resulting created svmrescue.iso file is now 5+ GB in more recent versions of AOS as seen above in the output of Step #3.</span>
          </p>
          <p>
            <span style="color: rgb(23,43,77);">Due to the above-mentioned capacity restrictions, we recommend the <strong>/var/log</strong> directory as this has more available space.</span>
          </p>
          <ac:structured-macro ac:macro-id="43ec6fb1-685c-424d-b616-aabbeac31def" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  df -h /var/lib/libvirt/NTNX-CVM/
Filesystem           Size  Used Avail Use% Mounted on
/dev/mapper/ahv-var  2.9G  208M  2.5G   8% /var


[root@ahv ~]#  df -h /var/log/
Filesystem              Size  Used Avail Use% Mounted on
/dev/mapper/ahv-varlog  208G  671M  197G   1% /var/log]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">5. </strong> <span style="letter-spacing: 0.0px;">ssh into the AHV host of the affected CVM where the svmrescue.iso file was transferred and</span> <strong style="letter-spacing: 0.0px;"> </strong> <span style="letter-spacing: 0.0px;">ensure the MD5 checksum of the svmrescue.iso file is consistent with the working CVM on which it was created:</span>
          </p>
          <ac:structured-macro ac:macro-id="ac409569-c2ff-4231-86e4-30f6f49b1bf8" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$  md5sum /home/nutanix/data/installer/svmrescue.iso 
fb012230b7d85e06bd76eeb626f9cb6d  svmrescue.iso]]></ac:plain-text-body>
          </ac:structured-macro>
          <ac:structured-macro ac:macro-id="c04dcdd1-60e7-484e-964d-0fb1df1e21d4" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  md5sum /var/log/svmrescue.iso 
fb012230b7d85e06bd76eeb626f9cb6d  svmrescue.iso]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">6.</strong> <span style="letter-spacing: 0.0px;"> Change the permissions of the svmrescue.iso file to be owned by the '</span> <strong style="letter-spacing: 0.0px;">qemu</strong> <span style="letter-spacing: 0.0px;">' user with all read-level permissions:</span>
          </p>
          <ac:structured-macro ac:macro-id="955a3529-1496-41ec-ba80-5646343f8af6" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv /var/log]#  chmod 644 svmrescue.iso 

[root@ahv /var/log]#  chown qemu:qemu svmrescue.iso 

[root@ahv /var/log]#  ls -l svmrescue.iso 
-rw-r--r--. 1 qemu qemu 5779675136 Jul 12 22:07 svmrescue.iso]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">7.</strong> <span style="letter-spacing: 0.0px;"> Record the affected CVM's virsh domain name:</span>
          </p>
          <ac:structured-macro ac:macro-id="ebd9fbe5-546f-46f0-a77d-98db68f4aa72" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh list --all

 Id   Name                    State
---------------------------------------
 1    {CVM_NAME}              running]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <br/>
          </p>
          <p>
            <strong>8.</strong> Eject the CVM's current svmboot.iso image from the virtual CD-ROM device and replace it with the svmrescue.iso image:</p>
          <ac:structured-macro ac:macro-id="e59780ae-04c4-4e65-891b-1aeb83d10478" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh change-media {CVM_NAME} hdc --eject
Successfully ejected media.]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>Ensure that the CVM's virtual CD-ROM device is now empty:</p>
          <ac:structured-macro ac:macro-id="fde82897-6e74-4a84-88e4-acdb594b7e8f" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh domblklist {CVM_NAME}

 Target   Source
------------------
 hdc      -]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>Insert the svmrescue.iso image into the CVM's virtual CD-ROM device:</p>
          <ac:structured-macro ac:macro-id="049be3be-8a5a-49a7-9583-f3b15799c531" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh change-media {CVM_NAME} hdc /var/log/svmrescue.iso --insert
Successfully inserted media.]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>Ensure the the CVM's virtual CD-ROM device is now inserted with the svmrescue.iso image:</p>
          <ac:structured-macro ac:macro-id="27516f54-e2f3-4a76-b5e9-564b95b0c2c4" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh domblklist {CVM_NAME}

 Target   Source
----------------------------------
 hdc      /var/log/svmrescue.iso



[root@ahv ~]#  virsh dumpxml {CVM_NAME} | grep -B 2 -A 6 iso

    <disk type='file' device='cdrom'>
      <driver name='qemu' type='raw'/>
      <source file='/var/log/svmrescue.iso' index='3'/>          <<<<<----------
      <backingStore/>
      <target dev='hdc' bus='ide'/>
      <readonly/>
      <alias name='ide0-1-0'/>
      <address type='drive' controller='0' bus='1' target='0' unit='0'/>
    </disk>]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">9.</strong> <span style="letter-spacing: 0.0px;"> If the affected CVM is not already powered down, power down the CVM, then power on the CVM and immediately tail/monitor the CVM's </span> <em style="letter-spacing: 0.0px;"> <strong>/var/log/NTNX.serial.out.0</strong> </em> <span style="letter-spacing: 0.0px;"> serial output log.</span>
          </p>
          <ac:structured-macro ac:macro-id="3b91260d-47cd-4f0e-bf67-bc6d2457db99" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh destroy {CVM_NAME}
Domain '{CVM_NAME}' destroyed

[root@ahv ~]#  virsh start {CVM_NAME} && tail -F /var/log/NTNX.serial.out.0 
Domain '{CVM_NAME}' started]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>Example expected kernel output when tailing the CVM's <em> <strong>/var/log/NTNX.serial.out.0</strong> </em> serial output log when the CVM is booting into the svmrescue.iso image rescue shell:<br/>
              <ac:structured-macro ac:macro-id="00e854cd-eb1d-418d-97b8-fc0826677ce9" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:parameter ac:name="collapse">true</ac:parameter>
                <ac:plain-text-body><![CDATA[[    0.363885] kvm: already loaded the other module
======================
==== LOAD MODULES ====
======================
LOAD: acpi and vmbus
LOAD: looking through acpi, with the following aliases
/sys/bus/acpi/devices/ACPI0010:00/modalias
/sys/bus/acpi/devices/LNXCPU:00/modalias
/sys/bus/acpi/devices/LNXCPU:01/modalias
/sys/bus/acpi/devices/LNXCPU:02/modalias
/sys/bus/acpi/devices/LNXCPU:03/modalias
/sys/bus/acpi/devices/LNXCPU:04/modalias
/sys/bus/acpi/devices/LNXCPU:05/modalias
/sys/bus/acpi/devices/LNXCPU:06/modalias
/sys/bus/acpi/devices/LNXCPU:07/modalias
/sys/bus/acpi/devices/LNXCPU:08/modalias
/sys/bus/acpi/devices/LNXCPU:09/modalias
/sys/bus/acpi/devices/LNXCPU:0a/modalias
/sys/bus/acpi/devices/LNXCPU:0b/modalias
/sys/bus/acpi/devices/LNXPWRBN:00/modalias
/sys/bus/acpi/devices/LNXSYBUS:00/modalias
/sys/bus/acpi/devices/LNXSYBUS:01/modalias
/sys/bus/acpi/devices/LNXSYSTM:00/modalias
/sys/bus/acpi/devices/PNP0303:00/modalias
/sys/bus/acpi/devices/PNP0501:00/modalias
/sys/bus/acpi/devices/PNP0700:00/modalias
/sys/bus/acpi/devices/PNP0A03:00/modalias
/sys/bus/acpi/devices/PNP0A06:00/modalias
/sys/bus/acpi/devices/PNP0A06:01/modalias
/sys/bus/acpi/devices/PNP0A06:02/modalias
/sys/bus/acpi/devices/PNP0B00:00/modalias
/sys/bus/acpi/devices/PNP0C0F:00/modalias
/sys/bus/acpi/devices/PNP0C0F:01/modalias
/sys/bus/acpi/devices/PNP0C0F:02/modalias
/sys/bus/acpi/devices/PNP0C0F:03/modalias
/sys/bus/acpi/devices/PNP0C0F:04/modalias
/sys/bus/acpi/devices/PNP0F13:00/modalias
/sys/bus/acpi/devices/QEMU0002:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/ACPI0010:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:01/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:02/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:03/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:04/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:05/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:06/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:07/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:08/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:09/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:0a/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXCPU:0b/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXPWRBN:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXSYBUS:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXSYBUS:01/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/LNXSYSTM:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0303:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0501:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0700:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0A03:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0A06:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0A06:01/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0A06:02/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0B00:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0C0F:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0C0F:01/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0C0F:02/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0C0F:03/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0C0F:04/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/PNP0F13:00/modalias
LOAD: attempting modprobe /sys/bus/acpi/devices/QEMU0002:00/modalias
LOAD: looking through vmbus, with the following aliases
LOAD: PCI bus contains the following:
00:01.0 Class 0601: 8086:7000
00:04.0 Class 0200: 1af4:1000
00:00.0 Class 0600: 8086:1237
00:01.3 Class 0680: 8086:7113
00:03.0 Class 0200: 1af4:1000
00:01.1 Class 0101: 8086:7010
00:06.0 Class 0107: 1000:0097
00:02.0 Class 0300: 1013:00b8
00:05.0 Class 0200: 1af4:1000
LOAD: load VMD before all others
LOAD: looking through pci, with the following aliases
/sys/bus/pci/devices/0000:00:00.0/modalias
/sys/bus/pci/devices/0000:00:01.0/modalias
/sys/bus/pci/devices/0000:00:01.1/modalias
/sys/bus/pci/devices/0000:00:01.3/modalias
/sys/bus/pci/devices/0000:00:02.0/modalias
/sys/bus/pci/devices/0000:00:03.0/modalias
/sys/bus/pci/devices/0000:00:04.0/modalias
/sys/bus/pci/devices/0000:00:05.0/modalias
/sys/bus/pci/devices/0000:00:06.0/modalias
LOAD: All PCI devices
LOAD: looking through pci, with the following aliases
/sys/bus/pci/devices/0000:00:00.0/modalias
/sys/bus/pci/devices/0000:00:01.0/modalias
/sys/bus/pci/devices/0000:00:01.1/modalias
/sys/bus/pci/devices/0000:00:01.3/modalias
/sys/bus/pci/devices/0000:00:02.0/modalias
/sys/bus/pci/devices/0000:00:03.0/modalias
/sys/bus/pci/devices/0000:00:04.0/modalias
/sys/bus/pci/devices/0000:00:05.0/modalias
/sys/bus/pci/devices/0000:00:06.0/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:00.0/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:01.0/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:01.1/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:01.3/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:02.0/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:03.0/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:04.0/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:05.0/modalias
LOAD: attempting modprobe /sys/bus/pci/devices/0000:00:06.0/modalias
LOAD: All devices after PCI
LOAD: looking through virtio, with the following aliases
/sys/bus/virtio/devices/virtio0/modalias
/sys/bus/virtio/devices/virtio1/modalias
/sys/bus/virtio/devices/virtio2/modalias
LOAD: attempting modprobe /sys/bus/virtio/devices/virtio0/modalias
LOAD: attempting modprobe /sys/bus/virtio/devices/virtio1/modalias
LOAD: attempting modprobe /sys/bus/virtio/devices/virtio2/modalias
LOAD: looking through vio, with the following aliases
modprobe: module 'sr_mod' not found
modprobe: module 'isofs' not found
Extracting /mnt/cdrom/livecd/000-symlinks.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/acl-2.2.52-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/attr-2.4.47-r2.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/baselayout-2.3-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/bash-4.3_p48-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/bridge-utils-1.5-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/bzip2-1.0.6-r7.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/cdrkit-1.1.11-r2.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/coreutils-8.25-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/curl-7.53.0-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/dmidecode-2.12-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/e2fsprogs-1.43.3-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/e2fsprogs-libs-1.43.3-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/ethtool-3.18-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/expat-2.2.0-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/file-5.25-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/findutils-4.6.0-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/fuse-2.9.7-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/gawk-4.1.3-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/gcc-4.9.4-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/glib-2.48.2-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/glibc-2.22-r4.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/gptfdisk-1.0.1-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/grep-2.25-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/gzip-1.8-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/hdparm-9.50-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/hwdata-0.358.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/hwids-20150717-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/ipmitool-1.8.17-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/ipxe-1.0.0_p20160620-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/kmod-22-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/less-487-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libaio-0.3.110-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libffi-3.2.1-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libgcrypt-1.7.3-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libgpg-error-1.24-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libjpeg-turbo-1.5.0-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libpcre-8.39-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libseccomp-2.3.0-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libusb-1.0.19-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libxml2-2.9.4-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/libxslt-1.1.29-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/lshw-02.16b-r2.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/lsiutil-1.62-r2.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/lsscsi-0.28-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/mdadm-3.4-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/megacli-8.07.10-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/msr-tools-1.3-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/nano-2.5.3-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/ncurses-6.0-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/ntfs3g-2016.2.22-r2.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/nvme-cli-1.14.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/openrc-0.22.4-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/openssh-7.3_p1-r7.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/openssl-1.0.2j-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/pam-1.2.1-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/parted-3.2-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/pciutils-3.8.0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/pixman-0.34.0-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/popt-1.16-r2.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/python-2.6.9-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/python-2.7.12-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/python2.6-site.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/python2.7-site.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/qemu-2.8.0-r3.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/readline-6.3_p8-r3.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/sas2ircu-19-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/sas3ircu-5-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/seabios-1.10.1-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/sed-4.2.2-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/sg3_utils-1.42-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/sgabios-0.1_pre8-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/smartmontools-6.4-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/tar-1.29-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/third-party.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/usbutils-008-r1.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/util-linux-2.26.2-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/vgabios-0.7a-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/vim-8.0.0386-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/wimlib-1.11.0-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/xfsprogs-4.5.0-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/xz-utils-5.2.2-r0.tbz2 into temp root...
Extracting /mnt/cdrom/livecd/zlib-1.2.8-r1.tbz2 into temp root...
/mnt/cdrom/ipconfig.sh exists
Starting interface eth0
Starting interface eth1
Starting interface eth2
Applying static IP 192.168.5.254 on interface eth1
ssh-keygen: generating new host keys: RSA DSA ED25519 
SSHD has started.
You may ssh into this machine as soon as you bring up a network interface.]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <strong>10.</strong> Once the affected CVM is finished booting into the rescue shell, from the AHV host ssh into the CVM over the internal 192.168.5.254 IP address as the '<strong>root</strong>' user with default password '<strong>nutanix/4u</strong>':</p>
          <ac:structured-macro ac:macro-id="c6894dd1-d4cb-40c9-9d7a-eb982d935429" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]# ssh root@192.168.5.254]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>If the following error is encountered when trying to ssh into the CVM, enable verbose logging of the ssh command:<br/>
              <ac:structured-macro ac:macro-id="60e13f7f-0e1b-4289-842f-0a9b3859ba31" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[ssh_dispatch_run_fatal: Connection to 192.168.5.254 port 22: invalid argument]]></ac:plain-text-body>
              </ac:structured-macro>
              <ac:structured-macro ac:macro-id="abb27005-88bd-4e94-a5f0-646fae69b791" ac:name="expand" ac:schema-version="1">
                <ac:parameter ac:name="title">Click to see "ssh -vv" output</ac:parameter>
                <ac:rich-text-body>
                  <p>[root@ahv ~]# ssh -vv <a href="mailto:root@192.168.5.254">root@192.168.5.254</a>
                  </p>
                  <p>OpenSSH_8.0p1, OpenSSL 1.1.1k  FIPS 25 Mar 2021<br/>debug1: Reading configuration data /etc/ssh/ssh_config<br/>debug1: /etc/ssh/ssh_config line 56: Applying options for *<br/>debug2: resolve_canonicalize: hostname 192.168.5.254 is address<br/>debug1: FIPS mode initialized<br/>debug2: ssh_connect_direct<br/>debug1: Connecting to 192.168.5.254 [192.168.5.254] port 22.<br/>debug1: Connection established.<br/>debug1: identity file /root/.ssh/id_rsa type -1<br/>debug1: identity file /root/.ssh/id_rsa-cert type -1<br/>debug1: identity file /root/.ssh/id_dsa type -1<br/>debug1: identity file /root/.ssh/id_dsa-cert type -1<br/>debug1: identity file /root/.ssh/id_ecdsa type -1<br/>debug1: identity file /root/.ssh/id_ecdsa-cert type -1<br/>debug1: identity file /root/.ssh/id_ed25519 type -1<br/>debug1: identity file /root/.ssh/id_ed25519-cert type -1<br/>debug1: identity file /root/.ssh/id_xmss type -1<br/>debug1: identity file /root/.ssh/id_xmss-cert type -1<br/>debug1: Local version string SSH-2.0-OpenSSH_8.0<br/>debug1: Remote protocol version 2.0, remote software version OpenSSH_7.3p1-hpn14v11<br/>debug1: match: OpenSSH_7.3p1-hpn14v11 pat OpenSSH_7.0*,OpenSSH_7.1*,OpenSSH_7.2*,OpenSSH_7.3*,OpenSSH_7.4*,OpenSSH_7.5*,OpenSSH_7.6*,OpenSSH_7.7* compat 0x04000002<br/>debug2: fd 3 setting O_NONBLOCK<br/>debug1: Authenticating to 192.168.5.254:22 as 'root'<br/>debug1: SSH2_MSG_KEXINIT sent<br/>debug1: SSH2_MSG_KEXINIT received<br/>debug2: local client KEXINIT proposal<br/>debug2: KEX algorithms: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256,ext-info-c,kex-strict-c-v00@<a href="http://openssh.com">openssh.com</a>
                    <br/>debug2: host key algorithms: <a href="mailto:ecdsa-sha2-nistp256-cert-v01@openssh.com">ecdsa-sha2-nistp256-cert-v01@openssh.com</a>,ecdsa-sha2-nistp384-cert-v01@<a href="http://openssh.com">openssh.com</a>,ecdsa-sha2-nistp521-cert-v01@<a href="http://openssh.com">openssh.com</a>,rsa-sha2-512-cert-v01@<a href="http://openssh.com">openssh.com</a>,rsa-sha2-256-cert-v01@<a href="http://openssh.com">openssh.com</a>,ssh-rsa-cert-v01@<a href="http://openssh.com">openssh.com</a>,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,rsa-sha2-512,rsa-sha2-256,ssh-rsa<br/>debug2: ciphers ctos: aes256-ctr<br/>debug2: ciphers stoc: aes256-ctr<br/>debug2: MACs ctos: hmac-sha2-512,hmac-sha2-256<br/>debug2: MACs stoc: hmac-sha2-512,hmac-sha2-256<br/>debug2: compression ctos: none,zlib@<a href="http://openssh.com">openssh.com</a>,zlib<br/>debug2: compression stoc: none,zlib@<a href="http://openssh.com">openssh.com</a>,zlib<br/>debug2: languages ctos: <br/>debug2: languages stoc: <br/>debug2: first_kex_follows 0 <br/>debug2: reserved 0 <br/>debug2: peer server KEXINIT proposal<br/>debug2: KEX algorithms: <a href="mailto:curve25519-sha256@libssh.org">curve25519-sha256@libssh.org</a>,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256,diffie-hellman-group14-sha1<br/>debug2: host key algorithms: ssh-rsa,rsa-sha2-512,rsa-sha2-256,ssh-ed25519<br/>debug2: ciphers ctos: <a href="mailto:chacha20-poly1305@openssh.com">chacha20-poly1305@openssh.com</a>,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@<a href="http://openssh.com">openssh.com</a>,aes256-gcm@<a href="http://openssh.com">openssh.com</a>
                    <br/>debug2: ciphers stoc: <a href="mailto:chacha20-poly1305@openssh.com">chacha20-poly1305@openssh.com</a>,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@<a href="http://openssh.com">openssh.com</a>,aes256-gcm@<a href="http://openssh.com">openssh.com</a>
                    <br/>debug2: MACs ctos: <a href="mailto:umac-64-etm@openssh.com">umac-64-etm@openssh.com</a>,umac-128-etm@<a href="http://openssh.com">openssh.com</a>,hmac-sha2-256-etm@<a href="http://openssh.com">openssh.com</a>,hmac-sha2-512-etm@<a href="http://openssh.com">openssh.com</a>,hmac-sha1-etm@<a href="http://openssh.com">openssh.com</a>,umac-64@<a href="http://openssh.com">openssh.com</a>,umac-128@<a href="http://openssh.com">openssh.com</a>,hmac-sha2-256,hmac-sha2-512,hmac-sha1<br/>debug2: MACs stoc: <a href="mailto:umac-64-etm@openssh.com">umac-64-etm@openssh.com</a>,umac-128-etm@<a href="http://openssh.com">openssh.com</a>,hmac-sha2-256-etm@<a href="http://openssh.com">openssh.com</a>,hmac-sha2-512-etm@<a href="http://openssh.com">openssh.com</a>,hmac-sha1-etm@<a href="http://openssh.com">openssh.com</a>,umac-64@<a href="http://openssh.com">openssh.com</a>,umac-128@<a href="http://openssh.com">openssh.com</a>,hmac-sha2-256,hmac-sha2-512,hmac-sha1<br/>debug2: compression ctos: none,zlib@<a href="http://openssh.com">openssh.com</a>
                    <br/>debug2: compression stoc: none,zlib@<a href="http://openssh.com">openssh.com</a>
                    <br/>debug2: languages ctos: <br/>debug2: languages stoc: <br/>debug2: first_kex_follows 0 <br/>debug2: reserved 0 <br/>debug1: kex: algorithm: diffie-hellman-group-exchange-sha256<br/>debug1: kex: host key algorithm: rsa-sha2-512<br/>debug1: kex: server-&gt;client cipher: aes256-ctr MAC: hmac-sha2-512 compression: none<br/>debug1: kex: client-&gt;server cipher: aes256-ctr MAC: hmac-sha2-512 compression: none<br/>debug1: kex: diffie-hellman-group-exchange-sha256 need=64 dh_need=64<br/>debug1: kex: diffie-hellman-group-exchange-sha256 need=64 dh_need=64<br/>debug1: SSH2_MSG_KEX_DH_GEX_REQUEST(2048&lt;8192&lt;8192) sent<br/>debug1: got SSH2_MSG_KEX_DH_GEX_GROUP<br/>ssh_dispatch_run_fatal: Connection to 192.168.5.254 port 22: invalid argument</p>
                </ac:rich-text-body>
              </ac:structured-macro>
              <br/>This error is due to these lines expecting the '<strong>diffie-hellman-group-exchange-sha256</strong>' key exchange algorithm:<br/>
              <ac:structured-macro ac:macro-id="43ce0255-a16b-41c6-b164-c9ee145d0842" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[debug1: kex: algorithm: diffie-hellman-group-exchange-sha256
debug1: kex: host key algorithm: rsa-sha2-512
. . .
debug1: kex: diffie-hellman-group-exchange-sha256 need=64 dh_need=64
debug1: kex: diffie-hellman-group-exchange-sha256 need=64 dh_need=64]]></ac:plain-text-body>
              </ac:structured-macro>
              <br/>Run the following ssh command with the additional flags/parameters specified:<br/>
              <ac:structured-macro ac:macro-id="cca5f31f-5e6b-438c-a2fc-a5ff166766ea" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">text</ac:parameter>
                <ac:plain-text-body><![CDATA[[root@ahv ~]#  ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o KexAlgorithms=diffie-hellman-group14-sha256 root@192.168.5.254

Warning: Permanently added '192.168.5.254' (RSA) to the list of known hosts.
root@192.168.5.254's password:  {nutanix/4u}]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <strong>11.</strong> Once logged into the rescue shell, navigate to the top-level '<em> <strong>/</strong> </em>' directory to view the various rescue utilities present.<br/>The `<strong>do_svmrescue.sh</strong>` bash script will be utilized:</p>
          <ac:structured-macro ac:macro-id="fef86ab9-10a0-4884-9fd1-b929daa8ac76" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[rescue ~ #

rescue ~ #  cd /

rescue / #  ls -l
drwxr-xr-x   2 root root 8480 Jul 12 22:51 bin
-rw-r--r--   1 root root 3381 Apr  7 23:05 chroot_env.sh
-rwxr-xr-x   1 root root 2692 Apr  7 23:05 cloudboot
drwxr-xr-x   7 root root 2640 Jul 12 22:51 dev
-rwxr-xr-x   1 root root  314 Apr  7 23:05 dhcp.sh
-rwxr-xr-x   1 root root 2789 Apr  7 23:05 do_rescue_lockdown.py
-rw-r--r--   1 root root  331 Apr  7 23:05 do_rescue_shell.sh
-rw-r--r--   1 root root 1680 Apr  7 23:05 do_slim_svmrescue.sh
-rw-r--r--   1 root root   39 Apr  7 23:05 do_svm_factory_deploy.sh
-rw-r--r--   1 root root 1459 Apr  7 23:05 do_svmrescue.sh                    <<<<<---------- 
-rw-r--r--   1 root root  423 Apr  7 23:05 env.py
drwxr-xr-x  22 root root 1140 Jul 12 22:51 etc
-rwxr-xr-x   1 root root  592 Apr  7 23:05 init
drwxr-xr-x   7 root root  140 Jul 12 22:51 lib
drwxr-xr-x   2 root root  940 Jul 12 22:51 lib32
drwxr-xr-x   4 root root 2280 Jul 12 22:51 lib64
-rwxr-xr-x   1 root root 3732 Apr  7 23:05 livecd.sh
drwxr-xr-x   5 root root  100 Jul 12 22:51 mnt
-rw-r--r--   1 root root 5152 Apr  7 23:05 modules.sh
drwxr-xr-x   5 root root  100 Jul 12 22:51 opt
dr-xr-xr-x 171 root root    0 Jul 12 22:51 proc
-rwxr-xr-x   1 root root  189 Apr  7 23:05 reboot_quick
lrwxrwxrwx   1 root root    9 Apr  7 23:05 rescue_shell -> livecd.sh
drwx------   2 root root   40 Sep 19  2023 root
drwxr-xr-x   2 root root 1740 Jul 12 22:51 sbin
lrwxrwxrwx   1 root root    9 Apr  7 23:05 svm_factory_deploy -> livecd.sh
-rwxr-xr-x   1 root root 5996 Apr  7 23:05 svmboot
-rw-r--r--   1 root root 5800 Apr  7 23:05 svmboot_common.sh
lrwxrwxrwx   1 root root    9 Apr  7 23:05 svmrescue -> livecd.sh
dr-xr-xr-x  12 root root    0 Jul 12 22:51 sys
drwxr-xr-x   2 root root   40 Apr  8 00:22 tmp
drwxr-xr-x  10 root root  220 Jul 12 22:51 usr
drwxr-xr-x   4 root root   80 Jul 12 22:51 var]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>Change the `<strong>do_svmrescue.sh</strong>` bash script to have the executable permissions set:</p>
          <ac:structured-macro ac:macro-id="30ca4fc7-705a-4369-a0f0-008a335c376b" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[rescue / #  chmod +x do_svmrescue.sh

rescue / #  ls -l do_svmrescue.sh
-rwxr-xr-x 1 root root 1459 Apr  7 23:05 do_svmrescue.sh]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">12.</strong> <span style="letter-spacing: 0.0px;"> Run the `</span> <strong style="letter-spacing: 0.0px;">do_svmrescue.sh</strong> <span style="letter-spacing: 0.0px;">` bash script:</span>
          </p>
          <ac:structured-macro ac:macro-id="5bb774b3-1b1e-4758-9a05-5b0a716eec33" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[rescue / #  ./do_svmrescue.sh]]></ac:plain-text-body>
          </ac:structured-macro>
          <ac:structured-macro ac:macro-id="34422fcb-d6d0-4597-ac81-f23f81d0195a" ac:name="tip" ac:schema-version="1">
            <ac:rich-text-body>
              <p>Pay close attention to the on-screen output so as to catch any potential failures. These will be identifiable by log lines starting with the word <strong>CRITICAL</strong>.</p>
            </ac:rich-text-body>
          </ac:structured-macro>
          <p>
            <br/>
          </p>
          <ul style="list-style-type: square;">
            <li>Example expected script output during the rescue operation:<br/>
              <ac:structured-macro ac:macro-id="a0704da5-f110-4300-b585-fa26bea68b13" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:parameter ac:name="collapse">true</ac:parameter>
                <ac:plain-text-body><![CDATA[Imaging SVM...
/mnt/cdrom/ipconfig.sh exists
Skipping config on internal interface eth1

Preparing chroot env...
'/chroot_env.sh' -> '/svmchroot/chroot_env.sh'
'/cloudboot' -> '/svmchroot/cloudboot'
'/dhcp.sh' -> '/svmchroot/dhcp.sh'
'/do_rescue_lockdown.py' -> '/svmchroot/do_rescue_lockdown.py'
'/do_rescue_shell.sh' -> '/svmchroot/do_rescue_shell.sh'
'/do_slim_svmrescue.sh' -> '/svmchroot/do_slim_svmrescue.sh'
'/do_svm_factory_deploy.sh' -> '/svmchroot/do_svm_factory_deploy.sh'
'/do_svmrescue.sh' -> '/svmchroot/do_svmrescue.sh'
'/env.py' -> '/svmchroot/env.py'
'/init' -> '/svmchroot/init'
'/livecd.sh' -> '/svmchroot/livecd.sh'
'/modules.sh' -> '/svmchroot/modules.sh'
'/reboot_quick' -> '/svmchroot/reboot_quick'
'/rescue_shell' -> '/svmchroot/rescue_shell'
'/svm_factory_deploy' -> '/svmchroot/svm_factory_deploy'
'/svmboot' -> '/svmchroot/svmboot'
'/svmboot_common.sh' -> '/svmchroot/svmboot_common.sh'
'/svmrescue' -> '/svmchroot/svmrescue'
'/bin/sudo' -> '/svmchroot/bin/sudo'
Python 3.9 or above is installed
Creating python3 virtualenv under /home/nutanix/cluster/.venv/bin
created virtual environment CPython3.9.20.final.0-64 in 275ms
  creator CPython3Posix(dest=/home/nutanix/cluster/.venv/bin, clear=True, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)
    added seed packages: pip==25.0.1, setuptools==75.8.0, wheel==0.45.1
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /mnt/cdrom/lib/py3
Processing /mnt/cdrom/lib/py3/Babel-2.13.1-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Deprecated-1.2.14-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Flask-1.1.2-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Flask_Babel-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Flask_INIConfig-0.1.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Flask_OAuthlib-0.9.6-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Flask_RESTful-0.3.10-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Flask_uWSGI_WebSocket-0.5.3+nutanix-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/IPy-1.1-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Jinja2-3.0.3-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/M2Crypto-0.40.1-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/Markdown-3.5-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/MarkupSafe-2.1.3-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/PyJWT-1.7.1-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/PyNaCl-1.5.0-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/PySocks-1.7.1-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/PyYAML-5.4.1-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/Rx-1.6.3-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/Werkzeug-0.16.1-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_event_v1-1.1.post255-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_gateway_v0-0.0.post258-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_gateway_v1-1.2.post264-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_host_v0-0.0.post255-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_host_v1-1.8.post255-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_net_v0-0.0.post264-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_net_v1-1.0.post259-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_vmm_v0-0.0.post264-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_client_vmm_v1-1.4.post255-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_py_client-1.1.post38-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ahv_gateway_utils-1.0.post255-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/aniso8601-9.0.1-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/annotated_types-0.6.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/bcrypt-4.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
Processing /mnt/cdrom/lib/py3/blinker-1.6.3-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/boto-2.38.0+nutanix-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/boto3-1.28.74-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/botocore-1.31.74-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/cachelib-0.10.2-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/certifi-2024.7.4-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/cffi-1.16.0-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/charset_normalizer-2.1.1-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/click-8.1.7-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/confluent_kafka-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
Processing /mnt/cdrom/lib/py3/coverage-6.5.0-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/cryptography-41.0.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
Processing /mnt/cdrom/lib/py3/distro-1.8.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/docker-5.0.3-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ecdsa-0.18.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/elasticsearch-7.17.9-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/flatbuffers-23.5.26-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/future-0.18.3-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/gevent-23.9.1+nutanix-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/googleapis_common_protos-1.56.4-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/graphql_core-2.3.2-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/greenlet-3.0.1-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/grpcio-1.48.2-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/idna-3.4-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/importlib_metadata-6.8.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/inflection-0.5.1-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/isodate-0.6.1-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/itsdangerous-0.24-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/jaeger_client-4.8.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/jmespath-0.10.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/jsonschema-2.6.0.post140-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/lxml-4.9.3-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/monotonic-1.6-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nats_py-2.8.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/netaddr-0.7.18-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/netsnmpagent-0.6.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/npyscreen-4.10.5-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ntlm_auth-1.5.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ntnx_api_utils_python-1.0.18-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ntnx_lcm_py_client-2.1.0.999-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ntnx_prism_py_client-16.9.0.4529-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/numpy-1.26.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
Processing /mnt/cdrom/lib/py3/nutanix_atlas_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_catalog_pc_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_cdp_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_cdp_pc_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_cluster_health_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_core_libs_pylibnfs-1.9.6rc1.post192-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/nutanix_core_vmd_py_utils-2.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_ctrl_plane_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_ctrl_plane_lib-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_ctrl_plane_pc_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_ctrl_plane_server-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_dp_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_enterprise_platform_solutions_passthrough_manager-1.0.0.post3+gaa776dc-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_ergon_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_flow_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_gateway_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_iam_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_infra_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_infra_server-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_minerva_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_ntnxdb_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_nusights_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_prismgw_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_python-0.0.0-py39-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_serviceability_client-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_serviceability_lib-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_util-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/nutanix_zeus-1.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/oauthlib-2.1.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_api-1.22.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_exporter_jaeger-1.21.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_exporter_jaeger_proto_grpc-1.21.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_exporter_jaeger_thrift-1.21.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_propagator_jaeger-1.23.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_proto-1.25.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_sdk-1.22.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/opentracing-2.4.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/packaging-23.2-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/paramiko-2.12.0+nutanix-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pexpect-4.8.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pip-24.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pkgconfig-1.5.5-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/ply-3.11-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/prettytable-3.9.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/promise-2.3-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/protobuf-3.19.4-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/psutil-5.9.6-cp39-abi3-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/ptyprocess-0.7.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pyOpenSSL-23.3.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl
Processing /mnt/cdrom/lib/py3/pyasn1-0.5.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pyasn1_modules-0.3.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pycparser-2.21-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pycryptodome-3.19.1-cp35-abi3-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/pycryptodomex-3.19.1-cp35-abi3-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/pydantic-2.6.3-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pydantic_core-2.16.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
Processing /mnt/cdrom/lib/py3/pylibvirt-2.0.0.post9-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/pyspnego-0.10.2-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/python3_saml-1.16.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/python_dateutil-2.8.2-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/python_gflags-3.1.2+nutanix-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/python_gnupg-0.5.1-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/python_jose-3.3.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/python_jsonschema_objects-0.3.10+nutanix-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/python_ldap-3.4.3-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/python_pam-1.8.4-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pytz-2023.3-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pyudev-0.24.1-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pyvmomi-7.0.3+nutanix-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pywinrm-0.3.0+nutanix-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/pyxattr-0.8.1-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/repoze.lru-0.7-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/requests-2.31.0+nutanix-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/requests_ntlm-1.2.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/requests_oauthlib-1.1.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/rsa-4.9-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/s3transfer-0.7.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/setuptools-68.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/six-1.16.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/threadloop-1.0.2-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/thrift-0.16.0-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/tornado-6.1-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/typing_extensions-4.8.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/uWSGI-2.0.22+nutanix-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/urllib3-1.26.15-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/watchdog-3.0.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/wcwidth-0.2.8-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/websocket_client-0.59.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/wrapt-1.16.0-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/xmlsec-1.3.13-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/xmltodict-0.13.0-py2.py3-none-any.whl
Processing /mnt/cdrom/lib/py3/yappi-1.4.0-cp39-cp39-linux_x86_64.whl
Processing /mnt/cdrom/lib/py3/zipp-3.17.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/zope.event-5.0-py3-none-any.whl
Processing /mnt/cdrom/lib/py3/zope.interface-6.1-cp39-cp39-linux_x86_64.whl
Installing collected packages: yappi, wcwidth, uWSGI, thrift, threadloop, Rx, repoze.lru, pywinrm, pytz, python-pam, python-jsonschema-objects, python-jose, python-gnupg, python-gflags, pylibvirt, PyJWT, py-spy, ptyprocess, promise, ply, pexpect, paramiko, opentracing, oauthlib, nutanix-zeus, nutanix-util, nutanix-serviceability-lib, nutanix-serviceability-client, nutanix-python, nutanix-prismgw-client, nutanix-nusights-client, nutanix-ntnxdb-client, nutanix-minerva-client, nutanix-infra-server, nutanix-infra-client, nutanix-iam-client, nutanix-gateway-client, nutanix-flow-client, nutanix-ergon-client, nutanix-dp-client, nutanix-ctrl-plane-server, nutanix-ctrl-plane-pc-client, nutanix-ctrl-plane-lib, nutanix-ctrl-plane-client, nutanix-core-vmd-py-utils, nutanix-core-libs-pylibnfs, nutanix-cluster-health-client, nutanix-cdp-pc-client, nutanix-cdp-client, nutanix-catalog-pc-client, nutanix-atlas-client, ntnx-prism-py-client, ntnx-lcm-py-client, ntnx-api-utils-python, npyscreen, netsnmpagent, netaddr, monotonic, M2Crypto, jsonschema, itsdangerous, isodate, IPy, graphql-core, flatbuffers, Flask-uWSGI-WebSocket, Flask-RESTful, Flask-OAuthlib, Flask-INIConfig, Flask-Babel, confluent-kafka, boto, aniso8601, ahv-gateway-py-client, ahv-gateway-client-vmm-v1, ahv-gateway-client-vmm-v0, ahv-gateway-client-net-v1, ahv-gateway-client-net-v0, ahv-gateway-client-host-v1, ahv-gateway-client-host-v0, ahv-gateway-client-gateway-v1, ahv-gateway-client-gateway-v0, ahv-gateway-client-event-v1, zope.interface, zope.event, zipp, xmltodict, xmlsec, wrapt, Werkzeug, websocket-client, watchdog, urllib3, typing-extensions, tornado, six, setuptools, s3transfer, rsa, requests-oauthlib, requests-ntlm, requests, PyYAML, pyxattr, pyvmomi, pyudev, python3-saml, python-ldap, python-dateutil, pyspnego, PySocks, pyOpenSSL, PyNaCl, pydantic-core, pydantic, pycryptodomex, pycryptodome, pycparser, pyasn1-modules, pyasn1, psutil, protobuf, prettytable, pkgconfig, pip, packaging, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-proto, opentelemetry-propagator-jaeger, opentelemetry-exporter-jaeger-thrift, opentelemetry-exporter-jaeger-proto-grpc, opentelemetry-exporter-jaeger, opentelemetry-api, nutanix-enterprise-platform-solutions-passthrough-manager, numpy, ntlm-auth, nats-py, MarkupSafe, Markdown, lxml, jmespath, Jinja2, jaeger-client, inflection, importlib-metadata, idna, grpcio, greenlet, googleapis-common-protos, gevent, future, Flask, elasticsearch, ecdsa, docker, distro, Deprecated, cryptography, coverage, click, charset-normalizer, cffi, certifi, cachelib, botocore, boto3, blinker, bcrypt, Babel, annotated-types, ahv-gateway-utils
  Attempting uninstall: setuptools
    Found existing installation: setuptools 75.8.0
    Uninstalling setuptools-75.8.0:
      Successfully uninstalled setuptools-75.8.0
  Attempting uninstall: pip
    Found existing installation: pip 25.0.1
    Uninstalling pip-25.0.1:
      Successfully uninstalled pip-25.0.1
Successfully installed Babel-2.13.1 Deprecated-1.2.14 Flask-1.1.2 Flask-Babel-1.0.0 Flask-INIConfig-0.1.0 Flask-OAuthlib-0.9.6 Flask-RESTful-0.3.10 Flask-uWSGI-WebSocket-0.5.3+nutanix IPy-1.1 Jinja2-3.0.3 M2Crypto-0.40.1 Markdown-3.5 MarkupSafe-2.1.3 PyJWT-1.7.1 PyNaCl-1.5.0 PySocks-1.7.1 PyYAML-5.4.1 Rx-1.6.3 Werkzeug-0.16.1 ahv-gateway-client-event-v1-1.1.post255 ahv-gateway-client-gateway-v0-0.0.post258 ahv-gateway-client-gateway-v1-1.2.post264 ahv-gateway-client-host-v0-0.0.post255 ahv-gateway-client-host-v1-1.8.post255 ahv-gateway-client-net-v0-0.0.post264 ahv-gateway-client-net-v1-1.0.post259 ahv-gateway-client-vmm-v0-0.0.post264 ahv-gateway-client-vmm-v1-1.4.post255 ahv-gateway-py-client-1.1 ahv-gateway-utils-1.0.post255 aniso8601-9.0.1 annotated-types-0.6.0 bcrypt-4.0.1 blinker-1.6.3 boto-2.38.0+nutanix boto3-1.28.74 botocore-1.31.74 cachelib-0.10.2 certifi-2024.7.4 cffi-1.16.0 charset-normalizer-2.1.1 click-8.1.7 confluent-kafka-2.3.0 coverage-6.5.0 cryptography-41.0.7 distro-1.8.0 docker-5.0.3 ecdsa-0.18.0 elasticsearch-7.17.9 flatbuffers-23.5.26 future-0.18.3 gevent-23.9.1+nutanix googleapis-common-protos-1.56.4 graphql-core-2.3.2 greenlet-3.0.1 grpcio-1.48.2 idna-3.4 importlib-metadata-6.8.0 inflection-0.5.1 isodate-0.6.1 itsdangerous-0.24 jaeger-client-4.8.0 jmespath-0.10.0 jsonschema-2.6.0.post140 lxml-4.9.3 monotonic-1.6 nats-py-2.8.0 netaddr-0.7.18 netsnmpagent-0.6.0 npyscreen-4.10.5 ntlm-auth-1.5.0 ntnx-api-utils-python-1.0.18 ntnx-lcm-py-client-2.1.0.999 ntnx-prism-py-client-16.9.0.4529 numpy-1.26.0 nutanix-atlas-client-1.0.0 nutanix-catalog-pc-client-1.0.0 nutanix-cdp-client-1.0.0 nutanix-cdp-pc-client-1.0.0 nutanix-cluster-health-client-1.0.0 nutanix-core-libs-pylibnfs-1.9.6rc1.post192 nutanix-core-vmd-py-utils-2.0 nutanix-ctrl-plane-client-1.0.0 nutanix-ctrl-plane-lib-1.0.0 nutanix-ctrl-plane-pc-client-1.0.0 nutanix-ctrl-plane-server-1.0.0 nutanix-dp-client-1.0.0 nutanix-enterprise-platform-solutions-passthrough-manager-1.0.0.post3+gaa776dc nutanix-ergon-client-1.0.0 nutanix-flow-client-1.0.0 nutanix-gateway-client-1.0.0 nutanix-iam-client-1.0.0 nutanix-infra-client-1.0.0 nutanix-infra-server-1.0.0 nutanix-minerva-client-1.0.0 nutanix-ntnxdb-client-1.0.0 nutanix-nusights-client-1.0.0 nutanix-prismgw-client-1.0.0 nutanix-python-0.0.0 nutanix-serviceability-client-1.0.0 nutanix-serviceability-lib-1.0.0 nutanix-util-1.0.0 nutanix-zeus-1.0.0 oauthlib-2.1.0 opentelemetry-api-1.22.0 opentelemetry-exporter-jaeger-1.21.0 opentelemetry-exporter-jaeger-proto-grpc-1.21.0 opentelemetry-exporter-jaeger-thrift-1.21.0 opentelemetry-propagator-jaeger-1.23.0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 opentracing-2.4.0 packaging-23.2 paramiko-2.12.0+nutanix pexpect-4.8.0 pip-24.0 pkgconfig-1.5.5 ply-3.11 prettytable-3.9.0 promise-2.3 protobuf-3.19.4 psutil-5.9.6 ptyprocess-0.7.0 py-spy-0.3.14 pyOpenSSL-23.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycparser-2.21 pycryptodome-3.19.1 pycryptodomex-3.19.1 pydantic-2.6.3 pydantic-core-2.16.3 pylibvirt-2.0.0 pyspnego-0.10.2 python-dateutil-2.8.2 python-gflags-3.1.2+nutanix python-gnupg-0.5.1 python-jose-3.3.0 python-jsonschema-objects-0.3.10+nutanix python-ldap-3.4.3 python-pam-1.8.4 python3-saml-1.16.0 pytz-2023.3 pyudev-0.24.1 pyvmomi-7.0.3+nutanix pywinrm-0.3.0+nutanix pyxattr-0.8.1 repoze.lru-0.7 requests-2.31.0+nutanix requests-ntlm-1.2.0 requests-oauthlib-1.1.0 rsa-4.9 s3transfer-0.7.0 setuptools-68.0.0 six-1.16.0 threadloop-1.0.2 thrift-0.16.0 tornado-6.1 typing-extensions-4.8.0 uWSGI-2.0.22+nutanix urllib3-1.26.15 watchdog-3.0.0 wcwidth-0.2.8 websocket-client-0.59.0 wrapt-1.16.0 xmlsec-1.3.13 xmltodict-0.13.0 yappi-1.4.0 zipp-3.17.0 zope.event-5.0 zope.interface-6.1
Created python3 virtualenv under /home/nutanix/cluster/.venv/bin
Chrooting into /svmchroot
build/bdist.linux-x86_64/egg/util/base/log.py:488: RuntimeWarning: Trying to access flag debug_rss before flags were parsed. This will raise an exception in the future.
ERROR:root:Trying to access flag debug_rss before flags were parsed.
Traceback (most recent call last):
  File "<python_gflags-3.1.2+nutanix>/gflags/flagvalues.py", line 535, in __getattr__
gflags.exceptions.UnparsedFlagAccessError: Trying to access flag debug_rss before flags were parsed.
Unable to read /etc/nutanix/release_version: [Errno 2] No such file or directory: '/etc/nutanix/release_version'
2025-07-12 23:03:35,652Z ERROR layout.py:40 Failed to parse factory_config.json:
Traceback (most recent call last):
  File "build/bdist.linux-x86_64/egg/util/hardware/layout.py", line 35, in should_use_layout
FileNotFoundError: [Errno 2] No such file or directory: '/etc/nutanix/factory_config.json'

2025-07-12 23:03:35,652Z ERROR layout.py:40 Failed to parse factory_config.json:
Traceback (most recent call last):
  File "build/bdist.linux-x86_64/egg/util/hardware/layout.py", line 35, in should_use_layout
FileNotFoundError: [Errno 2] No such file or directory: '/etc/nutanix/factory_config.json'

2025-07-12 23:03:35,652Z ERROR layout.py:40 Failed to parse factory_config.json:
Traceback (most recent call last):
  File "build/bdist.linux-x86_64/egg/util/hardware/layout.py", line 35, in should_use_layout
FileNotFoundError: [Errno 2] No such file or directory: '/etc/nutanix/factory_config.json'

2025-07-12 23:03:35,662Z ERROR layout.py:40 Failed to parse factory_config.json:
Traceback (most recent call last):
  File "build/bdist.linux-x86_64/egg/util/hardware/layout.py", line 35, in should_use_layout
FileNotFoundError: [Errno 2] No such file or directory: '/etc/nutanix/factory_config.json'

2025-07-12 23:03:35,663Z ERROR layout.py:40 Failed to parse factory_config.json:
Traceback (most recent call last):
  File "build/bdist.linux-x86_64/egg/util/hardware/layout.py", line 35, in should_use_layout
FileNotFoundError: [Errno 2] No such file or directory: '/etc/nutanix/factory_config.json'

2025-07-12 23:03:35,663Z ERROR layout.py:40 Failed to parse factory_config.json:
Traceback (most recent call last):
  File "build/bdist.linux-x86_64/egg/util/hardware/layout.py", line 35, in should_use_layout
FileNotFoundError: [Errno 2] No such file or directory: '/etc/nutanix/factory_config.json'

2025-07-12 23:03:35,663Z INFO svm_rescue:1262 Will image ['/dev/sda', '/dev/sdb'] from /mnt/cdrom/images/svm.tar.xz.
2025-07-12 23:03:35,664Z INFO svm_rescue:168 exec_cmd: blkid /dev/sda1
2025-07-12 23:03:35,668Z INFO svm_rescue:168 exec_cmd: blkid /dev/sda2
2025-07-12 23:03:35,671Z INFO svm_rescue:168 exec_cmd: blkid /dev/sda3
2025-07-12 23:03:35,675Z INFO svm_rescue:168 exec_cmd: blkid /dev/sdb1
2025-07-12 23:03:35,679Z INFO svm_rescue:168 exec_cmd: blkid /dev/sdb2
2025-07-12 23:03:35,682Z INFO svm_rescue:168 exec_cmd: blkid /dev/sdb3
2025-07-12 23:03:35,686Z INFO svm_rescue:168 exec_cmd: mdadm --assemble --scan
2025-07-12 23:03:37,147Z INFO svm_rescue:168 exec_cmd: mount /dev/md2 '/mnt/data'
2025-07-12 23:03:37,316Z INFO svm_rescue:168 exec_cmd: umount /dev/md2
2025-07-12 23:03:37,334Z INFO svm_rescue:168 exec_cmd: mount /dev/md0 '/mnt/data'
2025-07-12 23:03:37,483Z INFO svm_rescue:168 exec_cmd: umount /dev/md0
2025-07-12 23:03:37,488Z INFO svm_rescue:168 exec_cmd: mount /dev/md1 '/mnt/data'
2025-07-12 23:03:37,495Z INFO svm_rescue:168 exec_cmd: umount /dev/md1
2025-07-12 23:03:37,498Z INFO svm_rescue:168 exec_cmd: mount /dev/md2 '/mnt/data'
2025-07-12 23:03:37,508Z INFO svm_rescue:168 exec_cmd: umount /dev/md2
2025-07-12 23:03:37,511Z INFO svm_rescue:168 exec_cmd: mount /dev/md0 '/mnt/data'
2025-07-12 23:03:37,518Z INFO svm_rescue:168 exec_cmd: umount /dev/md0
2025-07-12 23:03:37,522Z INFO svm_rescue:168 exec_cmd: mount /dev/md1 '/mnt/data'
2025-07-12 23:03:37,529Z INFO svm_rescue:168 exec_cmd: umount /dev/md1
2025-07-12 23:03:37,533Z INFO svm_rescue:1026 find_svm_volumes: raid_map {'/dev/md0': {'drives': ['/dev/sda1', '/dev/sdb1']}, '/dev/md1': {'drives': ['/dev/sda2', '/dev/sdb2']}, '/dev/md2': {'drives': ['/dev/sda3', '/dev/sdb3']}}
2025-07-12 23:03:37,533Z INFO svm_rescue:1279 CVM MDS: ['/dev/md0', '/dev/md1', '/dev/md2']
2025-07-12 23:03:37,533Z INFO svm_rescue:168 exec_cmd: mdadm --stop /dev/md0
2025-07-12 23:03:37,678Z INFO svm_rescue:168 exec_cmd: mdadm --stop /dev/md1
2025-07-12 23:03:37,788Z INFO svm_rescue:168 exec_cmd: mdadm --stop /dev/md2
2025-07-12 23:03:38,104Z INFO disk_utils.py:44 Found available storage controllers with PCI ids: ['1000:0097']
2025-07-12 23:03:38,131Z INFO svm_rescue:867 Found the following available disks: ['/dev/sdd', '/dev/sdb', '/dev/sdc', '/dev/sda']
2025-07-12 23:03:38,131Z INFO svm_rescue:872 Available disk /dev/sdd
2025-07-12 23:03:38,131Z INFO svm_rescue:872 Available disk /dev/sdb
2025-07-12 23:03:38,131Z INFO svm_rescue:875 Repartitioning disk /dev/sdb
2025-07-12 23:03:38,131Z INFO svm_rescue:168 exec_cmd: parted -s /dev/sdb unit s print
2025-07-12 23:03:38,140Z INFO svm_rescue:829 Detected partition table already present on destination block device /dev/sdb
2025-07-12 23:03:38,140Z INFO svm_rescue:841 Existing partition table on /dev/sdb is valid
2025-07-12 23:03:38,140Z INFO svm_rescue:872 Available disk /dev/sdc
2025-07-12 23:03:38,140Z INFO svm_rescue:872 Available disk /dev/sda
2025-07-12 23:03:38,140Z INFO svm_rescue:875 Repartitioning disk /dev/sda
2025-07-12 23:03:38,140Z INFO svm_rescue:168 exec_cmd: parted -s /dev/sda unit s print
2025-07-12 23:03:38,149Z INFO svm_rescue:829 Detected partition table already present on destination block device /dev/sda
2025-07-12 23:03:38,149Z INFO svm_rescue:841 Existing partition table on /dev/sda is valid
2025-07-12 23:03:38,149Z INFO svm_rescue:1067 All partitions in boot disk /dev/sda: ['/dev/sda4', '/dev/sda3', '/dev/sda2', '/dev/sda1']
2025-07-12 23:03:38,149Z INFO svm_rescue:1056 Boot partitions: ['/dev/sda3', '/dev/sda2', '/dev/sda1']
2025-07-12 23:03:38,149Z INFO svm_rescue:1069 Boot partitions for boot disk /dev/sda: [['/dev/sda1', '/dev/sda2', '/dev/sda3']]
2025-07-12 23:03:38,149Z INFO svm_rescue:1067 All partitions in boot disk /dev/sdb: ['/dev/sdb4', '/dev/sdb3', '/dev/sdb2', '/dev/sdb1']
2025-07-12 23:03:38,149Z INFO svm_rescue:1056 Boot partitions: ['/dev/sdb3', '/dev/sdb2', '/dev/sdb1']
2025-07-12 23:03:38,150Z INFO svm_rescue:1069 Boot partitions for boot disk /dev/sdb: [['/dev/sda1', '/dev/sda2', '/dev/sda3'], ['/dev/sdb1', '/dev/sdb2', '/dev/sdb3']]
2025-07-12 23:03:38,150Z INFO svm_rescue:771 Running blkdiscard on disk /dev/sda1
2025-07-12 23:03:38,150Z INFO svm_rescue:771 Running blkdiscard on disk /dev/sda2
2025-07-12 23:03:38,150Z INFO svm_rescue:771 Running blkdiscard on disk /dev/sda3
2025-07-12 23:03:38,150Z INFO svm_rescue:776 Formatting disks ['/dev/sda1', '/dev/sda2', '/dev/sda3']
2025-07-12 23:03:38,150Z INFO svm_rescue:168 exec_cmd: /mnt/cdrom/bin/clean_disks -p /dev/sda1,/dev/sda2,/dev/sda3
2025-07-12 23:03:40,580Z INFO svm_rescue:771 Running blkdiscard on disk /dev/sdb1
2025-07-12 23:03:40,580Z INFO svm_rescue:771 Running blkdiscard on disk /dev/sdb2
2025-07-12 23:03:40,580Z INFO svm_rescue:771 Running blkdiscard on disk /dev/sdb3
2025-07-12 23:03:40,580Z INFO svm_rescue:776 Formatting disks ['/dev/sdb1', '/dev/sdb2', '/dev/sdb3']
2025-07-12 23:03:40,580Z INFO svm_rescue:168 exec_cmd: /mnt/cdrom/bin/clean_disks -p /dev/sdb1,/dev/sdb2,/dev/sdb3
2025-07-12 23:03:42,981Z INFO disk_utils.py:81 Creating RAID1 volume /dev/md0 from ('/dev/sda1', '/dev/sdb1')
2025-07-12 23:03:42,990Z INFO disk_utils.py:81 Creating RAID1 volume /dev/md1 from ('/dev/sda2', '/dev/sdb2')
2025-07-12 23:03:43,025Z INFO disk_utils.py:81 Creating RAID1 volume /dev/md2 from ('/dev/sda3', '/dev/sdb3')
2025-07-12 23:03:43,069Z INFO svm_rescue:771 Running blkdiscard on disk /dev/md0
2025-07-12 23:03:43,069Z INFO svm_rescue:771 Running blkdiscard on disk /dev/md1
2025-07-12 23:03:43,069Z INFO svm_rescue:771 Running blkdiscard on disk /dev/md2
2025-07-12 23:03:43,069Z INFO svm_rescue:776 Formatting disks ['/dev/md0', '/dev/md1', '/dev/md2']
2025-07-12 23:03:43,070Z INFO svm_rescue:168 exec_cmd: /mnt/cdrom/bin/clean_disks -p /dev/md0,/dev/md1,/dev/md2
2025-07-12 23:03:45,556Z INFO svm_rescue:168 exec_cmd: mount /dev/md0 /mnt/disk
2025-07-12 23:03:45,605Z INFO loopfs_utils.py:77 Creating loop volume /mnt/disk/root/filesystems/var.bin
2025-07-12 23:03:45,609Z INFO loopfs_utils.py:89 Creating volume file with cmd sudo truncate -s 1073741824 '/mnt/disk/root/filesystems/var.bin'
2025-07-12 23:03:45,612Z INFO loopfs_utils.py:97 Creating filesystem with cmd sudo mkfs.ext4 -F -m 1 '/mnt/disk/root/filesystems/var.bin'
2025-07-12 23:03:45,620Z INFO loopfs_utils.py:129 Mounting loop volume /mnt/disk/root/filesystems/var.bin to /mnt/disk/var
2025-07-12 23:03:45,620Z INFO loopfs_utils.py:109 Creating mountpoint /mnt/disk/var
2025-07-12 23:03:45,626Z WARNING sudo.py:307 Directory /mnt/disk/var does not exist
2025-07-12 23:03:45,694Z INFO loopfs_utils.py:77 Creating loop volume /mnt/disk/root/filesystems/varlog.bin
2025-07-12 23:03:45,697Z INFO loopfs_utils.py:89 Creating volume file with cmd sudo truncate -s 1073741824 '/mnt/disk/root/filesystems/varlog.bin'
2025-07-12 23:03:45,701Z INFO loopfs_utils.py:97 Creating filesystem with cmd sudo mkfs.ext4 -F -m 1 '/mnt/disk/root/filesystems/varlog.bin'
2025-07-12 23:03:45,720Z INFO loopfs_utils.py:129 Mounting loop volume /mnt/disk/root/filesystems/varlog.bin to /mnt/disk/var/log
2025-07-12 23:03:45,720Z INFO loopfs_utils.py:109 Creating mountpoint /mnt/disk/var/log
2025-07-12 23:03:45,727Z WARNING sudo.py:307 Directory /mnt/disk/var/log does not exist
2025-07-12 23:03:45,796Z INFO svm_rescue:168 exec_cmd: cd /mnt/disk; tar -xJpf /mnt/cdrom/images/svm.tar.xz; chown root:root .; chmod a+rx .
2025-07-12 23:04:19,844Z INFO loopfs_utils.py:192 Adding loop volume /root/filesystems/var.bin to /mnt/disk/etc/fstab
2025-07-12 23:04:19,849Z INFO loopfs_utils.py:198 Successfully read fstab file /mnt/disk/etc/fstab
2025-07-12 23:04:19,863Z WARNING sudo.py:131 Failed to chcon '/mnt/disk/etc/fstabthu_96b8', ret 1, stdout b'', stderr b"chcon: failed to get security context of '/mnt/disk/etc/fstab': No data available\n"
2025-07-12 23:04:19,875Z INFO loopfs_utils.py:214 Succesfully wrote new fstab to file /mnt/disk/etc/fstab
2025-07-12 23:04:19,875Z INFO loopfs_utils.py:192 Adding loop volume /root/filesystems/varlog.bin to /mnt/disk/etc/fstab
2025-07-12 23:04:19,878Z INFO loopfs_utils.py:198 Successfully read fstab file /mnt/disk/etc/fstab
2025-07-12 23:04:19,891Z WARNING sudo.py:131 Failed to chcon '/mnt/disk/etc/fstab4xib7mne', ret 1, stdout b'', stderr b"chcon: failed to get security context of '/mnt/disk/etc/fstab': No data available\n"
2025-07-12 23:04:19,901Z INFO loopfs_utils.py:214 Succesfully wrote new fstab to file /mnt/disk/etc/fstab
2025-07-12 23:04:19,901Z INFO svm_rescue:168 exec_cmd: mkdir /mnt/disk/var/log/journal
2025-07-12 23:04:19,907Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-bootstrap-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:04:24,882Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:04:24,882Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:04:24,888Z INFO svm_rescue:1127 hardlink output: 

Directories 14
Objects 169
IFREG 154
Comparisons 0
Linked 0
saved 0

2025-07-12 23:04:24,888Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-core-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:14,401Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:14,401Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:14,767Z INFO svm_rescue:1127 hardlink output: 

Directories 130
Objects 3153
IFREG 2932
Comparisons 751
Linked 745
saved 307036160

2025-07-12 23:05:14,767Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-clusters-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.gz'
2025-07-12 23:05:14,773Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:14,773Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:14,786Z INFO svm_rescue:1127 hardlink output: 

Directories 131
Objects 3157
IFREG 2935
Comparisons 6
Linked 0
saved 0

2025-07-12 23:05:14,787Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-pe-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:19,339Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:19,339Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:21,187Z INFO svm_rescue:1127 hardlink output: 

Directories 535
Objects 7977
IFREG 7350
Comparisons 2207
Linked 2143
saved 171806720

2025-07-12 23:05:21,188Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-diagnostics-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:22,616Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:22,617Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:22,744Z INFO svm_rescue:1127 hardlink output: 

Directories 541
Objects 8076
IFREG 7443
Comparisons 209
Linked 152
saved 86347776

2025-07-12 23:05:22,745Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-infrastructure-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:29,878Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:29,878Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:30,022Z INFO svm_rescue:1127 hardlink output: 

Directories 575
Objects 8695
IFREG 8018
Comparisons 280
Linked 223
saved 190652416

2025-07-12 23:05:30,022Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-lcm-3.1.1.61127.tar.xz'
2025-07-12 23:05:34,216Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:34,216Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:34,294Z INFO svm_rescue:1127 hardlink output: 

Directories 642
Objects 9084
IFREG 8340
Comparisons 248
Linked 184
saved 112009216

2025-07-12 23:05:34,295Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-ikatproxy-master.tar.xz'
2025-07-12 23:05:35,011Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:35,012Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:35,043Z INFO svm_rescue:1127 hardlink output: 

Directories 645
Objects 9090
IFREG 8343
Comparisons 64
Linked 0
saved 0

2025-07-12 23:05:35,043Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-ikatcontrolplane-master.tar.xz'
2025-07-12 23:05:36,352Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:36,352Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:36,383Z INFO svm_rescue:1127 hardlink output: 

Directories 648
Objects 9099
IFREG 8349
Comparisons 64
Linked 0
saved 0

2025-07-12 23:05:36,384Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-networkservice-1.0.164.tar.xz'
2025-07-12 23:05:37,434Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:37,434Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:37,465Z INFO svm_rescue:1127 hardlink output: 

Directories 651
Objects 9104
IFREG 8351
Comparisons 64
Linked 0
saved 0

2025-07-12 23:05:37,466Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-serviceability-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:42,372Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:42,372Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:42,494Z INFO svm_rescue:1127 hardlink output: 

Directories 777
Objects 10071
IFREG 9192
Comparisons 1299
Linked 1231
saved 162959360

2025-07-12 23:05:42,494Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-ncc-el8.5-release-ncc-5.1.1-x86_64-latest.tar.gz'
2025-07-12 23:05:49,604Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:49,605Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:49,972Z INFO svm_rescue:1127 hardlink output: 

Directories 1036
Objects 11570
IFREG 10426
Comparisons 331
Linked 264
saved 245985280

2025-07-12 23:05:49,972Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-minervacvm-el8.5-release-5.0.0.1-8da0965291d7453229238d58dc1abc3f09f4031d-x86_64.tar.gz'
2025-07-12 23:05:50,923Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:50,923Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:50,999Z INFO svm_rescue:1127 hardlink output: 

Directories 1256
Objects 13128
IFREG 11764
Comparisons 1239
Linked 1155
saved 21323776

2025-07-12 23:05:51,000Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-perftools-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:55,646Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:55,646Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:55,975Z INFO svm_rescue:1127 hardlink output: 

Directories 1260
Objects 13258
IFREG 11890
Comparisons 612
Linked 540
saved 145825792

2025-07-12 23:05:55,976Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/srv/; tar -xf /mnt/cdrom/pkg/nutanix-salt-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:55,988Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/srv/;hardlink -c -v .
2025-07-12 23:05:55,988Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/srv/;hardlink -c -v .'
2025-07-12 23:05:55,993Z INFO svm_rescue:1127 hardlink output: 

Directories 28
Objects 167
IFREG 139
Comparisons 0
Linked 0
saved 0

2025-07-12 23:05:55,994Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-intentgateway-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:57,643Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:57,643Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:57,688Z INFO svm_rescue:1127 hardlink output: 

Directories 1302
Objects 13387
IFREG 11977
Comparisons 74
Linked 1
saved 4096

2025-07-12 23:05:57,689Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-clusterconfig-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:57,694Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:57,695Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:57,737Z INFO svm_rescue:1127 hardlink output: 

Directories 1302
Objects 13388
IFREG 11978
Comparisons 73
Linked 0
saved 0

2025-07-12 23:05:57,737Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-zkcore-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:05:57,743Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:05:57,743Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:05:57,784Z INFO svm_rescue:1127 hardlink output: 

Directories 1302
Objects 13389
IFREG 11979
Comparisons 73
Linked 0
saved 0

2025-07-12 23:05:57,784Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-athena-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:06:03,540Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:06:03,540Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:06:03,586Z INFO svm_rescue:1127 hardlink output: 

Directories 1304
Objects 13398
IFREG 11986
Comparisons 73
Linked 0
saved 0

2025-07-12 23:06:03,586Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix; tar -xf /mnt/cdrom/pkg/nutanix-xtrim-el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0.tar.xz'
2025-07-12 23:06:03,594Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/disk/usr/local/nutanix;hardlink -c -v .
2025-07-12 23:06:03,594Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/disk/usr/local/nutanix;hardlink -c -v .'
2025-07-12 23:06:03,637Z INFO svm_rescue:1127 hardlink output: 

Directories 1304
Objects 13400
IFREG 11988
Comparisons 73
Linked 0
saved 0

2025-07-12 23:06:03,638Z INFO svm_rescue:1397 Making post deployment modifications on /dev/md0
2025-07-12 23:06:05,142Z INFO svm_rescue:737 Root filesystem (on /dev/md0) UUID is cf77fe64-b757-4344-94b6-6780957c5f4b instead of ad6af956-f77d-45dd-8d44-9c006cbaddd5.
2025-07-12 23:06:05,166Z INFO svm_rescue:1093 Injecting mdadm.conf into boot partition.
2025-07-12 23:06:05,167Z INFO svm_rescue:1099 Injecting mdadm.conf into initrd /mnt/disk/boot/initramfs-5.10.224-2.el8.nutanix.20241212.100223.x86_64.img
2025-07-12 23:06:05,167Z INFO svm_rescue:168 exec_cmd: cd /tmp/tmprpb2f1wp; gunzip -c /mnt/disk/boot/initramfs-5.10.224-2.el8.nutanix.20241212.100223.x86_64.img | cpio -id
2025-07-12 23:06:06,036Z INFO svm_rescue:168 exec_cmd: cd /tmp/tmprpb2f1wp; find . | cpio -o -H newc | gzip > /mnt/disk/boot/initramfs-5.10.224-2.el8.nutanix.20241212.100223.x86_64.img
2025-07-12 23:06:11,254Z INFO svm_rescue:285 Creating Nutanix boot marker file from grub.conf ...
2025-07-12 23:06:11,268Z ERROR genesis_utils.py:3131 Unable to fetch cluster_functions from cached proto
2025-07-12 23:06:11,268Z INFO svm_rescue:299 Wrote marker file, contents:
KERNEL=/boot/vmlinuz-5.10.224-2.el8.nutanix.20241212.100223.x86_64
CMDLINE='ro rd_NO_LUKS rd_NO_LVM rd_NO_DM LANG=en_US.UTF-8 SYSFONT=latarcyrheb-sun16 rhgb KEYBOARDTYPE=pc KEYTABLE=us audit=1 audit_backlog_limit=8192 watchdog_thresh=20 nousb nomodeset biosdevname=0 net.ifnames=0 scsi_mod.use_blk_mq=y clocksource=tsc hv_netvsc.ring_size=512 mds=off panic=30 mpt2sas.prot_mask=1 mpt3sas.prot_mask=1 mpt3sas.hbas_to_enumerate=0 mpt2sas.issue_scsi_cmd_to_bringup_drive=0 mpt3sas.issue_scsi_cmd_to_bringup_drive=0 iavmd.direct_assign=1 vmd.direct_assign=1 page_poison=0 slub_debug=n pti=off fips=1 vsyscall=none mitigations=off,eibrs crashkernel=no rd_MD_UUID=81b195a2:ccb50c3f:4ffb4457:651111ff root=UUID=cf77fe64-b757-4344-94b6-6780957c5f4b console=ttyS0,115200n8 console=tty0'
INITRD=/boot/initramfs-5.10.224-2.el8.nutanix.20241212.100223.x86_64.img

2025-07-12 23:06:11,268Z INFO svm_rescue:315 Will try to copy /sys/class/dmi/id/product_uuid to /mnt/disk/.cvm_uuid
2025-07-12 23:06:11,268Z ERROR svm_rescue:329 Unable to create CVM UUID Marker. Error: [Errno 2] No such file or directory: '/sys/class/dmi/id/product_uuid'
2025-07-12 23:06:11,268Z ERROR svm_rescue:1430 Unable to create CVM UUID marker.
2025-07-12 23:06:11,268Z INFO svm_rescue:528 Adding /dev/md2 to /etc/fstab to be mounted at /home...
2025-07-12 23:06:11,275Z INFO svm_rescue:572 Adding journal log bind entry in fstab, path: /mnt/disk/etc/fstab
2025-07-12 23:06:11,275Z INFO svm_rescue:168 exec_cmd: mount /dev/md2 /mnt/data
2025-07-12 23:06:11,283Z INFO loopfs_utils.py:77 Creating loop volume /mnt/data/log/home_log_audit.bin
2025-07-12 23:06:11,287Z INFO loopfs_utils.py:89 Creating volume file with cmd sudo truncate -s 52428800 '/mnt/data/log/home_log_audit.bin'
2025-07-12 23:06:11,290Z INFO loopfs_utils.py:97 Creating filesystem with cmd sudo mkfs.ext4 -F -m 1 '/mnt/data/log/home_log_audit.bin'
2025-07-12 23:06:11,296Z INFO loopfs_utils.py:109 Creating mountpoint /mnt/data/log/audit
2025-07-12 23:06:11,299Z INFO loopfs_utils.py:192 Adding loop volume /home/log/home_log_audit.bin to /mnt/disk/etc/fstab
2025-07-12 23:06:11,302Z INFO loopfs_utils.py:198 Successfully read fstab file /mnt/disk/etc/fstab
2025-07-12 23:06:11,315Z WARNING sudo.py:131 Failed to chcon '/mnt/disk/etc/fstabdu85fhdb', ret 1, stdout b'', stderr b"chcon: failed to get security context of '/mnt/disk/etc/fstab': No data available\n"
2025-07-12 23:06:11,324Z INFO loopfs_utils.py:214 Succesfully wrote new fstab to file /mnt/disk/etc/fstab
2025-07-12 23:06:11,324Z INFO svm_rescue:591 Adding /var/log/audit bind entry in fstab, path: /mnt/disk/etc/fstab
2025-07-12 23:06:11,325Z INFO svm_rescue:1529 Fixing permissions on /home.
2025-07-12 23:06:11,325Z INFO svm_rescue:1529 Fixing permissions on /home./nutanix
2025-07-12 23:06:11,325Z INFO svm_rescue:1554 Copying installer to /mnt/data/nutanix/data/installer/el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0
2025-07-12 23:06:11,325Z INFO svm_rescue:168 exec_cmd: tar -C '/mnt/cdrom' -cf - . | tar -C '/mnt/data/nutanix/data/installer/el8.5-release-ganges-7.0.1.5-stable-2b92eec28a15b783f394a639a46583d5d9584ab0' -xf -
2025-07-12 23:06:20,314Z INFO svm_rescue:168 exec_cmd: tar -xf /mnt/cdrom/pkg/nutanix-foundation-5.7.1-20250131-b100e38c.tar.xz -C /mnt/data/nutanix
2025-07-12 23:06:41,980Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/data/nutanix/flow_staging; tar -xf /mnt/cdrom/pkg/nutanix-flow-4.2.0.tar.xz'
2025-07-12 23:06:46,653Z INFO svm_rescue:1121 hardlink all duplicate files: cd /mnt/data/nutanix/flow_staging;hardlink -c -v .
2025-07-12 23:06:46,653Z INFO svm_rescue:168 exec_cmd: bash -c 'cd /mnt/data/nutanix/flow_staging;hardlink -c -v .'
2025-07-12 23:06:46,658Z INFO svm_rescue:1127 hardlink output: 

Directories 7
Objects 151
IFREG 144
Comparisons 0
Linked 0
saved 0

2025-07-12 23:06:46,659Z INFO svm_rescue:1624 Setting up SSH configuration
2025-07-12 23:06:46,659Z INFO sshkeys_helper.py:927 Writing ssh configuration to a temporary file
2025-07-12 23:06:46,659Z INFO sshkeys_helper.py:931 Overwriting temporary file to /mnt/disk/root/.ssh/config
2025-07-12 23:06:46,659Z INFO sshkeys_helper.py:927 Writing ssh configuration to a temporary file
2025-07-12 23:06:46,660Z INFO sshkeys_helper.py:931 Overwriting temporary file to /mnt/data/nutanix/.ssh/config
2025-07-12 23:06:46,660Z INFO svm_rescue:1634 Writing out rc.nutanix
2025-07-12 23:06:46,660Z INFO svm_rescue:1712 Running setfiles.sh on the chroot: /mnt/disk
2025-07-12 23:07:06,894Z INFO svm_rescue:168 exec_cmd: sync; sync; sync
2025-07-12 23:07:06,905Z INFO svm_rescue:168 exec_cmd: umount -R /mnt/disk
2025-07-12 23:07:07,598Z INFO svm_rescue:168 exec_cmd: umount -R /mnt/data
Tearing down chroot...
Reimaging complete. Shutting down...]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <span style="letter-spacing: 0.0px;">If the rescued CVM does not power down automatically despite the last line of the script output, manually power down the CVM:<br/>
            </span>
          </p>
          <ac:structured-macro ac:macro-id="ac6f788b-0083-4bae-82bf-d80e2cdcd2e7" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh destroy {CVM_NAME}
Domain '{CVM_NAME}' destroyed


[root@ahv ~]#  virsh list --all

 Id   Name                    State
----------------------------------------
 -    {CVM_NAME}   shut off]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">13.</strong> <span style="letter-spacing: 0.0px;"> </span> <span style="letter-spacing: 0.0px;">Eject the svmrecue.iso image from the virtual CD-ROM device and replace it with the original svmboot.iso image:</span>
          </p>
          <ac:structured-macro ac:macro-id="baa9dc8f-e9e6-42bf-b035-e2d9b129ed50" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh change-media {CVM_NAME} hdc --eject
Successfully ejected media.]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <span style="color: rgb(23,43,77);">Ensure that the CVM's virtual CD-ROM device is now empty:</span>
          </p>
          <ac:structured-macro ac:macro-id="5a48d6ed-0a36-4c2a-9651-ea71f9dbe6a5" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh domblklist {CVM_NAME}

 Target   Source
------------------
 hdc      -]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <span style="color: rgb(23,43,77);">Insert the svmboot.iso image into the CVM's virtual CD-ROM device:</span>
          </p>
          <ac:structured-macro ac:macro-id="f531fbfc-a772-48a6-affe-03c336c8a0dd" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh change-media {CVM_NAME} hdc /var/lib/libvirt/NTNX-CVM/svmboot.iso --insert
Successfully inserted media.]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <span style="color: rgb(23,43,77);">Ensure the the CVM's virtual CD-ROM device is now inserted with the original svmboot.iso image:</span>
          </p>
          <ac:structured-macro ac:macro-id="0d1e57eb-5384-48b6-bc3e-e058811b7ee4" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh domblklist {CVM_NAME}

 Target   Source
-------------------------------------------------
 hdc      /var/lib/libvirt/NTNX-CVM/svmboot.iso


[root@ahv ~]#  virsh dumpxml {CVM_NAME} | grep -B 2 -A 6 iso
    <disk type='file' device='cdrom'>
      <driver name='qemu' type='raw'/>
      <source file='/var/lib/libvirt/NTNX-CVM/svmboot.iso'/>          <<<<<---------- 
      <target dev='hdc' bus='ide'/>
      <readonly/>
      <address type='drive' controller='0' bus='1' target='0' unit='0'/>
    </disk>]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">14.</strong> <span style="letter-spacing: 0.0px;"> Boot the CVM normally into the newly installed AOS kernel:</span>
          </p>
          <ac:structured-macro ac:macro-id="bb1d5601-16cd-4a20-9595-41e3f0005745" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  virsh start {CVM_NAME} && tail -F /var/log/NTNX.serial.out.0 
Domain '{CVM_NAME}' started]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>
              <span style="color: rgb(23,43,77);">Example expected kernel output when tailing the CVM's <em style="text-align: left;"> <strong>/var/log/NTNX.serial.out.0</strong> </em> <span> </span>serial output log when the CVM is booting normally into the AOS kernel:<br/>
              </span>
              <ac:structured-macro ac:macro-id="701ff64c-04f9-42c2-85ca-d14095398a8c" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:parameter ac:name="collapse">true</ac:parameter>
                <ac:plain-text-body><![CDATA[[    0.000000] Linux version 5.10.224-2.el8.nutanix.20241212.100223.x86_64 (root@ip-10-192-14-249) (gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-22), GNU ld version 2.30-125.el8_10) #1 SMP Thu Dec 12 06:24:08 UTC 2024
[    0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-5.10.224-2.el8.nutanix.20241212.100223.x86_64 ro rd_NO_LUKS rd_NO_LVM rd_NO_DM LANG=en_US.UTF-8 SYSFONT=latarcyrheb-sun16 rhgb KEYBOARDTYPE=pc KEYTABLE=us audit=1 audit_backlog_limit=8192 watchdog_thresh=20 nousb nomodeset biosdevname=0 net.ifnames=0 scsi_mod.use_blk_mq=y clocksource=tsc hv_netvsc.ring_size=512 mds=off panic=30 mpt2sas.prot_mask=1 mpt3sas.prot_mask=1 mpt3sas.hbas_to_enumerate=0 mpt2sas.issue_scsi_cmd_to_bringup_drive=0 mpt3sas.issue_scsi_cmd_to_bringup_drive=0 iavmd.direct_assign=1 vmd.direct_assign=1 page_poison=0 slub_debug=n pti=off fips=1 vsyscall=none mitigations=off,eibrs crashkernel=256M console=tty0 console=ttyS0,115200n8
[    0.000000] BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable
[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000001ffdffff] usable
[    0.000000] BIOS-e820: [mem 0x000000001ffe0000-0x000000001fffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000feffc000-0x00000000feffffff] reserved
[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000100000000-0x00000008dfffffff] usable
[    0.000000] NX (Execute Disable) protection: active
[    0.000000] SMBIOS 2.8 present.
[    0.000000] DMI: Red Hat KVM, BIOS nutanix-ahv-10.0s5c7r2.el8 04/01/2014
[    0.000000] Hypervisor detected: KVM
[    0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00
[    0.000000] kvm-clock: cpu 0, msr 8a8b50001, primary cpu clock
[    0.000000] kvm-clock: using sched offset of 16787095571 cycles
[    0.000002] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns
[    0.000004] tsc: Detected 2499.998 MHz processor
[    0.000951] last_pfn = 0x8e0000 max_arch_pfn = 0x400000000
[    0.001002] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  
[    0.001011] last_pfn = 0x1ffe0 max_arch_pfn = 0x400000000
[    0.001021] kexec: Reserving the low 1M of memory for crashkernel
[    0.001047] Using GB pages for direct mapping
[    0.001220] RAMDISK: [mem 0x1bd9e000-0x1e11bfff]
[    0.001222] ACPI: Early table checksum verification disabled
[    0.001224] ACPI: RSDP 0x00000000000F51D0 000014 (v00 BOCHS )
[    0.001228] ACPI: RSDT 0x000000001FFE2105 000034 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.001233] ACPI: FACP 0x000000001FFE1E31 000074 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.001238] ACPI: DSDT 0x000000001FFE0040 001DF1 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.001241] ACPI: FACS 0x000000001FFE0000 000040
[    0.001243] ACPI: APIC 0x000000001FFE1EA5 0000D0 (v03 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.001246] ACPI: SRAT 0x000000001FFE1F75 000168 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.001249] ACPI: WAET 0x000000001FFE20DD 000028 (v01 BOCHS  BXPC     00000001 BXPC 00000001)
[    0.001252] ACPI: Reserving FACP table memory at [mem 0x1ffe1e31-0x1ffe1ea4]
[    0.001253] ACPI: Reserving DSDT table memory at [mem 0x1ffe0040-0x1ffe1e30]
[    0.001254] ACPI: Reserving FACS table memory at [mem 0x1ffe0000-0x1ffe003f]
[    0.001255] ACPI: Reserving APIC table memory at [mem 0x1ffe1ea5-0x1ffe1f74]
[    0.001256] ACPI: Reserving SRAT table memory at [mem 0x1ffe1f75-0x1ffe20dc]
[    0.001257] ACPI: Reserving WAET table memory at [mem 0x1ffe20dd-0x1ffe2104]
[    0.001335] SRAT: PXM 0 -> APIC 0x00 -> Node 0
[    0.001337] SRAT: PXM 0 -> APIC 0x01 -> Node 0
[    0.001338] SRAT: PXM 0 -> APIC 0x02 -> Node 0
[    0.001340] SRAT: PXM 0 -> APIC 0x03 -> Node 0
[    0.001342] SRAT: PXM 0 -> APIC 0x04 -> Node 0
[    0.001343] SRAT: PXM 0 -> APIC 0x05 -> Node 0
[    0.001345] SRAT: PXM 0 -> APIC 0x06 -> Node 0
[    0.001347] SRAT: PXM 0 -> APIC 0x07 -> Node 0
[    0.001348] SRAT: PXM 0 -> APIC 0x08 -> Node 0
[    0.001350] SRAT: PXM 0 -> APIC 0x09 -> Node 0
[    0.001352] SRAT: PXM 0 -> APIC 0x0a -> Node 0
[    0.001353] SRAT: PXM 0 -> APIC 0x0b -> Node 0
[    0.001357] ACPI: SRAT: Node 0 PXM 0 [mem 0x00000000-0x0009ffff]
[    0.001359] ACPI: SRAT: Node 0 PXM 0 [mem 0x00100000-0x1fffffff]
[    0.001361] ACPI: SRAT: Node 0 PXM 0 [mem 0x100000000-0x8dfffffff]
[    0.001365] NUMA: Node 0 [mem 0x00000000-0x0009ffff] + [mem 0x00100000-0x1fffffff] -> [mem 0x00000000-0x1fffffff]
[    0.001367] NUMA: Node 0 [mem 0x00000000-0x1fffffff] + [mem 0x100000000-0x8dfffffff] -> [mem 0x00000000-0x8dfffffff]
[    0.001372] NODE_DATA(0) allocated [mem 0x8dfff8000-0x8dfffffff]
[    0.001384] Reserving 256MB of memory at 176MB for crashkernel (System RAM: 32767MB)
[    0.001414] Zone ranges:
[    0.001415]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.001417]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff]
[    0.001418]   Normal   [mem 0x0000000100000000-0x00000008dfffffff]
[    0.001419]   Device   empty
[    0.001421] Movable zone start for each node
[    0.001422] Early memory node ranges
[    0.001423]   node   0: [mem 0x0000000000001000-0x000000000009efff]
[    0.001424]   node   0: [mem 0x0000000000100000-0x000000001ffdffff]
[    0.001425]   node   0: [mem 0x0000000100000000-0x00000008dfffffff]
[    0.001429] Initmem setup node 0 [mem 0x0000000000001000-0x00000008dfffffff]
[    0.001440] On node 0, zone DMA: 1 pages in unavailable ranges
[    0.001461] On node 0, zone DMA: 97 pages in unavailable ranges
[    0.043736] On node 0, zone Normal: 32 pages in unavailable ranges
[    0.044163] ACPI: PM-Timer IO Port: 0x608
[    0.044173] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])
[    0.044200] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23
[    0.044202] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
[    0.044204] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)
[    0.044205] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
[    0.044206] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)
[    0.044207] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)
[    0.044212] Using ACPI (MADT) for SMP configuration information
[    0.044214] TSC deadline timer available
[    0.044215] smpboot: Allowing 12 CPUs, 0 hotplug CPUs
[    0.044226] kvm-guest: KVM setup pv remote TLB flush
[    0.044231] kvm-guest: setup PV sched yield
[    0.044245] [mem 0x20000000-0xfeffbfff] available for PCI devices
[    0.044246] Booting paravirtualized kernel on KVM
[    0.044248] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns
[    0.048830] setup_percpu: NR_CPUS:256 nr_cpumask_bits:256 nr_cpu_ids:12 nr_node_ids:1
[    0.049136] percpu: Embedded 58 pages/cpu s198680 r8192 d30696 u262144
[    0.049167] kvm-guest: stealtime: cpu 0, msr 8bfa1bf00
[    0.049171] kvm-guest: PV spinlocks enabled
[    0.049174] PV qspinlock hash table entries: 256 (order: 0, 4096 bytes, linear)
[    0.049180] Built 1 zonelists, mobility grouping on.  Total pages: 8257248
[    0.049181] Policy zone: Normal
[    0.049183] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-5.10.224-2.el8.nutanix.20241212.100223.x86_64 ro rd_NO_LUKS rd_NO_LVM rd_NO_DM LANG=en_US.UTF-8 SYSFONT=latarcyrheb-sun16 rhgb KEYBOARDTYPE=pc KEYTABLE=us audit=1 audit_backlog_limit=8192 watchdog_thresh=20 nousb nomodeset biosdevname=0 net.ifnames=0 scsi_mod.use_blk_mq=y clocksource=tsc hv_netvsc.ring_size=512 mds=off panic=30 mpt2sas.prot_mask=1 mpt3sas.prot_mask=1 mpt3sas.hbas_to_enumerate=0 mpt2sas.issue_scsi_cmd_to_bringup_drive=0 mpt3sas.issue_scsi_cmd_to_bringup_drive=0 iavmd.direct_assign=1 vmd.direct_assign=1 page_poison=0 slub_debug=n pti=off fips=1 vsyscall=none mitigations=off,eibrs crashkernel=256M console=tty0 console=ttyS0,115200n8
[    0.049352] audit: enabled (after initialization)
[    0.049366] audit: audit_backlog_limit: 8192
[    0.049412] You have booted with nomodeset. This means your GPU drivers are DISABLED
[    0.049413] Any video related functionality will be severely degraded, and you may not even be able to suspend the system properly
[    0.049414] Unless you actually understand what nomodeset does, you should reboot without enabling it
[    0.049671] slub_debug option 'n' unknown. skipped
[    0.049701] fips mode: enabled
[    0.051292] Dentry cache hash table entries: 4194304 (order: 13, 33554432 bytes, linear)
[    0.052054] Inode-cache hash table entries: 2097152 (order: 12, 16777216 bytes, linear)
[    0.052188] mem auto-init: stack:off, heap alloc:off, heap free:off
[    0.120459] Memory: 32565124K/33553912K available (14349K kernel code, 8898K rwdata, 12152K rodata, 2088K init, 2848K bss, 988528K reserved, 0K cma-reserved)
[    0.120499] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=12, Nodes=1
[    0.120514] ftrace: allocating 46143 entries in 181 pages
[    0.143762] ftrace: allocated 181 pages with 5 groups
[    0.143852] rcu: Hierarchical RCU implementation.
[    0.143853] rcu: 	RCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=12.
[    0.143855] 	Rude variant of Tasks RCU enabled.
[    0.143856] 	Tracing variant of Tasks RCU enabled.
[    0.143857] rcu: RCU calculated value of scheduler-enlistment delay is 100 jiffies.
[    0.143858] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=12
[    0.147547] NR_IRQS: 16640, nr_irqs: 520, preallocated irqs: 16
[    0.147705] rcu: 	Offload RCU callbacks from CPUs: (none).
[    0.147722] random: crng init done
[    0.155790] Console: colour VGA+ 80x25
[    0.188715] printk: console [tty0] enabled
[    0.342838] printk: console [ttyS0] enabled
[    0.343806] ACPI: Core revision 20200925
[    0.344726] APIC: Switch to symmetric I/O mode setup
[    0.346003] x2apic enabled
[    0.346869] Switched APIC routing to physical x2apic.
[    0.347978] kvm-guest: setup PV IPIs
[    0.349532] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x240937b9988, max_idle_ns: 440795218083 ns
[    0.351849] Calibrating delay loop (skipped) preset value.. 4999.99 BogoMIPS (lpj=2499998)
[    0.352847] x86/cpu: User Mode Instruction Prevention (UMIP) activated
[    0.352847] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0
[    0.352847] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0
[    0.352847] Spectre V2 : Mitigation: Enhanced / Automatic IBRS
[    0.352847] Speculative Store Bypass: Vulnerable
[    0.352847] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x008: 'MPX bounds registers'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x010: 'MPX CSR'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x020: 'AVX-512 opmask'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x040: 'AVX-512 Hi256'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x080: 'AVX-512 ZMM_Hi256'
[    0.352847] x86/fpu: Supporting XSAVE feature 0x200: 'Protection Keys User registers'
[    0.352847] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
[    0.352847] x86/fpu: xstate_offset[3]:  832, xstate_sizes[3]:   64
[    0.352847] x86/fpu: xstate_offset[4]:  896, xstate_sizes[4]:   64
[    0.352847] x86/fpu: xstate_offset[5]:  960, xstate_sizes[5]:   64
[    0.352847] x86/fpu: xstate_offset[6]: 1024, xstate_sizes[6]:  512
[    0.352847] x86/fpu: xstate_offset[7]: 1536, xstate_sizes[7]: 1024
[    0.352847] x86/fpu: xstate_offset[9]: 2560, xstate_sizes[9]:    8
[    0.352847] x86/fpu: Enabled xstate features 0x2ff, context size is 2568 bytes, using 'compacted' format.
[    0.352847] Freeing SMP alternatives memory: 40K
[    0.352847] pid_max: default: 32768 minimum: 301
[    0.352847] LSM: Security Framework initializing
[    0.352847] Yama: becoming mindful.
[    0.352847] SELinux:  Initializing.
[    0.352847] Mount-cache hash table entries: 65536 (order: 7, 524288 bytes, linear)
[    0.352847] Mountpoint-cache hash table entries: 65536 (order: 7, 524288 bytes, linear)
[    0.352847] smpboot: CPU0: Intel(R) Xeon(R) Gold 6210U CPU @ 2.50GHz (family: 0x6, model: 0x55, stepping: 0x7)
[    0.352931] Performance Events: Skylake events, full-width counters, Intel PMU driver.
[    0.353852] ... version:                2
[    0.354755] ... bit width:              48
[    0.354849] ... generic registers:      4
[    0.355757] ... value mask:             0000ffffffffffff
[    0.355849] ... max period:             00007fffffffffff
[    0.356849] ... fixed-purpose events:   3
[    0.357757] ... event mask:             000000070000000f
[    0.357938] rcu: Hierarchical SRCU implementation.
[    0.359212] smp: Bringing up secondary CPUs ...
[    0.359927] x86: Booting SMP configuration:
[    0.360851] .... node  #0, CPUs:        #1
[    0.205135] kvm-clock: cpu 1, msr 8a8b50041, secondary cpu clock
[    0.361883] kvm-guest: stealtime: cpu 1, msr 8bfa5bf00
[    0.363913]   #2
[    0.205135] kvm-clock: cpu 2, msr 8a8b50081, secondary cpu clock
[    0.365190] kvm-guest: stealtime: cpu 2, msr 8bfa9bf00
[    0.366908]   #3
[    0.205135] kvm-clock: cpu 3, msr 8a8b500c1, secondary cpu clock
[    0.368327] kvm-guest: stealtime: cpu 3, msr 8bfadbf00
[    0.369909]   #4
[    0.205135] kvm-clock: cpu 4, msr 8a8b50101, secondary cpu clock
[    0.371490] kvm-guest: stealtime: cpu 4, msr 8bfb1bf00
[    0.373910]   #5
[    0.205135] kvm-clock: cpu 5, msr 8a8b50141, secondary cpu clock
[    0.374509] kvm-guest: stealtime: cpu 5, msr 8bfb5bf00
[    0.376906]   #6
[    0.205135] kvm-clock: cpu 6, msr 8a8b50181, secondary cpu clock
[    0.377914] kvm-guest: stealtime: cpu 6, msr 8bfb9bf00
[    0.379912]   #7
[    0.205135] kvm-clock: cpu 7, msr 8a8b501c1, secondary cpu clock
[    0.381028] kvm-guest: stealtime: cpu 7, msr 8bfbdbf00
[    0.382910]   #8
[    0.205135] kvm-clock: cpu 8, msr 8a8b50201, secondary cpu clock
[    0.384159] kvm-guest: stealtime: cpu 8, msr 8bfc1bf00
[    0.385913]   #9
[    0.205135] kvm-clock: cpu 9, msr 8a8b50241, secondary cpu clock
[    0.387249] kvm-guest: stealtime: cpu 9, msr 8bfc5bf00
[    0.388909]  #10
[    0.205135] kvm-clock: cpu 10, msr 8a8b50281, secondary cpu clock
[    0.390387] kvm-guest: stealtime: cpu 10, msr 8bfc9bf00
[    0.392907]  #11
[    0.205135] kvm-clock: cpu 11, msr 8a8b502c1, secondary cpu clock
[    0.393475] kvm-guest: stealtime: cpu 11, msr 8bfcdbf00
[    0.395883] smp: Brought up 1 node, 12 CPUs
[    0.396850] smpboot: Max logical packages: 1
[    0.397813] smpboot: Total of 12 processors activated (59999.95 BogoMIPS)
[    0.399242] devtmpfs: initialized
[    0.399883] x86/mm: Memory block size: 128MB
[    0.402355] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns
[    0.402855] futex hash table entries: 4096 (order: 6, 262144 bytes, linear)
[    0.404044] NET: Registered protocol family 16
[    0.405029] audit: initializing netlink subsys (enabled)
[    0.405858] audit: type=2000 audit(1752362835.826:1): state=initialized audit_enabled=1 res=1
[    0.405909] thermal_sys: Registered thermal governor 'step_wise'
[    0.406856] cpuidle: using governor ladder
[    0.408774] cpuidle: using governor menu
[    0.409046] ACPI: bus type PCI registered
[    0.409851] acpiphp: ACPI Hot Plug PCI Controller Driver version: 0.5
[    0.410930] PCI: Using configuration type 1 for base access
[    0.413504] Kprobes globally optimized
[    0.413868] HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages
[    0.414851] HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages
[    0.439853] alg: self-tests for rsa-generic (rsa) passed
[    0.440863] alg: self-tests for cipher_null-generic (cipher_null) passed
[    0.441863] alg: self-tests for ecb-cipher_null (ecb(cipher_null)) passed
[    0.444000] alg: self-tests for sha256-generic (sha256) passed
[    0.444992] alg: self-tests for sha224-generic (sha224) passed
[    0.446977] alg: self-tests for sha3-224-generic (sha3-224) passed
[    0.447975] alg: self-tests for sha3-256-generic (sha3-256) passed
[    0.449993] alg: self-tests for sha3-384-generic (sha3-384) passed
[    0.451037] alg: self-tests for sha3-512-generic (sha3-512) passed
[    0.452864] alg: self-tests for aes-generic (aes) passed
[    0.453944] alg: self-tests for crc32c-generic (crc32c) passed
[    0.454997] alg: self-tests for crct10dif-generic (crct10dif) passed
[    0.456888] ACPI: Added _OSI(Module Device)
[    0.457852] ACPI: Added _OSI(Processor Device)
[    0.458843] ACPI: Added _OSI(3.0 _SCP Extensions)
[    0.459850] ACPI: Added _OSI(Processor Aggregator Device)
[    0.460850] ACPI: Added _OSI(Linux-Dell-Video)
[    0.461843] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)
[    0.462850] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)
[    0.464296] ACPI: 1 ACPI AML tables successfully acquired and loaded
[    0.466925] ACPI: Interpreter enabled
[    0.467777] ACPI: (supports S0 S5)
[    0.468851] ACPI: Using IOAPIC for interrupt routing
[    0.469859] PCI: Using host bridge windows from ACPI; if necessary, use "pci=nocrs" and report a bug
[    0.471930] ACPI: Enabled 2 GPEs in block 00 to 0F
[    0.474717] ACPI: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])
[    0.475854] acpi PNP0A03:00: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3]
[    0.477856] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge.
[    0.480058] acpiphp: Slot [3] registered
[    0.481865] acpiphp: Slot [4] registered
[    0.482776] acpiphp: Slot [5] registered
[    0.482867] acpiphp: Slot [6] registered
[    0.483779] acpiphp: Slot [7] registered
[    0.484862] acpiphp: Slot [8] registered
[    0.485765] acpiphp: Slot [9] registered
[    0.486865] acpiphp: Slot [10] registered
[    0.487790] acpiphp: Slot [11] registered
[    0.488863] acpiphp: Slot [12] registered
[    0.489785] acpiphp: Slot [13] registered
[    0.490864] acpiphp: Slot [14] registered
[    0.491781] acpiphp: Slot [15] registered
[    0.492863] acpiphp: Slot [16] registered
[    0.493781] acpiphp: Slot [17] registered
[    0.493864] acpiphp: Slot [18] registered
[    0.494787] acpiphp: Slot [19] registered
[    0.495865] acpiphp: Slot [20] registered
[    0.496787] acpiphp: Slot [21] registered
[    0.497862] acpiphp: Slot [22] registered
[    0.498782] acpiphp: Slot [23] registered
[    0.499862] acpiphp: Slot [24] registered
[    0.500779] acpiphp: Slot [25] registered
[    0.501863] acpiphp: Slot [26] registered
[    0.502775] acpiphp: Slot [27] registered
[    0.503863] acpiphp: Slot [28] registered
[    0.504782] acpiphp: Slot [29] registered
[    0.504866] acpiphp: Slot [30] registered
[    0.505792] acpiphp: Slot [31] registered
[    0.506859] PCI host bridge to bus 0000:00
[    0.507786] pci_bus 0000:00: root bus resource [io  0x0000-0x0cf7 window]
[    0.509856] pci_bus 0000:00: root bus resource [io  0x0d00-0xffff window]
[    0.510850] pci_bus 0000:00: root bus resource [mem 0x000a0000-0x000bffff window]
[    0.512850] pci_bus 0000:00: root bus resource [mem 0x20000000-0xfebfffff window]
[    0.513850] pci_bus 0000:00: root bus resource [mem 0xe0000000000-0xe007fffffff window]
[    0.515850] pci_bus 0000:00: root bus resource [bus 00-ff]
[    0.516889] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000
[    0.519298] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100
[    0.520447] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180
[    0.525412] pci 0000:00:01.1: reg 0x20: [io  0xc1c0-0xc1cf]
[    0.528052] pci 0000:00:01.1: legacy IDE quirk: reg 0x10: [io  0x01f0-0x01f7]
[    0.528851] pci 0000:00:01.1: legacy IDE quirk: reg 0x14: [io  0x03f6]
[    0.530851] pci 0000:00:01.1: legacy IDE quirk: reg 0x18: [io  0x0170-0x0177]
[    0.531850] pci 0000:00:01.1: legacy IDE quirk: reg 0x1c: [io  0x0376]
[    0.534061] pci 0000:00:01.3: [8086:7113] type 00 class 0x068000
[    0.535301] pci 0000:00:01.3: quirk: [io  0x0600-0x063f] claimed by PIIX4 ACPI
[    0.536860] pci 0000:00:01.3: quirk: [io  0x0700-0x070f] claimed by PIIX4 SMB
[    0.539068] pci 0000:00:02.0: [1013:00b8] type 00 class 0x030000
[    0.540855] pci 0000:00:02.0: reg 0x10: [mem 0xfc000000-0xfdffffff pref]
[    0.543854] pci 0000:00:02.0: reg 0x14: [mem 0xfebd0000-0xfebd0fff]
[    0.550277] pci 0000:00:02.0: reg 0x30: [mem 0xfebc0000-0xfebcffff pref]
[    0.552146] pci 0000:00:03.0: [1af4:1000] type 00 class 0x020000
[    0.554852] pci 0000:00:03.0: reg 0x10: [io  0xc100-0xc13f]
[    0.557852] pci 0000:00:03.0: reg 0x14: [mem 0xfebd1000-0xfebd1fff]
[    0.561852] pci 0000:00:03.0: reg 0x20: [mem 0xe0040000000-0xe0040003fff 64bit pref]
[    0.564783] pci 0000:00:03.0: reg 0x30: [mem 0xfeb00000-0xfeb3ffff pref]
[    0.566562] pci 0000:00:04.0: [1af4:1000] type 00 class 0x020000
[    0.569297] pci 0000:00:04.0: reg 0x10: [io  0xc140-0xc17f]
[    0.571696] pci 0000:00:04.0: reg 0x14: [mem 0xfebd2000-0xfebd2fff]
[    0.575852] pci 0000:00:04.0: reg 0x20: [mem 0xe0040004000-0xe0040007fff 64bit pref]
[    0.578852] pci 0000:00:04.0: reg 0x30: [mem 0xfeb40000-0xfeb7ffff pref]
[    0.581558] pci 0000:00:05.0: [1af4:1000] type 00 class 0x020000
[    0.583770] pci 0000:00:05.0: reg 0x10: [io  0xc180-0xc1bf]
[    0.585700] pci 0000:00:05.0: reg 0x14: [mem 0xfebd3000-0xfebd3fff]
[    0.589852] pci 0000:00:05.0: reg 0x20: [mem 0xe0040008000-0xe004000bfff 64bit pref]
[    0.592686] pci 0000:00:05.0: reg 0x30: [mem 0xfeb80000-0xfebbffff pref]
[    0.595503] pci 0000:00:06.0: [1000:0097] type 00 class 0x010700
[    0.597855] pci 0000:00:06.0: reg 0x10: [io  0xc000-0xc0ff]
[    0.600856] pci 0000:00:06.0: reg 0x14: [mem 0xe0000040000-0xe000004ffff 64bit]
[    0.613659] pci 0000:00:06.0: reg 0x1c: [mem 0xe0000000000-0xe000003ffff 64bit]
[    0.619000] pci 0000:00:06.0: supports D1 D2
[    0.620350] ACPI: PCI Interrupt Link [LNKA] (IRQs 5 *10 11)
[    0.621959] ACPI: PCI Interrupt Link [LNKB] (IRQs 5 *10 11)
[    0.640922] ACPI: PCI Interrupt Link [LNKC] (IRQs 5 10 *11)
[    0.642954] ACPI: PCI Interrupt Link [LNKD] (IRQs 5 10 *11)
[    0.643914] ACPI: PCI Interrupt Link [LNKS] (IRQs *9)
[    0.645270] iommu: Default domain type: Translated 
[    0.646869] pci 0000:00:02.0: vgaarb: setting as boot VGA device
[    0.647847] pci 0000:00:02.0: vgaarb: VGA device added: decodes=io+mem,owns=io+mem,locks=none
[    0.649852] pci 0000:00:02.0: vgaarb: bridge control possible
[    0.650850] vgaarb: loaded
[    0.651568] SCSI subsystem initialized
[    0.652864] ACPI: bus type USB registered
[    0.653789] usbcore: registered new interface driver usbfs
[    0.654860] usbcore: registered new interface driver hub
[    0.655856] usbcore: registered new device driver usb
[    0.656859] pps_core: LinuxPPS API ver. 1 registered
[    0.657849] pps_core: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it>
[    0.659851] PTP clock support registered
[    0.660924] PCI: Using ACPI for IRQ routing
[    0.662037] clocksource: Switched to clocksource kvm-clock
[    0.682606] VFS: Disk quotas dquot_6.6.0
[    0.683529] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
[    0.685039] pnp: PnP ACPI init
[    0.685950] pnp: PnP ACPI: found 5 devices
[    0.692832] clocksource: acpi_pm: mask: 0xffffff max_cycles: 0xffffff, max_idle_ns: 2085701024 ns
[    0.694760] NET: Registered protocol family 2
[    0.695892] IP idents hash table entries: 262144 (order: 9, 2097152 bytes, linear)
[    0.699164] tcp_listen_portaddr_hash hash table entries: 16384 (order: 6, 262144 bytes, linear)
[    0.701092] TCP established hash table entries: 262144 (order: 9, 2097152 bytes, linear)
[    0.703001] TCP bind hash table entries: 65536 (order: 8, 1048576 bytes, linear)
[    0.704712] TCP: Hash tables configured (established 262144 bind 65536)
[    0.706167] UDP hash table entries: 16384 (order: 7, 524288 bytes, linear)
[    0.707666] UDP-Lite hash table entries: 16384 (order: 7, 524288 bytes, linear)
[    0.709341] NET: Registered protocol family 1
[    0.710335] pci_bus 0000:00: resource 4 [io  0x0000-0x0cf7 window]
[    0.711667] pci_bus 0000:00: resource 5 [io  0x0d00-0xffff window]
[    0.713003] pci_bus 0000:00: resource 6 [mem 0x000a0000-0x000bffff window]
[    0.714458] pci_bus 0000:00: resource 7 [mem 0x20000000-0xfebfffff window]
[    0.715917] pci_bus 0000:00: resource 8 [mem 0xe0000000000-0xe007fffffff window]
[    0.717555] pci 0000:00:01.0: PIIX3: Enabling Passive Release
[    0.718803] pci 0000:00:00.0: Limiting direct PCI/PCI transfers
[    0.720107] pci 0000:00:01.0: Activating ISA DMA hang workarounds
[    0.721475] pci 0000:00:02.0: Video device with shadowed ROM at [mem 0x000c0000-0x000dffff]
[    0.723319] PCI: CLS 32 bytes, default 64
[    0.724256] Unpacking initramfs...
[    1.179181] Freeing initrd memory: 36344K
[    1.180177] PCI-DMA: Using software bounce buffering for IO (SWIOTLB)
[    1.181574] software IO TLB: mapped [mem 0x0000000007000000-0x000000000b000000] (64MB)
[    1.183431] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x240937b9988, max_idle_ns: 440795218083 ns
[    1.185632] clocksource: Switched to clocksource tsc
[    1.187012] Initialise system trusted keyrings
[    1.188086] workingset: timestamp_bits=39 max_order=23 bucket_order=0
[    1.190486] SGI XFS with ACLs, security attributes, scrub, repair, no debug enabled
[    1.192663] Key type asymmetric registered
[    1.193602] Asymmetric key parser 'x509' registered
[    1.194688] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 249)
[    1.196295] io scheduler mq-deadline registered
[    1.197309] io scheduler kyber registered
[    1.198809] shpchp: Standard Hot Plug PCI Controller Driver version: 0.4
[    1.200360] IPMI message handler: version 39.2
[    1.201359] ipmi device interface
[    1.202177] ipmi_si: IPMI System Interface driver
[    1.203259] ipmi_si: Unable to find any System Interface(s)
[    1.204529] input: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0
[    1.206165] ACPI: Power Button [PWRF]
[    1.223936] PCI Interrupt Link [LNKC] enabled at IRQ 11
[    1.242690] PCI Interrupt Link [LNKD] enabled at IRQ 10
[    1.261399] PCI Interrupt Link [LNKA] enabled at IRQ 10
[    1.263607] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled
[    1.265092] 00:00: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
[    1.266857] ACPI: bus type drm_connector registered
[    1.269757] loop: module loaded
[    1.270525] Loading iSCSI transport class v2.0-870.
[    1.271799] tun: Universal TUN/TAP device driver, 1.6
[    1.296022] ixgb: Intel(R) PRO/10GbE Network Driver
[    1.297128] ixgb: Copyright (c) 1999-2008 Intel Corporation.
[    1.298409] VFIO - User Level meta-driver version: 0.3
[    1.299639] i8042: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12
[    1.302100] serio: i8042 KBD port at 0x60,0x64 irq 1
[    1.303203] serio: i8042 AUX port at 0x60,0x64 irq 12
[    1.304402] rtc_cmos 00:04: RTC can wake from S4
[    1.305915] input: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input1
[    1.308013] rtc_cmos 00:04: registered as rtc0
[    1.309651] rtc_cmos 00:04: setting system clock to 2025-07-12T23:27:16 UTC (1752362836)
[    1.312018] rtc_cmos 00:04: alarms up to one day, y3k, 242 bytes nvram
[    1.313906] device-mapper: uevent: version 1.0.3
[    1.315299] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com
[    1.317707] intel_pstate: CPU model not supported
[    1.319107] usbcore: registered new interface driver usbhid
[    1.320706] usbhid: USB HID core driver
[    1.321863] drop_monitor: Initializing network drop monitor service
[    1.323763] NET: Registered protocol family 10
[    1.325301] Segment Routing with IPv6
[    1.326436] NET: Registered protocol family 17
[    1.327784] 8021q: 802.1Q VLAN Support v1.8
[    1.329169] IPI shorthand broadcast: enabled
[    1.330437] sched_clock: Marking stable (1126286136, 204135053)->(1410197187, -79775998)
[    1.332836] registered taskstats version 1
[    1.334048] Loading compiled-in X.509 certificates
[    1.394035] alg: self-tests for pkcs1pad(rsa-generic,sha256) (pkcs1pad(rsa,sha256)) passed
[    1.396006] Loaded X.509 cert 'Nutanix (Test) Kernel Module Signing Key: 75a38375b62fd1d338d63c651b04ad8961c8c2ce'
[    1.432791] alg: self-tests for cbc(aes-generic) (cbc(aes)) passed
[    1.434174] Key type encrypted registered
[    1.435970] clk: Disabling unused clocks
[    1.438012] Freeing unused kernel image (initmem) memory: 2088K
[    1.446153] Write protecting the kernel read-only data: 28672k
[    1.448243] Freeing unused kernel image (text/rodata gap) memory: 2032K
[    1.450192] Freeing unused kernel image (rodata/data gap) memory: 136K
[    1.452054] rodata_test: all tests were successful
[    1.453466] Run /init as init process
[    1.527768] systemd[1]: systemd 239 (239-82.el8) running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +SECCOMP +BLKID +ELFUTILS +KMOD +IDN2 -IDN +PCRE2 default-hierarchy=legacy)
[    1.533998] systemd[1]: Detected virtualization kvm.
[    1.535454] systemd[1]: Detected architecture x86-64.
[    1.536929] systemd[1]: Running in initial RAM disk.

Welcome to Rocky Linux 8.10 (Green Obsidian) dracut-049-233.git20240115.el8 (Initramfs)!

[    1.540653] systemd[1]: No hostname configured.
[    1.542113] systemd[1]: Set hostname to <localhost>.
[    1.543585] systemd[1]: Initializing machine ID from KVM UUID.
[    1.625480] systemd[1]: Reached target Slices.
[  OK  ] Reached target Slices.
[    1.627660] systemd[1]: Reached target Initrd Root Device.
[  OK  ] Reached target Initrd Root Device.
[    1.630331] systemd[1]: Listening on Journal Socket.
[  OK  ] Listening on Journal Socket.
[  OK  ] Reached target Swap.
[  OK  ] Listening on udev Control Socket.
[  OK  ] Started Memstrack Anylazing Service.
[    1.636238] audit: type=1130 audit(1752362836.826:2): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=memstrack comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Listening on Open-iSCSI iscsiuio Socket.
         Starting iSCSI UserSpace I/O driver...
[  OK  ] Reached target Timers.
         Starting Create list of required st…ce nodes for the current kernel...
         Starting Load Kernel Modules...
[  OK  ] Listening on Journal Socket (/dev/log).
         Starting Setup Virtual Console...
[  OK  ] Started Dispatch Password Requests to Console Directory Watch.
[  OK  ] Reached target Local Encrypted Volumes.
[  OK  ] Listening on udev Kernel Socket.
[  OK  ] Listening on Open-iSCSI iscsid Socket.
[  OK  ] Reached target Sockets.
[  OK  ] Reached target Paths.
[    1.654904] audit: type=1131 audit(1752362836.844:3): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=memstrack comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Started Create list of required sta…vice nodes for the current kernel.
[    1.662230] audit: type=1130 audit(1752362836.852:4): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=kmod-static-nodes comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
         Starting Create Static Device Nodes in /dev...
[  OK  ] Started iSCSI UserSpace I/O driver.
[    1.707630] audit: type=1130 audit(1752362836.897:5): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=iscsiuio comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[    1.747062] fuse: init (API version 7.32)
[  OK  ] Started Load Kernel Modules.
[    1.755464] audit: type=1130 audit(1752362836.945:6): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=systemd-modules-load comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Started Setup Virtual Console.
[    1.760766] audit: type=1130 audit(1752362836.950:7): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=systemd-vconsole-setup comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[    1.764954] audit: type=1131 audit(1752362836.954:8): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=systemd-vconsole-setup comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Started Create Static Device Nodes in /dev.
[    1.770461] audit: type=1130 audit(1752362836.960:9): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=systemd-tmpfiles-setup-dev comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[    1.775924] audit: type=1130 audit(1752362836.965:10): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=haveged comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
         Starting Journal Service...
         Starting dracut cmdline hook...
         Starting Apply Kernel Variables...
[    1.852465] iscsi: registered transport (tcp)
[  OK  ] Started Journal Service.
[    1.682929] dracut-cmdline[223]: Warning: Kernel command line option 'rd_NO_LUKS' is deprecated, use 'rd.luks=0' instead.
[  OK  ] Started Apply Kernel Variables.
[  OK  ] Stopped Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Started dracut cmdline hook.
         Starting dracut pre-udev hook...
[    2.102273] alg: self-tests for sha1-generic (sha1) passed
[    2.104074] alg: self-tests for sha1-ssse3 (sha1) passed
[    2.114478] alg: self-tests for sha1-avx (sha1) passed
[    2.115719] alg: self-tests for sha1-avx2 (sha1) passed
[    2.134648] alg: self-tests for sha256-ssse3 (sha256) passed
[    2.136072] alg: self-tests for sha224-ssse3 (sha224) passed
[    2.137470] alg: self-tests for sha256-avx (sha256) passed
[    2.138830] alg: self-tests for sha224-avx (sha224) passed
[    2.140190] alg: self-tests for sha256-avx2 (sha256) passed
[    2.141562] alg: self-tests for sha224-avx2 (sha224) passed
[  OK  ] Stopped Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[    2.177503] alg: self-tests for sha512-generic (sha512) passed
[    2.178985] alg: self-tests for sha384-generic (sha384) passed
[    2.180879] alg: self-tests for sha512-ssse3 (sha512) passed
[    2.182276] alg: self-tests for sha384-ssse3 (sha384) passed
[    2.183668] alg: self-tests for sha512-avx (sha512) passed
[    2.185039] alg: self-tests for sha384-avx (sha384) passed
[    2.186402] alg: self-tests for sha512-avx2 (sha512) passed
[    2.187781] alg: self-tests for sha384-avx2 (sha384) passed
[    2.223446] alg: self-tests for crc32c-intel (crc32c) passed
[    2.242172] alg: self-tests for crct10dif-pclmul (crct10dif) passed
[    2.261150] cryptd: max_cpu_qlen set to 1000
[    2.346104] alg: self-tests for ghash-clmulni (ghash) passed
[    2.348135] alg: self-tests for ghash-generic (ghash) passed
[    2.367437] alg: self-tests for des3_ede-asm (des3_ede) passed
[    2.368926] alg: self-tests for ecb-des3_ede-asm (ecb(des3_ede)) passed
[    2.370606] alg: self-tests for cbc-des3_ede-asm (cbc(des3_ede)) passed
[    2.372327] alg: self-tests for ctr-des3_ede-asm (ctr(des3_ede)) passed
[    2.374216] alg: self-tests for des3_ede-generic (des3_ede) passed
[    2.395107] AVX2 version of gcm_enc/dec engaged.
[    2.396167] AES CTR mode by8 optimization enabled
[    2.397294] alg: self-tests for aes-aesni (aes) passed
[    2.432001] alg: self-tests for ecb-aes-aesni (ecb(aes)) passed
[    2.466749] alg: self-tests for cbc-aes-aesni (cbc(aes)) passed
[    2.501463] alg: self-tests for ctr-aes-aesni (ctr(aes)) passed
[  OK  ] Stopped Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[    2.536474] alg: self-tests for xts-aes-aesni (xts(aes)) passed
[    2.571852] alg: self-tests for rfc4106-gcm-aesni (rfc4106(gcm(aes))) passed
[    2.606954] alg: self-tests for generic-gcm-aesni (gcm(aes)) passed
[    2.705618] alg: self-tests for dh-generic (dh) passed
[    2.828195] alg: self-tests for deflate-generic (deflate) passed
[    2.829830] alg: self-tests for deflate-scomp (deflate) passed
[    2.831394] alg: self-tests for zlib-deflate-scomp (zlib-deflate) passed
[    2.850526] alg: self-tests for lzo-generic (lzo) passed
[    2.851876] alg: self-tests for lzo-scomp (lzo) passed
[    2.870408] alg: No test for fips(ansi_cprng) (fips_ansi_cprng)
[  OK  ] Stopped Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[    2.908154] alg: self-tests for sha1 (sha1) passed
[    2.909423] alg: self-tests for ecb(des3_ede) (ecb(des3_ede)) passed
[    2.911017] alg: self-tests for cbc(des3_ede) (cbc(des3_ede)) passed
[    2.912635] alg: self-tests for ctr(des3_ede) (ctr(des3_ede)) passed
[    2.914124] alg: self-tests for sha256 (sha256) passed
[    2.915317] alg: self-tests for ecb(aes) (ecb(aes)) passed
[    2.916595] alg: self-tests for cbc(aes) (cbc(aes)) passed
[    2.917877] alg: self-tests for xts(aes) (xts(aes)) passed
[    2.919150] alg: self-tests for ctr(aes) (ctr(aes)) passed
[    2.954179] alg: self-tests for rfc3686(ctr-aes-aesni) (rfc3686(ctr(aes))) passed
[    2.955988] alg: self-tests for rfc3686(ctr(aes)) (rfc3686(ctr(aes))) passed
[    2.991068] alg: self-tests for ofb(aes-aesni) (ofb(aes)) passed
[    2.992456] alg: self-tests for ofb(aes) (ofb(aes)) passed
[    3.027229] alg: self-tests for cfb(aes-aesni) (cfb(aes)) passed
[    3.028643] alg: self-tests for cfb(aes) (cfb(aes)) passed
[    3.029960] alg: self-tests for sha384 (sha384) passed
[    3.031220] alg: self-tests for sha512 (sha512) passed
[    3.032441] alg: self-tests for deflate (deflate) passed
[    3.033707] alg: self-tests for crc32c (crc32c) passed
[    3.034957] alg: self-tests for sha224 (sha224) passed
[    3.036346] alg: self-tests for gcm(aes) (gcm(aes)) passed
[    3.037577] alg: self-tests for lzo (lzo) passed
[    3.105510] alg: self-tests for cbcmac(aes-aesni) (cbcmac(aes)) passed
[    3.107412] alg: self-tests for ccm_base(ctr-aes-aesni,cbcmac(aes-aesni)) (ccm(aes)) passed
[    3.109674] alg: self-tests for ccm(aes) (ccm(aes)) passed
[    3.144465] alg: self-tests for cts(cbc-aes-aesni) (cts(cbc(aes))) passed
[    3.146053] alg: self-tests for cts(cbc(aes)) (cts(cbc(aes))) passed
[    3.181323] alg: self-tests for rfc4309(ccm_base(ctr-aes-aesni,cbcmac(aes-aesni))) (rfc4309(ccm(aes))) passed
[    3.183971] alg: self-tests for rfc4309(ccm(aes)) (rfc4309(ccm(aes))) passed
[    3.185596] alg: self-tests for ghash (ghash) passed
[    3.186747] alg: self-tests for crct10dif (crct10dif) passed
[    3.188130] alg: self-tests for sha3-224 (sha3-224) passed
[    3.189486] alg: self-tests for sha3-256 (sha3-256) passed
[    3.190847] alg: self-tests for sha3-384 (sha3-384) passed
[    3.192258] alg: self-tests for sha3-512 (sha3-512) passed
[    3.227109] alg: self-tests for hmac(sha1-avx2) (hmac(sha1)) passed
[    3.228664] alg: self-tests for hmac(sha1) (hmac(sha1)) passed
[  OK  ] Stopped Entropy Daemon based on the HAVEGE algorithm.
[FAILED] Failed to start Entropy Daemon based on the HAVEGE algorithm.
See 'systemctl status haveged.service' for details.
[    3.263557] alg: self-tests for hmac(sha256-avx2) (hmac(sha256)) passed
[    3.265332] alg: self-tests for hmac(sha256) (hmac(sha256)) passed
[    3.300305] alg: self-tests for hmac(sha384-avx2) (hmac(sha384)) passed
[    3.301961] alg: self-tests for hmac(sha384) (hmac(sha384)) passed
[    3.337082] alg: self-tests for hmac(sha512-avx2) (hmac(sha512)) passed
[    3.338717] alg: self-tests for hmac(sha512) (hmac(sha512)) passed
[    3.373660] alg: self-tests for hmac(sha224-avx2) (hmac(sha224)) passed
[    3.375295] alg: self-tests for hmac(sha224) (hmac(sha224)) passed
[    3.410496] alg: self-tests for hmac(sha3-224-generic) (hmac(sha3-224)) passed
[    3.412351] alg: self-tests for hmac(sha3-224) (hmac(sha3-224)) passed
[    3.447441] alg: self-tests for hmac(sha3-256-generic) (hmac(sha3-256)) passed
[    3.449302] alg: self-tests for hmac(sha3-256) (hmac(sha3-256)) passed
[    3.484459] alg: self-tests for hmac(sha3-384-generic) (hmac(sha3-384)) passed
[    3.486347] alg: self-tests for hmac(sha3-384) (hmac(sha3-384)) passed
[    3.521365] alg: self-tests for hmac(sha3-512-generic) (hmac(sha3-512)) passed
[    3.523263] alg: self-tests for hmac(sha3-512) (hmac(sha3-512)) passed
[    3.525068] alg: self-tests for rfc4106(gcm(aes)) (rfc4106(gcm(aes))) passed
[    3.560079] alg: self-tests for cmac(aes-aesni) (cmac(aes)) passed
[    3.561539] alg: self-tests for cmac(aes) (cmac(aes)) passed
[    3.596556] alg: self-tests for cmac(des3_ede-asm) (cmac(des3_ede)) passed
[    3.598181] alg: self-tests for cmac(des3_ede) (cmac(des3_ede)) passed
[    3.633267] alg: self-tests for authenc(hmac(sha1-avx2),cbc-aes-aesni) (authenc(hmac(sha1),cbc(aes))) passed
[    3.635594] alg: self-tests for authenc(hmac(sha1),cbc(aes)) (authenc(hmac(sha1),cbc(aes))) passed
[    3.671090] alg: self-tests for authenc(hmac(sha1-avx2),cbc-des3_ede-asm) (authenc(hmac(sha1),cbc(des3_ede))) passed
[    3.673450] alg: self-tests for authenc(hmac(sha1),cbc(des3_ede)) (authenc(hmac(sha1),cbc(des3_ede))) passed
[    3.709119] alg: self-tests for authenc(hmac(sha224-avx2),cbc-des3_ede-asm) (authenc(hmac(sha224),cbc(des3_ede))) passed
[    3.711554] alg: self-tests for authenc(hmac(sha224),cbc(des3_ede)) (authenc(hmac(sha224),cbc(des3_ede))) passed
[    3.747347] alg: self-tests for authenc(hmac(sha256-avx2),cbc-des3_ede-asm) (authenc(hmac(sha256),cbc(des3_ede))) passed
[    3.749787] alg: self-tests for authenc(hmac(sha256),cbc(des3_ede)) (authenc(hmac(sha256),cbc(des3_ede))) passed
[    3.785578] alg: self-tests for authenc(hmac(sha384-avx2),cbc-des3_ede-asm) (authenc(hmac(sha384),cbc(des3_ede))) passed
[    3.788011] alg: self-tests for authenc(hmac(sha384),cbc(des3_ede)) (authenc(hmac(sha384),cbc(des3_ede))) passed
[    3.823767] alg: self-tests for authenc(hmac(sha512-avx2),cbc-des3_ede-asm) (authenc(hmac(sha512),cbc(des3_ede))) passed
[    3.826237] alg: self-tests for authenc(hmac(sha512),cbc(des3_ede)) (authenc(hmac(sha512),cbc(des3_ede))) passed
[  OK  ] Started dracut pre-udev hook.
         Starting udev Kernel Device Manager...
[  OK  ] Started udev Kernel Device Manager.
         Starting dracut pre-trigger hook...
[  OK  ] Started dracut pre-trigger hook.
         Starting udev Coldplug all Devices...
[  OK  ] Started udev Coldplug all Devices.
         Starting udev Wait for Complete Device Initialization...
[    4.452815] scsi host0: ata_piix
[    4.453918] alg: self-tests for crc32-pclmul (crc32) passed
[    4.454478] mpt3sas: loading out-of-tree module taints kernel.
[    4.457320] scsi host1: ata_piix
[    4.458352] ata1: PATA max MWDMA2 cmd 0x1f0 ctl 0x3f6 bmdma 0xc1c0 irq 14
[    4.458438] mpt3sas version 40.00.00.00 loaded
[    4.460052] ata2: PATA max MWDMA2 cmd 0x170 ctl 0x376 bmdma 0xc1c8 irq 15
[    4.480615] PCI Interrupt Link [LNKB] enabled at IRQ 11
[    4.482185] mpt3sas_cm0: 63 BIT PCI BUS DMA ADDRESSING SUPPORTED, total mem (32606024 kB)
[    4.601163] mpt3sas_cm0: IOC Number : 0
[    4.602257] mpt3sas_cm0: CurrentHostPageSize is 0: Setting default host page size to 4k
[    4.617601] ata2.00: ATAPI: QEMU DVD-ROM, 2.5+, max UDMA/100
[    4.623889] mpt3sas0-msix0: PCI-MSI-X enabled: IRQ 51
[    4.625241] mpt3sas0-msix1: PCI-MSI-X enabled: IRQ 52
[    4.626374] mpt3sas0-msix2: PCI-MSI-X enabled: IRQ 53
[    4.627496] mpt3sas0-msix3: PCI-MSI-X enabled: IRQ 54
[    4.628619] mpt3sas0-msix4: PCI-MSI-X enabled: IRQ 55
[    4.629750] mpt3sas0-msix5: PCI-MSI-X enabled: IRQ 56
[    4.630877] mpt3sas0-msix6: PCI-MSI-X enabled: IRQ 57
[    4.631999] mpt3sas0-msix7: PCI-MSI-X enabled: IRQ 58
[    4.633127] mpt3sas0-msix8: PCI-MSI-X enabled: IRQ 59
[    4.634253] mpt3sas0-msix9: PCI-MSI-X enabled: IRQ 60
[    4.635393] mpt3sas0-msix10: PCI-MSI-X enabled: IRQ 61
[    4.636546] mpt3sas0-msix11: PCI-MSI-X enabled: IRQ 62
[    4.637695] mpt3sas_cm0: iomem(0x00000e0000040000), mapped(0x0000000006e9054b), size(65536)
[    4.639510] mpt3sas_cm0: ioport(0x000000000000c000), size(256)
[    4.641861] scsi 1:0:0:0: CD-ROM            QEMU     QEMU DVD-ROM     2.5+ PQ: 0 ANSI: 5
[    4.644718] sr 1:0:0:0: [sr0] scsi3-mmc drive: 4x/4x cd/rw xa/form2 tray
[    4.646175] cdrom: Uniform CD-ROM driver Revision: 3.20
[    4.671405] sr 1:0:0:0: Attached scsi generic sg0 type 5
[    4.756140] mpt3sas_cm0: IOC Number : 0
[    4.757044] mpt3sas_cm0: CurrentHostPageSize is 0: Setting default host page size to 4k
[    4.813142] mpt3sas_cm0: scatter gather: sge_in_main_msg(0), sge_per_chain(7), sge_per_io(128), chains_per_io(19)
[    4.815373] mpt3sas_cm0: request pool(0x00000000764e5b94) - dma(0x10cc80000): depth(3200), frame_size(128), pool_size(400 kB)
[    4.827019] mpt3sas_cm0: sense pool(0x00000000fe95cac5) - dma(0x10d700000): depth(2939), element_size(96), pool_size (275 kB)
[    4.829467] mpt3sas_cm0: reply pool(0x00000000ea4123d6) - dma(0x10d780000): depth(3264)frame_size(128), pool_size(408 kB)
[    4.831862] mpt3sas_cm0: config page(0x0000000037fd2cdd) - dma(0x10d68b000): size(512)
[    4.833592] mpt3sas_cm0: Allocated physical memory: size(8684 kB)
[    4.834929] mpt3sas_cm0: Current Controller Queue Depth(2936), Max Controller Queue Depth(3072)
[    5.057477] mpt3sas_cm0: LSISAS3008: FWVersion(16.00.10.00), ChipRevision(0x02)
[    5.059101] mpt3sas_cm0: Protocol=(
[    5.059101] Initiator
[    5.059922] ,Target
[    5.060509] ), 
[    5.061057] Capabilities=(
[    5.061538] TLR
[    5.062209] ,EEDP
[    5.062684] ,Snapshot Buffer
[    5.063201] ,Diag Trace Buffer
[    5.063901] ,Task Set Full
[    5.064641] ,NCQ
[    5.065316] )
[    5.066421] mpt3sas_cm0: : host protection capabilities enabled  DIF1
[    5.067824] scsi host2: Fusion MPT SAS Host
[    5.069227] mpt3sas_cm0: sending port enable !!
[    6.615924] mpt3sas_cm0: hba_port entry: 00000000b565bbd6, port: 255 is added to hba_port list
[    6.619005] mpt3sas_cm0: host_add: handle(0x0001), sas_addr(0x5003048022e197f0), phys(8)
[    6.621175] mpt3sas_cm0: handle(0x9) sas_address(0x4433221100000000) port_type(0x1)
[    6.866168] mpt3sas_cm0: handle(0xa) sas_address(0x4433221101000000) port_type(0x1)
[    6.868278] mpt3sas_cm0: handle(0xb) sas_address(0x4433221102000000) port_type(0x1)
[    6.870391] mpt3sas_cm0: handle(0xc) sas_address(0x4433221103000000) port_type(0x1)
[   ***] A start job is running for udev Wai…ice Initialization (10s / 3min 2s)[   12.750161] mpt3sas_cm0: port enable: SUCCESS
[    **] A start job is running for udev Wai…ice Initialization (11s / 3min 2s)[   13.116164] scsi 2:0:0:0: Direct-Access     ATA      SAMSUNG MZ7LH1T9 B04Q PQ: 0 ANSI: 6
[   13.118290] scsi 2:0:0:0: SATA: handle(0x0009), sas_addr(0x4433221100000000), phy(0), device_name(0x0000000000000000)
[   13.120564] scsi 2:0:0:0: enclosure logical id(0x5003048022e197f0), slot(0) 
[   13.122080] scsi 2:0:0:0: enclosure level(0x0000), connector name(     )
[   13.123598] scsi 2:0:0:0: atapi(n), ncq(y), asyn_notify(n), smart(y), fua(y), sw_preserve(y)
[   13.125675] scsi 2:0:0:0: serial_number(S455NA0N300750      )
[   13.126939] scsi 2:0:0:0: qdepth(32), tagged(1), scsi_level(7), cmd_que(1)
[   13.129652]  end_device-2:0: mpt3sas_transport_port_add: added: handle(0x0009), sas_addr(0x4433221100000000)
[     *] A start job is running for udev Wai…ice Initialization (11s / 3min 2s)[   13.616147] scsi 2:0:1:0: Direct-Access     ATA      SAMSUNG MZ7LH1T9 B04Q PQ: 0 ANSI: 6
[   13.618268] scsi 2:0:1:0: SATA: handle(0x000a), sas_addr(0x4433221101000000), phy(1), device_name(0x0000000000000000)
[   13.620533] scsi 2:0:1:0: enclosure logical id(0x5003048022e197f0), slot(1) 
[   13.622044] scsi 2:0:1:0: enclosure level(0x0000), connector name(     )
[   13.623560] scsi 2:0:1:0: atapi(n), ncq(y), asyn_notify(n), smart(y), fua(y), sw_preserve(y)
[   13.625627] scsi 2:0:1:0: serial_number(S455NA0N300758      )
[   13.626893] scsi 2:0:1:0: qdepth(32), tagged(1), scsi_level(7), cmd_que(1)
[   13.629594]  end_device-2:1: mpt3sas_transport_port_add: added: handle(0x000a), sas_addr(0x4433221101000000)
[    **] A start job is running for udev Wai…ice Initialization (12s / 3min 2s)[   14.116048] scsi 2:0:2:0: Direct-Access     ATA      HGST HUS726T4TAL W9U0 PQ: 0 ANSI: 6
[   14.118168] scsi 2:0:2:0: SATA: handle(0x000b), sas_addr(0x4433221102000000), phy(2), device_name(0x0000000000000000)
[   14.120464] scsi 2:0:2:0: enclosure logical id(0x5003048022e197f0), slot(2) 
[   14.121968] scsi 2:0:2:0: enclosure level(0x0000), connector name(     )
[   14.123481] scsi 2:0:2:0: atapi(n), ncq(y), asyn_notify(n), smart(y), fua(y), sw_preserve(y)
[   14.125483] scsi 2:0:2:0: serial_number(V1G2YRLB            )
[   14.126766] scsi 2:0:2:0: qdepth(32), tagged(1), scsi_level(7), cmd_que(1)
[   14.129084]  end_device-2:2: mpt3sas_transport_port_add: added: handle(0x000b), sas_addr(0x4433221102000000)
[   ***] A start job is running for udev Wai…ice Initialization (12s / 3min 2s)[   14.616063] scsi 2:0:3:0: Direct-Access     ATA      HGST HUS726T4TAL W9U0 PQ: 0 ANSI: 6
[   14.618131] scsi 2:0:3:0: SATA: handle(0x000c), sas_addr(0x4433221103000000), phy(3), device_name(0x0000000000000000)
[   14.620385] scsi 2:0:3:0: enclosure logical id(0x5003048022e197f0), slot(3) 
[   14.621901] scsi 2:0:3:0: enclosure level(0x0000), connector name(     )
[   14.623402] scsi 2:0:3:0: atapi(n), ncq(y), asyn_notify(n), smart(y), fua(y), sw_preserve(y)
[   14.625413] scsi 2:0:3:0: serial_number(V1G575HB            )
[   14.626679] scsi 2:0:3:0: qdepth(32), tagged(1), scsi_level(7), cmd_que(1)
[   14.628996]  end_device-2:3: mpt3sas_transport_port_add: added: handle(0x000c), sas_addr(0x4433221103000000)
[   14.631278] sd 2:0:0:0: Attached scsi generic sg1 type 0
[   14.631309] sd 2:0:0:0: Power-on or device reset occurred
[   14.632558] scsi 2:0:1:0: Attached scsi generic sg2 type 0
[   14.632647] sd 2:0:1:0: Power-on or device reset occurred
[   14.635583] sd 2:0:1:0: [sdb] 3750748848 512-byte logical blocks: (1.92 TB/1.75 TiB)
[   14.635673] sd 2:0:0:0: [sda] 3750748848 512-byte logical blocks: (1.92 TB/1.75 TiB)
[   14.635674] sd 2:0:0:0: [sda] 4096-byte physical blocks
[   14.636183] scsi 2:0:2:0: Attached scsi generic sg3 type 0
[   14.636262] sd 2:0:2:0: Power-on or device reset occurred
[   14.637144] sd 2:0:0:0: [sda] Write Protect is off
[   14.637480] sd 2:0:2:0: [sdc] 7814037168 512-byte logical blocks: (4.00 TB/3.64 TiB)
[   14.637481] sd 2:0:2:0: [sdc] 4096-byte physical blocks
[   14.637645] sd 2:0:0:0: [sda] Write cache: disabled, read cache: enabled, supports DPO and FUA
[   14.637779] sd 2:0:1:0: [sdb] 4096-byte physical blocks
[   14.639270] sd 2:0:1:0: [sdb] Write Protect is off
[   14.639579] scsi 2:0:3:0: Attached scsi generic sg4 type 0
[   14.639644] sd 2:0:3:0: Power-on or device reset occurred
[   14.640755] sd 2:0:3:0: [sdd] 7814037168 512-byte logical blocks: (4.00 TB/3.64 TiB)
[   14.641156] sd 2:0:1:0: [sdb] Write cache: disabled, read cache: enabled, supports DPO and FUA
[   14.643183] sd 2:0:2:0: [sdc] Write Protect is off
[   14.644169] sd 2:0:3:0: [sdd] 4096-byte physical blocks
[   14.646278] sd 2:0:2:0: [sdc] Write cache: disabled, read cache: enabled, supports DPO and FUA
[   14.652634] sd 2:0:3:0: [sdd] Write Protect is off
[   14.658832]  sda: sda1 sda2 sda3 sda4
[   14.659177]  sdb: sdb1 sdb2 sdb3 sdb4
[   14.663736] sd 2:0:1:0: [sdb] Attached SCSI disk
[   14.664471] sd 2:0:3:0: [sdd] Write cache: disabled, read cache: enabled, supports DPO and FUA
[   14.665793] sd 2:0:0:0: [sda] Attached SCSI disk
[  *** ] A start job is running for udev Wai…ice Initialization (13s / 3min 2s)[   15.491733]  sdd: sdd1
[   15.497809]  sdc: sdc1
[   15.500090] sd 2:0:3:0: [sdd] Attached SCSI disk
[   15.506166] sd 2:0:2:0: [sdc] Attached SCSI disk
[  OK  ] Started udev Wait for Complete Device Initialization.
[   15.872656] kauditd_printk_skb: 26 callbacks suppressed
[   15.872657] audit: type=1130 audit(1752362851.062:37): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=systemd-udev-settle comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
         Starting Device-Mapper Multipath Device Controller...
[  OK  ] Started Device-Mapper Multipath Device Controller.
[   15.898227] audit: type=1130 audit(1752362851.088:38): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=multipathd comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Reached target Local File Systems (Pre).
[  OK  ] Reached target Local File Systems.
         Starting Create Volatile Files and Directories...
         Starting Open-iSCSI...
[  OK  ] Started Open-iSCSI.
[   15.977370] audit: type=1130 audit(1752362851.167:39): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=iscsid comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
         Starting dracut initqueue hook...
[  OK  ] Started Create Volatile Files and Directories.
[   15.983398] audit: type=1130 audit(1752362851.173:40): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=systemd-tmpfiles-setup comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Reached target System Initialization.
[  OK  ] Reached target Basic System.
[  OK  ] Started dracut initqueue hook.
[   15.990386] audit: type=1130 audit(1752362851.180:41): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=dracut-initqueue comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Reached target Remote File Systems (Pre).
[  OK  ] Reached target Remote File Systems.
         Starting dracut pre-mount hook...
[  OK  ] Started dracut pre-mount hook.
[   16.007317] audit: type=1130 audit(1752362851.197:42): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=dracut-pre-mount comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Reached target Initrd Root File System.
         Starting Reload Configuration from the Real Root...
         Stopping Device-Mapper Multipath Device Controller...
[  OK  ] Started Reload Configuration from the Real Root.
[   16.344418] audit: type=1130 audit(1752362851.534:43): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=initrd-parse-etc comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[   16.348575] audit: type=1131 audit(1752362851.534:44): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=initrd-parse-etc comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
[  OK  ] Reached target Initrd File Systems.
[  OK  ] Reached target Initrd Default Target.
         Starting dracut mount hook...
svmboot: === SVMBOOT_NEW
svmboot: scanning boot partitions
[  OK  ] Stopped Device-Mapper Multip[   16.404399] audit: type=1130 audit(1752362851.593:45): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=multipathd comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
ath Device Controller.
[   16.408749] audit: type=1131 audit(1752362851.593:46): pid=1 uid=0 auid=4294967295 ses=4294967295 subj=kernel msg='unit=multipathd comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
svmboot: Found old /etc/mdadm.conf. Removing it
svmboot: Found boot disk with serial: sda  S455NA0N300750
svmboot: Found boot disk with serial: sdb  S455NA0N300758
svmboot: [1/4] Assembling raid
[   16.529495] md: md127 stopped.
[   16.548208] md/raid1:md127: active with 2 out of 2 mirrors
[   16.550186] md127: detected capacity change from 0 to 42914021376
mdadm: /dev/md/rescue:2 has been started with 2 drives.
[   16.568900] md: md126 stopped.
[   16.587274] md/raid1:md126: active with 2 out of 2 mirrors
[   16.589249] md126: detected capacity change from 0 to 10726932480
mdadm: /dev/md/rescue:1 has been started with 2 drives.
[   16.608203] md: md125 stopped.
[   16.626668] md/raid1:md125: active with 2 out of 2 mirrors
[   16.628643] md125: detected capacity change from 0 to 10726932480
mdadm: /dev/md/rescue:0 has been started with 2 drives.
svmboot: mdadm ret: 0 , retry: 0
mdadm: looking for devices for further assembly
mdadm: no recogniseable superblock on /dev/md/rescue:0
mdadm: no recogniseable superblock on /dev/md/rescue:1
mdadm: no recogniseable superblock on /dev/md/rescue:2
mdadm: no recogniseable superblock on /dev/sdd1
mdadm: Cannot assemble mbr metadata on /dev/sdd
mdadm: no recogniseable superblock on /dev/sdc1
mdadm: Cannot assemble mbr metadata on /dev/sdc
mdadm: no recogniseable superblock on /dev/sdb4
mdadm: /dev/sdb3 is busy - skipping
mdadm: /dev/sdb2 is busy - skipping
mdadm: /dev/sdb1 is busy - skipping
mdadm: Cannot assemble mbr metadata on /dev/sdb
mdadm: no recogniseable superblock on /dev/sda4
mdadm: /dev/sda3 is busy - skipping
mdadm: /dev/sda2 is busy - skipping
mdadm: /dev/sda1 is busy - skipping
mdadm: Cannot assemble mbr metadata on /dev/sda
mdadm: no recogniseable superblock on /dev/sr0
mdadm: No arrays found in config file or automatically
===== lsblk
NAME      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
sda         8:0    0  1.8T  0 disk  
|-sda1      8:1    0   10G  0 part  
| `-md125   9:125  0   10G  0 raid1 
|-sda2      8:2    0   10G  0 part  
| `-md126   9:126  0   10G  0 raid1 
|-sda3      8:3    0   40G  0 part  
| `-md127   9:127  0   40G  0 raid1 
`-sda4      8:4    0  1.7T  0 part  
sdb         8:16   0  1.8T  0 disk  
|-sdb1      8:17   0   10G  0 part  
| `-md125   9:125  0   10G  0 raid1 
|-sdb2      8:18   0   10G  0 part  
| `-md126   9:126  0   10G  0 raid1 
|-sdb3      8:19   0   40G  0 part  
| `-md127   9:127  0   40G  0 raid1 
`-sdb4      8:20   0  1.7T  0 part  
sdc         8:32   0  3.7T  0 di[   16.709081] EXT4-fs (md125): mounted filesystem with ordered data mode. Opts: (null)
sk  
`-sdc1      8:33   0  3.7T  0 part  
sdd         8:48   0  3.7T  0 disk  
`-sdd1      8:49   0  3.7T  0 part  
sr0        11:0    1 61.5M  0 rom   
BOOT_IMAGE=/boot/vmlinuz-5.10.224-2.el8.nutanix.20241212.100223.x86_64 ro rd_NO_LUKS rd_NO_LVM rd_NO_DM LANG=en_US.UTF-8 SYSFONT=latarcyrheb-sun16 rhgb KEYBOARDTYPE=pc KEYTABLE=us audit=1 audit_backlog_limit=8192 watchdog_thresh=20 nousb nomodeset biosdevname=0 net.ifnames=0 scsi_mod.use_blk_mq=y clocksource=tsc hv_netvsc.ring_size=512 mds=off panic=30 mpt2sas.prot_mask=1 mpt3sas.prot_mask=1 mpt3sas.hbas_to_enumerate=0 mpt2sas.issue_scsi_cmd_to_bringup_drive=0 mpt3sas.issue_scsi_cmd_to_bringup_drive=0 iavmd.direct_assign=1 vmd.direct_assign=1 page_poison=0 slub_debug=n pti=off fips=1 vsyscall=none mitigations=off,eibrs crashkernel=256M console=tty0 console=ttyS0,115200n8
svmboot: Checking /dev/md125 for /.nutanix_active_svm_partition
svmboot: Appropriate boot partition without /.cvm_uuid at /dev/md125
[   16.729386] EXT4-fs (md126): mounted filesystem with ordered data mode. Opts: (null)
[   16.739666] EXT4-fs (md127): mounted filesystem with ordered data mode. Opts: (null)
mount: /mnt: /dev/sda1 already mounted or mount point busy.
mount: /mnt: /dev/sda2 already mounted or mount point busy.
mount: /mnt: /dev/sda3 already mounted or mount point busy.
[   16.779797] EXT4-fs (sda4): mounted filesystem with ordered data mode. Opts: (null)
mount: /mnt: /dev/sdb1 already mounted or mount point busy.
mount: /mnt: /dev/sdb2 already mounted or mount point busy.
mount: /mnt: /dev/sdb3 already mounted or mount point busy.
[   16.820180] EXT4-fs (sdb4): mounted filesystem with ordered data mode. Opts: (null)
[   16.988371] EXT4-fs (sdc1): mounted filesystem with ordered data mode. Opts: (null)
[   17.026913] EXT4-fs (sdd1): INFO: recovery required on readonly filesystem
[   17.028626] EXT4-fs (sdd1): write access will be enabled during recovery
[   17.168695] EXT4-fs (sdd1): recovery complete
[   17.170287] EXT4-fs (sdd1): mounted filesystem with ordered data mode. Opts: (null)
svmboot: booting from only valid boot partition:  /dev/md125
[   17.188951] EXT4-fs (md125): mounted filesystem with ordered data mode. Opts: (null)
svmboot: Using /boot/vmlinuz-5.10.224-2.el8.nutanix.20241212.100223.x86_64
svmboot: Found /boot/vmlinuz-5.10.224-2.el8.nutanix.20241212.100223.x86_64 using the same
svmboot: stopping mdraid
[   17.198773] md125: detected capacity change from 10726932480 to 0
[   17.200250] md: md125 stopped.
[   17.228455] md126: detected capacity change from 10726932480 to 0
[   17.230063] md: md126 stopped.
[   17.247443] md127: detected capacity change from 42914021376 to 0
[   17.249498] md: md127 stopped.
ro rd_NO_LUKS rd_NO_LVM rd_NO_DM LANG=en_US.UTF-8 SYSFONT=latarcyrheb-sun16 rhgb KEYBOARDTYPE=pc KEYTABLE=us audit=1 audit_backlog_limit=8192 watchdog_thresh=20 nousb nomodeset biosdevname=0 net.ifnames=0 scsi_mod.use_blk_mq=y clocksource=tsc hv_netvsc.ring_size=512 mds=off panic=30 mpt2sas.prot_mask=1 mpt3sas.prot_mask=1 mpt3sas.hbas_to_enumerate=0 mpt2sas.issue_scsi_cmd_to_bringup_drive=0 mpt3sas.issue_scsi_cmd_to_bringup_drive=0 iavmd.direct_assign=1 vmd.direct_assign=1 page_poison=0 slub_debug=n pti=off fips=1 vsyscall=none mitigations=off,eibrs crashkernel=no rd_MD_UUID=81b195a2:ccb50c3f:4ffb4457:651111ff root=UUID=cf77fe64-b757-4344-94b6-6780957c5f4b console=ttyS0,115200n8 console=tty0
svmboot: === Setting root to /dev/md125, ROOT_UUID cf77fe64-b757-4344-94b6-6780957c5f4b, RD_MD_UUID 81b195a2:ccb50c3f:4ffb4457:651111ff
svmboot: assemble root RAID 81b195a2:ccb50c3f:4ffb4457:651111ff
===== /etc/mdadm.conf:
# Generated by /home/nutanix/cluster/.venv/bin/lib/python3.9/site-packages/cluster/disk_utils.pyc
AUTO -all
ARRAY /dev/md2 level=raid1 num-devices=2 metadata=1.1 UUID=cff7954e:9221727a:ea4a4b7f:50fbb164
ARRAY /dev/md1 level=raid1 num-devices=2 metadata=1.1 UUID=b034dc4e:c177ac0b:603a718e:691273b0
ARRAY /dev/md0 level=raid1 num-devices=2 metadata=1.1 UUID=81b195a2:ccb50c3f:4ffb4457:651111ff
[   17.293303] md: md2 stopped.
[   17.311641] md/raid1:md2: active with 2 out of 2 mirrors
[   17.312944] md2: detected capacity change from 0 to 42914021376
mdadm: /dev/md2 has been started with 2 drives.
[   17.318917] md: md1 stopped.
[   17.337110] md/raid1:md1: active with 2 out of 2 mirrors
[   17.338403] md1: detected capacity change from 0 to 10726932480
mdadm: /dev/md1 has been started with 2 drives.
[   17.344557] md: md0 stopped.
[   17.363242] md/raid1:md0: active with 2 out of 2 mirrors
[   17.364558] md0: detected capacity change from 0 to 10726932480
mdadm: /dev/md0 has been started with 2 drives.
[   17.386303] EXT4-fs (md0): mounted filesystem with ordered data mode. Opts: (null)
===== mount
rootfs on / type rootfs (rw,size=16282712k,nr_inodes=4070678)
sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
devtmpfs on /dev type devtmpfs (rw,nosuid,size=16282712k,nr_inodes=4070678,mode=755)
securityfs on /sys/kernel/security type securityfs (rw,nosuid,nodev,noexec,relatime)
tmpfs on /dev/shm type tmpfs (rw,nosuid,nodev)
devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)
tmpfs on /run type tmpfs (rw,nosuid,nodev,mode=755)
tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755)
cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)
pstore on /sys/fs/pstore type pstore (rw,nosuid,nodev,noexec,relatime)
none on /sys/fs/bpf type bpf (rw,nosuid,nodev,noexec,relatime,mode=700)
cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)
cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)
cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)
cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)
cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)
cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)
cgroup on /sys/fs/cgroup/rdma type cgroup (rw,nosuid,nodev,noexec,relatime,rdma)
cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)
none on /sys/kernel/tracing type tracefs (rw,relatime)
/dev/md0 on /sysroot type ext4 (ro,relatime)
[  OK  ] Started dracut mount hook.
         Starting dracut pre-pivot and cleanup hook...
[   17.461353] NET: Registered protocol family 38
[   17.483210] dracut-pre-pivot[935]: Jul 12 23:27:32 | /etc/multipath.conf does not exist, blacklisting all devices.
[   17.484957] dracut-pre-pivot[935]: Jul 12 23:27:32 | You can run "/sbin/mpathconf --enable" to create
[   17.486470] dracut-pre-pivot[935]: Jul 12 23:27:32 | /etc/multipath.conf. See man mpathconf(8) for more details
[  OK  ] Started dracut pre-pivot and cleanup hook.
         Starting Cleaning Up and Shutting Down Daemons...
[  OK  ] Stopped dracut pre-pivot and cleanup hook.
         Starting Tell haveged about new root...
[  OK  ] Stopped target Initrd Default Target.
[  OK  ] Stopped dracut mount hook.
[  OK  ] Stopped dracut pre-mount hook.
[  OK  ] Stopped target Timers.
[  OK  ] Stopped target Remote File Systems.
[  OK  ] Stopped target Remote File Systems (Pre).
[  OK  ] Stopped dracut initqueue hook.
         Stopping Open-iSCSI...
[  OK  ] Stopped target Basic System.
[  OK  ] Stopped target Slices.
[  OK  ] Stopped target System Initialization.
[  OK  ] Stopped udev Wait for Complete Device Initialization.
[  OK  ] Stopped udev Coldplug all Devices.
[  OK  ] Stopped dracut pre-trigger hook.
         Stopping udev Kernel Device Manager...
[  OK  ] Stopped Create Volatile Files and Directories.
[  OK  ] Stopped target Local File Systems.
[  OK  ] Stopped target Local File Systems (Pre).
[  OK  ] Stopped Apply Kernel Variables.
[  OK  ] Stopped target Local Encrypted Volumes.
[  OK  ] Stopped Load Kernel Modules.
[  OK  ] Stopped target Swap.
[  OK  ] Stopped target Sockets.
[  OK  ] Stopped target Paths.
[  OK  ] Stopped Dispatch Password Requests to Console Directory Watch.
[  OK  ] Stopped target Initrd Root Device.
[  OK  ] Stopped udev Kernel Device Manager.
[  OK  ] Stopped Open-iSCSI.
[  OK  ] Started Tell haveged about new root.
         Stopping iSCSI UserSpace I/O driver...
[  OK  ] Closed Open-iSCSI iscsid Socket.
[  OK  ] Stopped dracut pre-udev hook.
[  OK  ] Stopped dracut cmdline hook.
[  OK  ] Stopped Create Static Device Nodes in /dev.
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Stopped Create list of required sta…vice nodes for the current kernel.
[  OK  ] Closed udev Control Socket.
[  OK  ] Closed udev Kernel Socket.
         Starting Cleanup udevd DB...
[  OK  ] Stopped iSCSI UserSpace I/O driver.
[  OK  ] Started Cleaning Up and Shutting Down Daemons.
[  OK  ] Closed Open-iSCSI iscsiuio Socket.
[  OK  ] Started Cleanup udevd DB.
[  OK  ] Reached target Switch Root.
         Starting Switch Root...
[  OK  ] Stopped Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[   18.062102] printk: systemd: 31 output lines suppressed due to ratelimiting
[   18.278695] SELinux:  Permission watch in class filesystem not defined in policy.
[   18.280398] SELinux:  Permission watch in class file not defined in policy.
[   18.281889] SELinux:  Permission watch_mount in class file not defined in policy.
[   18.283523] SELinux:  Permission watch_sb in class file not defined in policy.
[   18.285115] SELinux:  Permission watch_with_perm in class file not defined in policy.
[   18.286821] SELinux:  Permission watch_reads in class file not defined in policy.
[   18.288471] SELinux:  Permission watch in class dir not defined in policy.
[   18.289964] SELinux:  Permission watch_mount in class dir not defined in policy.
[   18.291593] SELinux:  Permission watch_sb in class dir not defined in policy.
[   18.293133] SELinux:  Permission watch_with_perm in class dir not defined in policy.
[   18.294816] SELinux:  Permission watch_reads in class dir not defined in policy.
[   18.296439] SELinux:  Permission watch in class lnk_file not defined in policy.
[   18.298040] SELinux:  Permission watch_mount in class lnk_file not defined in policy.
[   18.299745] SELinux:  Permission watch_sb in class lnk_file not defined in policy.
[   18.301402] SELinux:  Permission watch_with_perm in class lnk_file not defined in policy.
[   18.303173] SELinux:  Permission watch_reads in class lnk_file not defined in policy.
[   18.304893] SELinux:  Permission watch in class chr_file not defined in policy.
[   18.306497] SELinux:  Permission watch_mount in class chr_file not defined in policy.
[   18.308246] SELinux:  Permission watch_sb in class chr_file not defined in policy.
[   18.309899] SELinux:  Permission watch_with_perm in class chr_file not defined in policy.
[   18.311681] SELinux:  Permission watch_reads in class chr_file not defined in policy.
[   18.313390] SELinux:  Permission watch in class blk_file not defined in policy.
[   18.314990] SELinux:  Permission watch_mount in class blk_file not defined in policy.
[   18.316709] SELinux:  Permission watch_sb in class blk_file not defined in policy.
[   18.318358] SELinux:  Permission watch_with_perm in class blk_file not defined in policy.
[   18.320136] SELinux:  Permission watch_reads in class blk_file not defined in policy.
[   18.321844] SELinux:  Permission watch in class sock_file not defined in policy.
[   18.323463] SELinux:  Permission watch_mount in class sock_file not defined in policy.
[   18.325183] SELinux:  Permission watch_sb in class sock_file not defined in policy.
[   18.326872] SELinux:  Permission watch_with_perm in class sock_file not defined in policy.
[   18.328658] SELinux:  Permission watch_reads in class sock_file not defined in policy.
[   18.330377] SELinux:  Permission watch in class fifo_file not defined in policy.
[   18.332000] SELinux:  Permission watch_mount in class fifo_file not defined in policy.
[   18.333714] SELinux:  Permission watch_sb in class fifo_file not defined in policy.
[   18.335381] SELinux:  Permission watch_with_perm in class fifo_file not defined in policy.
[   18.337172] SELinux:  Permission watch_reads in class fifo_file not defined in policy.
[   18.338926] SELinux:  Permission perfmon in class capability2 not defined in policy.
[   18.340627] SELinux:  Permission bpf in class capability2 not defined in policy.
[   18.342268] SELinux:  Permission perfmon in class cap2_userns not defined in policy.
[   18.343954] SELinux:  Permission bpf in class cap2_userns not defined in policy.
[   18.345595] SELinux:  Class lockdown not defined in policy.
[   18.346811] SELinux: the above unknown classes and permissions will be allowed
[   18.350312] SELinux:  policy capability network_peer_controls=1
[   18.351629] SELinux:  policy capability open_perms=1
[   18.352738] SELinux:  policy capability extended_socket_class=1
[   18.354019] SELinux:  policy capability always_check_network=0
[   18.355295] SELinux:  policy capability cgroup_seclabel=1
[   18.356487] SELinux:  policy capability nnp_nosuid_transition=1
[   18.357770] SELinux:  policy capability genfs_seclabel_symlinks=0
[   18.359090] SELinux:  policy capability ioctl_skip_cloexec=0
[   18.383313] systemd[1]: Successfully loaded SELinux policy in 198.770ms.
[   18.408771] systemd[1]: Relabelled /dev, /run and /sys/fs/cgroup in 17.169ms.
[   18.411978] systemd[1]: systemd 239 (239-82.el8) running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +SECCOMP +BLKID +ELFUTILS +KMOD +IDN2 -IDN +PCRE2 default-hierarchy=legacy)
[   18.416719] systemd[1]: Detected virtualization kvm.
[   18.417832] systemd[1]: Detected architecture x86-64.

Welcome to Rocky Linux 8.10 (Green Obsidian)!

[   18.421026] systemd[1]: Initializing machine ID from KVM UUID.
[   18.422350] systemd[1]: Installed transient /etc/machine-id file.
[   18.538277] systemd[1]: Configuration file /usr/lib/systemd/system/genesis_stop.service is marked executable. Please remove executable permission bits. Proceeding anyway.
[   18.581286] systemd[1]: initrd-switch-root.service: Succeeded.
[   18.582814] systemd[1]: Stopped Switch Root.
[  OK  ] Stopped Switch Root.
[   18.584643] systemd[1]: haveged.service: Service RestartSec=100ms expired, scheduling restart.
[   18.586537] systemd[1]: haveged.service: Stop job pending for unit, delaying automatic restart.
[  OK  ] Stopped Journal Service.
[  OK  ] Stopped Entropy Daemon based on the HAVEGE algorithm.
         Starting Journal Service...
[  OK  ] Listening on udev Control Socket.
[  OK  ] Created slice system-serial\x2dgetty.slice.
[  OK  ] Listening on RPCbind Server Activation Socket.
         Starting Read and set NIS domainname from /etc/sysconfig/network...
[  OK  ] Created slice User and Session Slice.
[  OK  ] Reached target Swap.
[  OK  ] Reached target RPC Port Mapper.
[  OK  ] Reached target Slices.
[  OK  ] Created slice system-systemd\x2dfsck.slice.
         Starting Load Kernel Modules...
[  OK  ] Listening on Process Core Dump Socket.
[  OK  ] Created slice system-sshd\x2dkeygen.slice.
[  OK  ] Listening on initctl Compatibility Named Pipe.
         Mounting Kernel Debug File System...
         Mounting Huge Pages File System...
         Starting Create list of required st…ce nodes for the current kernel...
         Mounting POSIX Message Queue File System...
[  OK  ] Created slice system-getty.slice.
[  OK  ] Listening on udev Kernel Socket.
         Starting udev Coldplug all Devices...
[  OK  ] Stopped target Switch Root.
[  OK  ] Stopped target Initrd File Systems.
[  OK  ] Stopped target Initrd Root File System.
[  OK  ] Started Forward Password Requests to Wall Directory Watch.
         Starting File System Check on Root Device...
[  OK  ] Started Dispatch Password Requests to Console Directory Watch.
[  OK  ] Reached target Paths.
[  OK  ] Reached target Local Encrypted Volumes.
[  OK  ] Started Read and set NIS domainname from /etc/sysconfig/network.
[  OK  ] Mounted Kernel Debug File System.
[  OK  ] Mounted Huge Pages File System.
[  OK  ] Mounted POSIX Message Queue File System.
[  OK  ] Started Create list of required sta…vice nodes for the current kernel.
[  OK  ] Started Load Kernel Modules.
         Starting Apply Kernel Variables...
         Mounting FUSE Control File System...
[  OK  ] Mounted FUSE Control File System.
[  OK  ] Started Apply Kernel Variables.
[  OK  ] Started Journal Service.
[  OK  ] Started udev Coldplug all Devices.
         Starting udev Wait for Complete Device Initialization...
[  OK  ] Started File System Check on Root Device.
         Starting Remount Root and Kernel File Systems...
[  OK  ] Started Remount Root and Kernel File Systems.
         Starting Create System Users...
         Starting Rebuild Hardware Database...
[  OK  ] Started Create System Users.
         Starting Create Static Device Nodes in /dev...
[  OK  ] Started Create Static Device Nodes in /dev.
[  OK  ] Started Rebuild Hardware Database.
         Starting udev Kernel Device Manager...
[  OK  ] Started udev Kernel Device Manager.
[  OK  ] Started Entropy Daemon based on the HAVEGE algorithm.
[  OK  ] Started udev Wait for Complete Device Initialization.
[  OK  ] Reached target Local File Systems (Pre).
         Starting File System Check on /dev/…a07-062d-4297-8d35-b02c431414aa...
         Mounting /var...
[  OK  ] Mounted /var.
         Starting Load/Save Random Seed...
         Mounting /var/log...
[  OK  ] Mounted /var/log.
[  OK  ] Started Load/Save Random Seed.
[  OK  ] Started File System Check on /dev/d…90a07-062d-4297-8d35-b02c431414aa.
         Mounting /home...
[  OK  ] Mounted /home.
         Mounting /home/log/audit...
         Mounting /var/log/journal...
[  OK  ] Mounted /var/log/journal.
         Starting Flush Journal to Persistent Storage...
[  OK  ] Mounted /home/log/audit.
         Mounting /var/log/audit...
[  OK  ] Mounted /var/log/audit.
[  OK  ] Reached target Local File Systems.
         Starting Import network configuration from initramfs...
         Starting Rebuild Journal Catalog...
         Starting Commit a transient machine-id on disk...
         Starting Rebuild Dynamic Linker Cache...
[  OK  ] Started Genesis Stop Service.
[  OK  ] Started Import network configuration from initramfs.
[  OK  ] Started Flush Journal to Persistent Storage.
         Starting Create Volatile Files and Directories...
[  OK  ] Started Rebuild Journal Catalog.
[  OK  ] Started Commit a transient machine-id on disk.
[  OK  ] Started Rebuild Dynamic Linker Cache.
         Starting Update is Completed...
[  OK  ] Started Create Volatile Files and Directories.
         Starting Security Auditing Service...
         Starting RPC Bind...
[FAILED] Failed to start Security Auditing Service.
See 'systemctl status auditd.service' for details.
         Starting Update UTMP about System Boot/Shutdown...
[  OK  ] Started Update is Completed.
[  OK  ] Started RPC Bind.
[  OK  ] Started Update UTMP about System Boot/Shutdown.
[  OK  ] Reached target System Initialization.
[  OK  ] Listening on D-Bus System Message Bus Socket.
[  OK  ] Listening on Open-iSCSI iscsiuio Socket.
[  OK  ] Started Run system activity accounting tool every 10 minutes.
[  OK  ] Started Generate summary of yesterday's process accounting.
[  OK  ] Started Daily Cleanup of Temporary Directories.
[  OK  ] Started dnf makecache --timer.
[  OK  ] Reached target Timers.
[  OK  ] Listening on Open-iSCSI iscsid Socket.
[  OK  ] Reached target Sockets.
[  OK  ] Reached target Basic System.
         Starting IP sets for iptables...
[  OK  ] Started irqbalance daemon.
         Starting openibd - configure Mellanox devices...
         Starting Restore /run/initramfs on shutdown...
         Starting Login Service...
         Starting NTP client/server...
         Starting Software RAID monitoring and management...
         Starting Resets System Activity Logs...
         Starting OpenSSH rsa Server Key Generation...
         Starting OpenSSH ecdsa Server Key Generation...
         Starting OpenSSH ed25519 Server Key Generation...
         Starting Self Monitoring and Reporting Technology (SMART) Daemon...
[  OK  ] Started D-Bus System Message Bus.
[  OK  ] Started Restore /run/initramfs on shutdown.
[FAILED] Failed to start Software RAID monitoring and management.
See 'systemctl status mdmonitor.service' for details.
[FAILED] Failed to start Resets System Activity Logs.
See 'systemctl status sysstat.service' for details.
[  OK  ] Started OpenSSH ed25519 Server Key Generation.
[  OK  ] Stopped Security Auditing Service.
         Starting Security Auditing Service...
[  OK  ] Started IP sets for iptables.
[  OK  ] Started OpenSSH ecdsa Server Key Generation.
[FAILED] Failed to start Security Auditing Service.
See 'systemctl status auditd.service' for details.
         Starting IPv6 firewall with ip6tables...
         Starting IPv4 firewall with iptables...
[  OK  ] Started Login Service.
[  OK  ] Started Self Monitoring and Reporting Technology (SMART) Daemon.
[  OK  ] Started IPv4 firewall with iptables.
[  OK  ] Stopped Security Auditing Service.
         Starting Security Auditing Service...
[  OK  ] Started NTP client/server.
[  OK  ] Started IPv6 firewall with ip6tables.
[FAILED] Failed to start Security Auditing Service.
See 'systemctl status auditd.service' for details.
[  OK  ] Reached target Network (Pre).
[  OK  ] Stopped Security Auditing Service.
         Starting Security Auditing Service...
[FAILED] Failed to start Security Auditing Service.
See 'systemctl status auditd.service' for details.
[  OK  ] Started openibd - configure Mellanox devices.
[  OK  ] Stopped Security Auditing Service.
         Starting Security Auditing Service...
[  OK  ] Started RPM DB Check Service.
         Starting LSB: Bring up/down networking...
[FAILED] Failed to start Security Auditing Service.
See 'systemctl status auditd.service' for details.
[  OK  ] Stopped Security Auditing Service.
[FAILED] Failed to start Security Auditing Service.
See 'systemctl status auditd.service' for details.
[  OK  ] Started OpenSSH rsa Server Key Generation.
[  OK  ] Reached target sshd-keygen.target.
[  OK  ] Started LSB: Bring up/down networking.
[  OK  ] Reached target Network.
         Starting OpenSSH server daemon...
         Starting Logout off all iSCSI sessions on shutdown...
[  OK  ] Reached target Network is Online.
         Starting System Logging Service...
[  OK  ] Started Logout off all iSCSI sessions on shutdown.
[  OK  ] Reached target Remote File Systems (Pre).
[  OK  ] Reached target Remote File Systems.
         Starting Permit User Sessions...
         Starting Crash recovery kernel arming...
[  OK  ] Started OpenSSH server daemon.
[  OK  ] Started System Logging Service.
[  OK  ] Started Permit User Sessions.
[  OK  ] Started Serial Getty on ttyS0.
[  OK  ] Started Getty on tty1.
[  OK  ] Reached target Login Prompts.
[  OK  ] Started Command Scheduler.
[  OK  ] Reached target Multi-User System.
         Starting Update UTMP about System Runlevel Changes...
         Starting Nutanix rc.local compatibility...
[  OK  ] Started Update UTMP about System Runlevel Changes.
         Stopping RPC Bind...
[  OK  ] Stopped RPC Bind.
         Starting RPC Bind...
[  OK  ] Started RPC Bind.
[  OK  ] Created slice User Slice of UID 0.
         Starting User runtime directory /run/user/0...
[  OK  ] Started User runtime directory /run/user/0.
         Starting User Manager for UID 0...
[  OK  ] Started User Manager for UID 0.
[  OK  ] Started Session c1 of user root.
[  OK  ] Started /usr/bin/systemctl start man-db-cache-update.
         Starting man-db-cache-update.service...
[  OK  ] Started man-db-cache-update.service.
         Stopping User Manager for UID 0...
[  OK  ] Stopped User Manager for UID 0.
         Stopping User runtime directory /run/user/0...
[  OK  ] Stopped User runtime directory /run/user/0.
[  OK  ] Removed slice User Slice of UID 0.
[  OK  ] Created slice User Slice of UID 0.
         Starting User runtime directory /run/user/0...
[  OK  ] Started User runtime directory /run/user/0.
         Starting User Manager for UID 0...
[  OK  ] Started User Manager for UID 0.
[  OK  ] Started Session c25 of user root.
[  OK  ] Started Session c26 of user root.
[  OK  ] Started Session c27 of user root.
[  OK  ] Started Session c28 of user root.
[  OK  ] Started Session c29 of user root.
[  OK  ] Started Session c30 of user root.
[  OK  ] Started Session c31 of user root.
[  OK  ] Started Session c32 of user root.
[  OK  ] Started Session c33 of user root.
[  OK  ] Started Session c34 of user root.
[  OK  ] Started Session c35 of user root.
         Stopping User Manager for UID 0...
[  OK  ] Stopped User Manager for UID 0.
         Stopping User runtime directory /run/user/0...
[  OK  ] Stopped User runtime directory /run/user/0.
[  OK  ] Removed slice User Slice of UID 0.
[  OK  ] Created slice User Slice of UID 0.
         Starting User runtime directory /run/user/0...
[  OK  ] Started User runtime directory /run/user/0.
         Starting User Manager for UID 0...
[  OK  ] Started User Manager for UID 0.
[  OK  ] Started Session c36 of user root.
[  OK  ] Started Session c37 of user root.
[  OK  ] Started Session c38 of user root.
[  OK  ] Started Session c39 of user root.
[  OK  ] Started Session c40 of user root.
[  OK  ] Started Session c41 of user root.
[  OK  ] Started Session c42 of user root.
[  OK  ] Started Session c43 of user root.
[  OK  ] Started Session c44 of user root.
[  OK  ] Started Session c45 of user root.
[  OK  ] Started Session c46 of user root.
[  OK  ] Started Session c47 of user root.
[  OK  ] Started Session c48 of user root.
[  OK  ] Started Session c49 of user root.
[  OK  ] Started Session c50 of user root.
[  OK  ] Started Session c51 of user root.
[  OK  ] Started Session c52 of user root.
[  OK  ] Started Session c53 of user root.
[  OK  ] Started Session c54 of user root.
[  OK  ] Started Session c55 of user root.
[  OK  ] Started Session c56 of user root.
[  OK  ] Started Session c57 of user root.
[  OK  ] Started Session c58 of user root.
[  OK  ] Started Session c59 of user root.
[  OK  ] Started Session c60 of user root.
[  OK  ] Started Session c61 of user root.
[  OK  ] Started Session c62 of user root.
[  OK  ] Started Session c63 of user root.
[  OK  ] Started Session c64 of user root.
[  OK  ] Started Session c65 of user root.
[  OK  ] Started Session c66 of user root.
[  OK  ] Started Session c67 of user root.
[  OK  ] Started Session c68 of user root.
[  OK  ] Started Session c69 of user root.
[  OK  ] Started Session c70 of user root.
[  OK  ] Started Session c71 of user root.
[  OK  ] Started Session c72 of user root.
[  OK  ] Started Session c73 of user root.
[  OK  ] Started Session c74 of user root.
[  OK  ] Started Session c75 of user root.
[  OK  ] Started Session c76 of user root.
[  OK  ] Started Session c77 of user root.
[  OK  ] Started Session c78 of user root.
[  OK  ] Started Session c79 of user root.
[  OK  ] Started Session c80 of user root.
[  OK  ] Created slice User Slice of UID 1000.
         Starting User runtime directory /run/user/1000...
[  OK  ] Started User runtime directory /run/user/1000.
         Starting User Manager for UID 1000...
[  OK  ] Started User Manager for UID 1000.
[  OK  ] Started Session c81 of user nutanix.
[  OK  ] Started Session c82 of user nutanix.
         Stopping User Manager for UID 0...
[  OK  ] Stopped User Manager for UID 0.
         Stopping User runtime directory /run/user/0...
[  OK  ] Stopped User runtime directory /run/user/0.
[  OK  ] Removed slice User Slice of UID 0.
         Stopping User Manager for UID 1000...
[  OK  ] Stopped User Manager for UID 1000.
         Stopping User runtime directory /run/user/1000...
[  OK  ] Stopped User runtime directory /run/user/1000.
[  OK  ] Removed slice User Slice of UID 1000.
[  OK  ] Created slice User Slice of UID 0.
         Starting User runtime directory /run/user/0...
[  OK  ] Started User runtime directory /run/user/0.
         Starting User Manager for UID 0...
[  OK  ] Started User Manager for UID 0.
[  OK  ] Started Session c83 of user root.
[  OK  ] Started Session c84 of user root.
[  OK  ] Started Session c85 of user root.
[  OK  ] Started Session c86 of user root.
[  OK  ] Started Session c87 of user root.
[  OK  ] Started Session c88 of user root.
[  OK  ] Started Session c89 of user root.
[  OK  ] Started Session c90 of user root.
[  OK  ] Started Session c91 of user root.
         Stopping User Manager for UID 0...
[  OK  ] Stopped User Manager for UID 0.
         Stopping User runtime directory /run/user/0...
[  OK  ] Stopped User runtime directory /run/user/0.
[  OK  ] Removed slice User Slice of UID 0.
[  OK  ] Created slice User Slice of UID 0.
         Starting User runtime directory /run/user/0...
[  OK  ] Started User runtime directory /run/user/0.
         Starting User Manager for UID 0...
[  OK  ] Started User Manager for UID 0.
[  OK  ] Started Session c92 of user root.
         Stopping System Logging Service...
[  OK  ] Stopped System Logging Service.
         Stopping NTP client/server...
[  OK  ] Stopped NTP client/server.
[  OK  ] Started Session c93 of user root.
[  OK  ] Started Session c94 of user root.
[  OK  ] Started Session c95 of user root.
[  OK  ] Started Session c96 of user root.
[  OK  ] Started Session c97 of user root.
[  OK  ] Started Session c98 of user root.
[  OK  ] Started Session c99 of user root.
[  OK  ] Started Session c100 of user root.
[  OK  ] Started Session c101 of user root.
[  OK  ] Started Session c102 of user root.
[  OK  ] Started Session c103 of user root.
[  OK  ] Started Session c104 of user root.
[  OK  ] Started Session c105 of user root.
[  OK  ] Started Session c106 of user root.
[  OK  ] Started Session c107 of user root.
[  OK  ] Started Session c108 of user root.
[  OK  ] Started Session c109 of user root.
[  OK  ] Started Session c110 of user root.
[  OK  ] Started Session c111 of user root.
[  OK  ] Started Session c112 of user root.
[  OK  ] Started Session c113 of user root.
[  OK  ] Started Session c114 of user root.
[  OK  ] Started Session c115 of user root.
[  OK  ] Started Session c116 of user root.
[  OK  ] Started Session c117 of user root.
[  OK  ] Started Session c118 of user root.
[  OK  ] Started Session c119 of user root.
[  OK  ] Started Session c120 of user root.
[  OK  ] Started Session c121 of user root.
[  OK  ] Started Session c122 of user root.
[  OK  ] Started Session c123 of user root.
[  OK  ] Started Session c124 of user root.
[  OK  ] Started Session c125 of user root.
[  OK  ] Started Session c126 of user root.
[  OK  ] Started Session c127 of user root.
[  OK  ] Started Session c128 of user root.
[  OK  ] Started Session c129 of user root.
[  OK  ] Started Session c130 of user root.
[  OK  ] Started Session c131 of user root.
[  OK  ] Started Session c132 of user root.
[  OK  ] Started Session c133 of user root.
[  OK  ] Started Session c134 of user root.
[  OK  ] Started Session c135 of user root.
         Starting system activity accounting tool...
[FAILED] Failed to start system activity accounting tool.
See 'systemctl status sysstat-collect.service' for details.
[  OK  ] Started Session c136 of user root.
[  OK  ] Started Session c137 of user root.
[  OK  ] Started Session c138 of user root.
[  OK  ] Started Session c139 of user root.
[  OK  ] Started Session c140 of user root.
[  OK  ] Started Session c141 of user root.
[  OK  ] Started Session c142 of user root.
[  OK  ] Started Session c143 of user root.
[  OK  ] Started Session c144 of user root.
[  OK  ] Started Session c145 of user root.
[  OK  ] Started Session c146 of user root.
[  OK  ] Started Session c147 of user root.
[  OK  ] Started Session c148 of user root.
[  OK  ] Started Session c149 of user root.
[  OK  ] Started Session c150 of user root.
[  OK  ] Started Session c151 of user root.
[  OK  ] Started Session c152 of user root.
[  OK  ] Created slice User Slice of UID 1000.
         Starting User runtime directory /run/user/1000...
[  OK  ] Started Session c153 of user root.
[  OK  ] Started User runtime directory /run/user/1000.
         Starting User Manager for UID 1000...
[  OK  ] Started Session c154 of user root.
[  OK  ] Started Session c155 of user root.
[  OK  ] Started Session c156 of user root.
[  OK  ] Started User Manager for UID 1000.
[  OK  ] Started Session 9 of user nutanix.
[  OK  ] Started Session 12 of user nutanix.
[  OK  ] Started Session 10 of user nutanix.
[  OK  ] Started Session 11 of user nutanix.
[  OK  ] Started Session c157 of user root.
[  OK  ] Started Session c158 of user root.
[  OK  ] Started Session c159 of user root.
[  OK  ] Started Session c160 of user root.
[  OK  ] Started Session c161 of user root.
[  OK  ] Started Session c162 of user root.
[  OK  ] Started Session c163 of user root.
[  OK  ] Started Session c164 of user root.
[  OK  ] Created slice User Slice of UID 2000.
         Starting User runtime directory /run/user/2000...
[  OK  ] Started User runtime directory /run/user/2000.
         Starting User Manager for UID 2000...
[  OK  ] Started User Manager for UID 2000.
[  OK  ] Started Session c165 of user admin.
[  OK  ] Started Session c166 of user root.
[  OK  ] Started Session c167 of user root.
[  OK  ] Started Session c168 of user root.
[  OK  ] Started Session c169 of user root.
[  OK  ] Started Session c170 of user root.
[  OK  ] Started Session c171 of user root.
[  OK  ] Started Session c172 of user root.
[  OK  ] Started Session c173 of user root.
[  OK  ] Started Session c174 of user root.
         Starting System Logging Service...
[  OK  ] Started System Logging Service.
         Starting NTP client/server...
[  OK  ] Started NTP client/server.
[  OK  ] Started Session c175 of user root.
         Stopping OpenSSH server daemon...
[  OK  ] Stopped OpenSSH server daemon.
[  OK  ] Stopped target sshd-keygen.target.
         Stopping sshd-keygen.target.
         Starting OpenSSH ecdsa Server Key Generation...
         Starting OpenSSH rsa Server Key Generation...
         Starting OpenSSH ed25519 Server Key Generation...
[  OK  ] Started OpenSSH ed25519 Server Key Generation.
[  OK  ] Started OpenSSH ecdsa Server Key Generation.
[  OK  ] Started OpenSSH rsa Server Key Generation.
[  OK  ] Reached target sshd-keygen.target.
         Starting OpenSSH server daemon...
[  OK  ] Started OpenSSH server daemon.
[  OK  ] Started Session c176 of user root.
         Stopping User Manager for UID 1000...
         Stopping User Manager for UID 2000...
[  OK  ] Stopped User Manager for UID 1000.
[  OK  ] Stopped User Manager for UID 2000.
         Stopping User runtime directory /run/user/2000...
         Stopping User runtime directory /run/user/1000...
[  OK  ] Stopped User runtime directory /run/user/1000.
[  OK  ] Removed slice User Slice of UID 1000.
[  OK  ] Stopped User runtime directory /run/user/2000.
[  OK  ] Removed slice User Slice of UID 2000.


Rocky Linux 8.10 (Green Obsidian)
Kernel 5.10.224-2.el8.nutanix.20241212.100223.x86_64 on an x86_64

localhost login:]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <strong>15.</strong> <span style="color: rgb(23,43,77);">Once the rescued CVM is finished booting normally into the AOS kernel, it will be in a <span style="color: rgb(23,43,77);">partially-unconfigured state. The network configuration and unique files in /etc/nutanix are mostly gone and the CVM will not be broadcasting itself to Foundation.</span>
              <br/>From the AHV host ssh into the CVM over the internal 192.168.5.254 IP address as the regular '</span> <strong>nutanix</strong> <span style="color: rgb(23,43,77);">' user with default password '</span> <strong>nutanix/4u</strong> <span style="color: rgb(23,43,77);">':</span>
          </p>
          <ac:structured-macro ac:macro-id="8b2d917d-1227-4f95-b5f8-82144705f0bd" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[[root@ahv ~]#  ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null nutanix@192.168.5.254]]></ac:plain-text-body>
          </ac:structured-macro>
          <ac:structured-macro ac:macro-id="7213de3c-e500-46e2-87e8-441c408c9dd7" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[Warning: Permanently added '192.168.5.254' (ECDSA) to the list of known hosts.
Nutanix Controller VM
nutanix@192.168.5.254's password:  {nutanix/4u}

Nutanix Controller VM (CVM) is a virtual storage appliance.

Alteration of the CVM (unless advised by Nutanix Technical Support or
Support Portal Documentation) is unsupported and may result in loss
of User VMs or other data residing on the cluster.

Unsupported alterations may include (but are not limited to):

- Configuration changes / removal of files.
- Installation of third-party software/scripts not approved by Nutanix.
- Installation or upgrade of software packages from non-Nutanix
  sources (using yum, rpm, or similar).

** SSH to CVM via 'nutanix' user will be restricted in coming releases.  **
** Please consider using the 'admin' user for basic workflows.           **
Last login: Sat Jul 12 23:32:09 UTC 2025
Last login: Sat Jul 12 23:32:50 2025 from 192.168.5.1

nutanix@::~$]]></ac:plain-text-body>
          </ac:structured-macro>
          <ac:structured-macro ac:macro-id="f6759023-afa6-426b-9299-55a12ab238f3" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@::~$  genesis status

2025-07-12 13:59:50.837358: Services running on this node:
  genesis: [4715, 57026, 57064, 57065]]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">16.</strong> <span style="letter-spacing: 0.0px;">Bring up the CVM's eth0 interface. <span style="color: rgb(23,43,77);">If IPv6 is enabled, take this opportunity to note down the IPv6 address of eth0, as this will be needed for invoking the boot_disk_replace script in the next section of the document.</span>
            </span>
          </p>
          <ac:structured-macro ac:macro-id="5ff70ec9-fa10-44b3-9f90-d466096c95c3" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">text</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@::~$  sudo ip link set eth0 up

nutanix@::~$  ip addr show dev eth0
3: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 52:54:00:3d:f5:b6 brd ff:ff:ff:ff:ff:ff
    altname enp0s3
    altname ens3
    inet6 fe80::5054:ff:fe3d:f5b6/64 scope link 
       valid_lft forever preferred_lft forever

nutanix@::~$  ifconfig eth0
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::5054:ff:fe3d:f5b6  prefixlen 64  scopeid 0x20<link>                  <--------- Record the IPv6 address of eth0
        ether 52:54:00:3d:f5:b6  txqueuelen 1000  (Ethernet)
        RX packets 2504  bytes 404492 (395.0 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 7  bytes 586 (586.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>If IPv6 is not enabled within the customer's environment, the <em> <strong>/etc/sysconfig/network-scripts/ifcfg-eth0</strong> </em> config file must be created with the necessary IPv4 <span style="color: rgb(23,43,77);">network information of the CVM:<br/>
              </span>
              <ac:structured-macro ac:macro-id="889b2dcb-e6ed-49c7-b188-7dfe5858f93c" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">text</ac:parameter>
                <ac:plain-text-body><![CDATA[nutanix@::~$  vi /etc/sysconfig/network-scripts/ifcfg-eth0]]></ac:plain-text-body>
              </ac:structured-macro>
              <ac:structured-macro ac:macro-id="c0ba34fb-3f9b-4cbe-8c64-262fb04099ce" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">text</ac:parameter>
                <ac:plain-text-body><![CDATA[DEVICE="eth0"
NM_CONTROLLED="no"
ONBOOT="yes"
TYPE="Ethernet"
IPADDR="{X.X.X.X}"
NETMASK="{X.X.X.X}"
GATEWAY="{X.X.X.X}"
NOZEROCONF="yes"
BOOTPROTO="none"]]></ac:plain-text-body>
              </ac:structured-macro>
              <span style="color: rgb(23,43,77);"> <br/>After the CVM's <em> <strong>/etc/sysconfig/network-scripts/ifcfg-eth0</strong> </em> config file is created and saved, reboot the CVM:<br/>
              </span>
              <ac:structured-macro ac:macro-id="bd26b303-20eb-443a-804c-a053981497ca" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">text</ac:parameter>
                <ac:plain-text-body><![CDATA[nutanix@::~$  sudo shutdown -r 0]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>
            <strong style="letter-spacing: 0.0px;">17.</strong> <span style="letter-spacing: 0.0px;"> At this stage, the `</span> <strong style="letter-spacing: 0.0px;">boot_disk_replace</strong> <span style="letter-spacing: 0.0px;">` script residing on <span style="color: rgb(23,43,77);">a working CVM that is a member of the the same Nutanix cluster</span> must be executed in order to re-apply the repaired CVM's original configuration information. This is a necessary step in order for the recreated CVM to be recognizable and usable by the existing cluster again.</span>
          </p>
          <p>
            <span style="letter-spacing: 0.0px;">Proceed to the section below titled "</span> <em style="letter-spacing: 0.0px;"> <strong>Using the `boot_disk_replace` Script</strong> </em> <span style="letter-spacing: 0.0px;">"</span>
          </p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <h3>Using the boot_disk_replace Script - Restore CVM cluster configuration after repair</h3>
      <p>This section covers the post-repair configuration process using the boot_disk_replace script. After any repair operation, this script is essential to restore the CVM's cluster configuration and make it recognizable by the existing cluster again.</p>
      <ac:structured-macro ac:macro-id="boot-disk-tips" ac:name="info" ac:schema-version="1">
        <ac:parameter ac:name="title">Tips and Gotchas</ac:parameter>
        <ac:rich-text-body>
          <p>
            <strong>When to use boot_disk_replace:</strong>
          </p>
          <ul>
            <li>After any CVM repair operation (Phoenix or single_ssd_repair)</li>
            <li>When a repaired CVM needs to rejoin the cluster</li>
            <li>To restore cluster configuration information</li>
            <li>As part of the post-repair workflow</li>
          </ul>
          <p>
            <strong>Important considerations:</strong>
          </p>
          <ul>
            <li>Must be run from a working CVM in the cluster</li>
            <li>Repaired CVM must be powered on and reachable</li>
            <li>Use correct IP addressing (IPv4/IPv6)</li>
            <li>Include hypervisor password if non-default</li>
            <li>For 2-node clusters, refer to KB-11378 for specific guidance</li>
          </ul>
        </ac:rich-text-body>
      </ac:structured-macro>
      <ac:structured-macro ac:macro-id="expand-boot-disk-replace" ac:name="expand" ac:schema-version="1">
        <ac:parameter ac:name="title">Click to view post-repair configuration</ac:parameter>
        <ac:rich-text-body>
          <ac:structured-macro ac:macro-id="boot-disk-replace-overview" ac:name="info" ac:schema-version="1">
            <ac:parameter ac:name="title">Post-Repair Configuration</ac:parameter>
            <ac:rich-text-body>
              <p>The <code>boot_disk_replace</code> script is a utility within the AOS kernel that re-applies a repaired CVM's original configuration information to make it recognizable and usable by the existing cluster again.</p>
              <p>
                <strong>Script Location:</strong> <code>/usr/local/nutanix/cluster/bin/boot_disk_replace</code>
              </p>
              <p>
                <strong>Important Note:</strong> For 2-node clusters, refer to <a href="https://portal.nutanix.com/kb/11378">KB-11378: Using boot_disk_replace script on a node in two-node cluster</a> for specific guidance.</p>
            </ac:rich-text-body>
          </ac:structured-macro>
          <h3>Overview</h3>
          <p>
            <span style="color: rgb(23,43,77);">The location of the script on the CVM is at <em> <strong>/usr/local/nutanix/cluster/bin/boot_disk_replace</strong> </em>.<br/>
            </span>
          </p>
          <p>
            <span style="color: rgb(23,43,77);"> <strong>*Note</strong>: Utilize <strong> <a href="https://portal.nutanix.com/kb/11378">KB-11378: Using boot_disk_replace script on a node in two-node cluster</a> </strong> if it is determined that a CVM within a 2-node cluster needed to be rescued.</span>
          </p>
          <p>
            <span style="letter-spacing: -0.008em;font-size: 20.0px;">Prerequisites</span>
          </p>
          <p>
            <span>- The repaired CVM must be powered on</span>, and either discoverable via IPv6 multicast in the environment or reachable over its configured IPv4 address</p>
          <p>
            <span style="letter-spacing: 0.0px;">- The script must be run from a working CVM</span>
          </p>
          <p>
            <span style="font-size: 20.0px;letter-spacing: -0.008em;">Script Usage</span>
          </p>
          <p>From a working CVM, run the `<strong>boot_disk_replace</strong>` script with the following syntax corresponding to whether IPv6 multicast discovery is enabled in the environment or only reachable over its IPv4 address:</p>
          <p>
            <strong>*Note</strong>: The '<strong>--hypervisor_password='{HYPERVISOR_PASSWD}'</strong>' flag is required with the correct hypervisor password specified if the hypervisor password is non-default.</p>
          <p>
            <strong>- For IPv6</strong>:</p>
          <ac:structured-macro ac:macro-id="22b9d3f7-2a27-46ed-818d-b9c06fa4f0aa" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">IPv6 with IPv4 fallback</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ boot_disk_replace -s {CVM_IPv6_ADDR} -i {CVM_IPv4_ADDR} [--hypervisor_password='{HYPERVISOR_PASSWD}']]]></ac:plain-text-body>
          </ac:structured-macro>
          <p>
            <strong style="letter-spacing: 0.0px;">- For IPv4</strong> <span style="letter-spacing: 0.0px;">:</span>
          </p>
          <ac:structured-macro ac:macro-id="c8abe86b-8d8d-4671-b245-1c7a1babbcf9" ac:name="code" ac:schema-version="1">
            <ac:parameter ac:name="language">bash</ac:parameter>
            <ac:parameter ac:name="title">IPv4 only</ac:parameter>
            <ac:plain-text-body><![CDATA[nutanix@cvm:~$ boot_disk_replace -i {CVM_IPv4_ADDR} [--hypervisor_password='{HYPERVISOR_PASSWD}']]]></ac:plain-text-body>
          </ac:structured-macro>
          <ul style="list-style-type: square;">
            <li>Example expected script output:<br/>
              <ac:structured-macro ac:macro-id="01637384-ba3d-4219-b51f-eee1654bc2a8" ac:name="code" ac:schema-version="1">
                <ac:parameter ac:name="language">bash</ac:parameter>
                <ac:plain-text-body><![CDATA[Hypervisor Password (blank for default):
Setting up host ssh keys/certs
Setting up factory config file
Setting up hardware config file
Waiting on Genesis to come up
Setting up /etc/hosts.
Configuring network interfaces on CVM...
Transferring cached configuration
Transferring certificates
Running Nutanix boot script
Copying stored nutanix ssh keys to /home/nutanix
Copying root and intermediate ca certificates to /home/certs
CVM recovery complete
CVM ip : {X.X.X.X}
Please verify genesis status on CVM and cluster status]]></ac:plain-text-body>
              </ac:structured-macro>
            </li>
          </ul>
          <p>Once the script is complete, ensure all cluster services start again on the repaired CVM and that the cluster is returning to a normal operating state with all CVMs in the cluster again.</p>
          <p>If any issues arise during the execution of the script or if it fails to complete successfully, any errors encountered may be analyzed in the <em> <strong>/home/nutanix/data/logs/boot_disk_replace.log</strong> </em> log file on the CVM from which the script was ran.</p>
        </ac:rich-text-body>
      </ac:structured-macro>
      <h3>
        <span style="letter-spacing: -0.006em;">Common Issues and Solutions</span>
      </h3>
      <h4>Hardware and Compatibility Issues</h4>
      <ul>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/6336">KB-6336</a>:</strong> Updating HCL for SSD Hardware Compatibility</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/18370">KB-18370</a>:</strong> "Repair Disk" failed with the error of create_boot_partitions after replacing the SSD</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/13774">KB-13774</a>:</strong> SVM Rescue failing as rescue shell is unable to find disk model for PCIe drives</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/15061">KB-15061</a>:</strong> SVM Rescue for RDMA-enabled nodes</li>
      </ul>
      <h4>Service and Cluster Issues</h4>
      <ul>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/7375">KB-7375:</a>
          </strong> Cassandra Fails to Start after running Boot_Disk_Replace or Single SSD Repair Scripts</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/16452">KB-16452</a>:</strong> Genesis service goes into a crash loop during single_ssd_repair workflow</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/14069">KB-14069</a>:</strong> Cassandra is in forwarding state after CVM wiped by phoenix</li>
      </ul>
      <h4>Script and Repair Issues</h4>
      <ul>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/12753">KB-12753</a>:</strong> Single SSD Repair task fails with "Failed to parse the output of memory info out: Filesystem" error</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/3293">KB-3293</a>:</strong> boot_disk_replace script fails to configure a CVM after running Phoenix</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/7707">KB-7707</a>:</strong> Single SSD repair script failing with "CVM did not come up"</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/5231">KB-5231</a>:</strong> Troubleshooting Single SSD Repair Features</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/15499">KB-15499</a>:</strong> Svmrescue script fails at create_boot_partitions when a CVM boot drive does not have the correct partitions</li>
      </ul>
      <h4>Configuration and Access Issues</h4>
      <ul>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/19245">KB-19245</a>:</strong> SSD Break-fix Workflow reset passwords for 'admin' and 'nutanix' users</li>
        <li>
          <strong>
            <a href="http://portal.nutanix.com/kb/5346">KB-5346</a>:</strong> How to Configure Network Access on Node Booted into Phoenix or Rescue Shells</li>
      </ul>
      <p>
        <br/>
      </p>
      <p>
        <ac:structured-macro ac:macro-id="0cc7d5b7-58b3-429b-8816-6dcb9bb8461a" ac:name="macrosuite-button" ac:schema-version="1">
          <ac:parameter ac:name="macroId">rC5a5Lc8KpDDv5TXp4bt-</ac:parameter>
          <ac:parameter ac:name="data">JTdCJTIyYnV0dG9uVHlwZSUyMiUzQSUyMmljb25fcmlnaHQlMjIlMkMlMjJidXR0b25TaXplJTIyJTNBJTIybGFyZ2UlMjIlMkMlMjJidXR0b25UZXh0JTIyJTNBJTIyUHJvY2VlZCUyMHRvJTIwQ2hhcHRlciUyMDYlM0ElMjBJbnN0YWxsJTIwYW5kJTIwQ29uZmlndXJlJTIwSHlwZXJ2aXNvciUyMiUyQyUyMmJ1dHRvblJhZGl1cyUyMiUzQTElMkMlMjJidXR0b25XaWR0aCUyMiUzQTIwJTJDJTIyYnV0dG9uQ29sb3IlMjIlM0ElMjIlMjMwMDAwMDAwMCUyMiUyQyUyMmJ1dHRvbkZvbnRDb2xvciUyMiUzQSUyMiUyMzAwNjVmZmZmJTIyJTJDJTIyYnV0dG9uQm9yZGVyQ29sb3IlMjIlM0ElMjIlMjMwMDAwMDAwMCUyMiUyQyUyMmJ1dHRvbkxpbmslMjIlM0ElMjIlN0IlNUMlMjJpZCU1QyUyMiUzQSU1QyUyMjQzMTMyODMwMSU1QyUyMiUyQyU1QyUyMmxpbmslNUMlMjIlM0ElNUMlMjIlMkZ4JTJGTFl5MUdRJTVDJTIyJTJDJTVDJTIydGl0bGUlNUMlMjIlM0ElNUMlMjJEUkFGVCUyMC0lMjBQaG9lbml4JTNBJTIwSW5zdGFsbCUyMGFuZCUyMENvbmZpZ3VyZSUyMEh5cGVydmlzb3IlNUMlMjIlMkMlNUMlMjJ0eXBlJTVDJTIyJTNBJTVDJTIycGFnZSU1QyUyMiUyQyU1QyUyMnNvdXJjZSU1QyUyMiUzQSU1QyUyMnBhZ2UlNUMlMjIlN0QlMjIlMkMlMjJidXR0b25OZXdUYWIlMjIlM0ElMjJ0cnVlJTIyJTJDJTIyYnV0dG9uTmV3TGluayUyMiUzQSUyMiUyMiUyQyUyMmJ1dHRvbkljb24lMjIlM0ElMjJib290c3RyYXAlMkZBcnJvd1JpZ2h0Q2lyY2xlJTIyJTJDJTIyYnV0dG9uSG92ZXJDb2xvciUyMiUzQSUyMnRyYW5zcGFyZW50JTIyJTJDJTIyYnV0dG9uQm9yZGVySG92ZXJDb2xvciUyMiUzQSUyMiUyMzAwMDAwMDAwJTIyJTJDJTIyYnV0dG9uRm9udEhvdmVyQ29sb3IlMjIlM0ElMjIlMjMwMDAwMDAwMCUyMiUyQyUyMmJ1dHRvbkljb25Ib3ZlckNvbG9yJTIyJTNBJTIyJTIzMDAwMDAwMDAlMjIlMkMlMjJpc0J1dHRvblNoYWRvd09uJTIyJTNBdHJ1ZSUyQyUyMmJ1dHRvbkljb25Db2xvciUyMiUzQSUyMiUyMzAwNjVmZmZmJTIyJTJDJTIyYnV0dG9uV2lkdGhEZXRlY3Rpb24lMjIlM0E2MCUyQyUyMmVtb2ppRW5hYmxlZCUyMiUzQWZhbHNlJTJDJTIyZW1vamklMjIlM0ElMjIlN0IlN0QlMjIlN0Q=</ac:parameter>
        </ac:structured-macro>
      </p>
    </ac:layout-cell>
  </ac:layout-section>
</ac:layout>
